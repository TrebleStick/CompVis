{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/vincentman0403/dcgan-on-mnist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "38443112fd55bef54d7807495b69d66353bfccae"
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "root = 'DCGAN_results/'\n",
    "\n",
    "# plotting data structure\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []\n",
    "train_hist['accuracy'] = []\n",
    "train_hist['Model'] = []\n",
    "\n",
    "\n",
    "# optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "804d0ab8433b786150c48cd6bd990d74705cb2a8"
   },
   "outputs": [],
   "source": [
    "def build_generator(pick_model='Deep_BN'):\n",
    "    if (pick_model == 'Deep_BN') | (pick_model == 'Deeper_G_BN') | (pick_model == 'Super_Deeper_G_BN'):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "    \n",
    "    elif (pick_model == 'Shallow_BN') | (pick_model == 'Deeper_D_BN'): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "\n",
    "    elif (pick_model == 'Super_Shallow_BN') | (pick_model == 'Super_Deeper_D_BN'): \n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "\n",
    "    elif pick_model == 'Shallow_Drop':\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "    \n",
    "    elif pick_model == 'Drop':\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.summary()\n",
    "        \n",
    "        \n",
    "        \n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "    \n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ea4efecf7d4faeb0a37a649c079ebe88396908"
   },
   "source": [
    "## Define a function to build a discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "b9aa34a385dac406b50e7e122b45483c98c0cffa"
   },
   "outputs": [],
   "source": [
    "# ['Super_Shallow_BN', 'Super_Deeper_G_BN', 'Super_Deeper_G_BN' ]\n",
    "\n",
    "def build_discriminator(pick_model='Deep_BN'):\n",
    "    if (pick_model == 'Deep_BN') | (pick_model == 'Deeper_D_BN') | (pick_model == 'Super_Deeper_D_BN'):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        \n",
    "    elif (pick_model == 'Shallow_BN') | (pick_model == 'Deeper_G_BN'): \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        \n",
    "    elif (pick_model == 'Super_Shallow_BN') | (pick_model == 'Super_Deeper_G_BN'): \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(LeakyReLU(alpha=0.2))\n",
    "#         model.add(Dropout(0.25))\n",
    "#         model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "    elif pick_model == 'Shallow_Drop':\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        \n",
    "    elif pick_model == 'Drop':\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(Dropout(0.25))        \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "    \n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1d9927bd8601eedf144b6f46f12cc4da0d045b5"
   },
   "source": [
    "## Define a function to train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6592840f1e019f1d6fd3e709a0885389d252164f"
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50, ratio = (1,1), pick_model = 'Deep_BN', learning_rate = 0.0002): ## ratio G:D\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    \n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Select a random real images\n",
    "        epoch_start_time = time.time()\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a batch of fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "          \n",
    "        #implement ratio of D  \n",
    "        if epoch % ratio[0] == 0:\n",
    "            # Train the discriminator\n",
    "            D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
    "            D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "            D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n",
    "        #implement ratio of G\n",
    "        if epoch % ratio[1] == 0:\n",
    "            # Train the generator\n",
    "            g_loss = combined.train_on_batch(noise, valid)\n",
    "            \n",
    "        # get epoch timing\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "        # save data for plotting and csv\n",
    "        train_hist['D_losses'].append(D_loss[0])\n",
    "        train_hist['G_losses'].append(g_loss)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)    \n",
    "        train_hist['accuracy'].append(100 * D_loss[1])\n",
    "        train_hist['Model'].append(pick_model)\n",
    "        \n",
    "        # If at save interval\n",
    "        if epoch % save_interval == 0:\n",
    "            # Print the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f] [epoch time: %.2f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss, per_epoch_ptime))\n",
    "            # Save generated image samples\n",
    "            save_imgs(epoch, pick_model, ratio, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b03c0413ddcde5125fa8fdb22bfe47e1bd668606"
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch, pick_model, ratio, learning_rate):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    os.makedirs(root + 'images/'+  pick_model + '/'+ str(ratio[0]) + '_' + str(ratio[1]) + '/' , exist_ok=True)\n",
    "    fig.savefig(root + 'images/'+  pick_model + '/'+ str(ratio[0]) + '_' + str(ratio[1]) + '/' + str(epoch) + '_' + str(learning_rate) + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "    \n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        \n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccbe0a280b9fc16e47a63dc5e5edae8909f7569c"
   },
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8a52d992f11a034e0cc0cabaddeb2ae93f160dc6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\venv\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.008466, acc.: 41.41%] [G loss: 0.685648] [epoch time: 4.38]\n",
      "200 [D loss: 0.786295, acc.: 51.56%] [G loss: 0.952255] [epoch time: 0.08]\n",
      "400 [D loss: 0.737603, acc.: 50.00%] [G loss: 1.080907] [epoch time: 0.08]\n",
      "600 [D loss: 0.722964, acc.: 53.91%] [G loss: 0.964403] [epoch time: 0.08]\n",
      "800 [D loss: 0.755879, acc.: 50.00%] [G loss: 0.975229] [epoch time: 0.08]\n",
      "1000 [D loss: 0.662793, acc.: 58.59%] [G loss: 1.205528] [epoch time: 0.08]\n",
      "1200 [D loss: 0.726496, acc.: 56.25%] [G loss: 0.919586] [epoch time: 0.08]\n",
      "1400 [D loss: 0.683884, acc.: 53.91%] [G loss: 1.001845] [epoch time: 0.08]\n",
      "1600 [D loss: 0.707490, acc.: 54.69%] [G loss: 0.989343] [epoch time: 0.08]\n",
      "1800 [D loss: 0.699541, acc.: 57.03%] [G loss: 0.980808] [epoch time: 0.08]\n",
      "2000 [D loss: 0.672161, acc.: 59.38%] [G loss: 1.020246] [epoch time: 0.08]\n",
      "2200 [D loss: 0.648324, acc.: 64.06%] [G loss: 0.914875] [epoch time: 0.08]\n",
      "2400 [D loss: 0.683703, acc.: 55.47%] [G loss: 0.980410] [epoch time: 0.08]\n",
      "2600 [D loss: 0.658607, acc.: 61.72%] [G loss: 0.896090] [epoch time: 0.08]\n",
      "2800 [D loss: 0.677159, acc.: 59.38%] [G loss: 0.950913] [epoch time: 0.08]\n",
      "3000 [D loss: 0.663411, acc.: 61.72%] [G loss: 0.837463] [epoch time: 0.08]\n",
      "3200 [D loss: 0.672757, acc.: 59.38%] [G loss: 0.973820] [epoch time: 0.08]\n",
      "3400 [D loss: 0.615365, acc.: 65.62%] [G loss: 0.957292] [epoch time: 0.08]\n",
      "3600 [D loss: 0.670309, acc.: 60.94%] [G loss: 0.960195] [epoch time: 0.08]\n",
      "3800 [D loss: 0.689170, acc.: 55.47%] [G loss: 0.917676] [epoch time: 0.08]\n",
      "4000 [D loss: 0.689302, acc.: 57.03%] [G loss: 0.939599] [epoch time: 0.08]\n",
      "4200 [D loss: 0.625463, acc.: 59.38%] [G loss: 1.095782] [epoch time: 0.08]\n",
      "4400 [D loss: 0.707517, acc.: 57.81%] [G loss: 0.963931] [epoch time: 0.08]\n",
      "4600 [D loss: 0.712464, acc.: 53.12%] [G loss: 1.031492] [epoch time: 0.08]\n",
      "4800 [D loss: 0.634821, acc.: 67.19%] [G loss: 0.989875] [epoch time: 0.08]\n",
      "5000 [D loss: 0.624831, acc.: 64.84%] [G loss: 1.055635] [epoch time: 0.08]\n",
      "5200 [D loss: 0.659008, acc.: 63.28%] [G loss: 1.057725] [epoch time: 0.08]\n",
      "5400 [D loss: 0.684988, acc.: 54.69%] [G loss: 1.039461] [epoch time: 0.08]\n",
      "5600 [D loss: 0.683201, acc.: 63.28%] [G loss: 0.948382] [epoch time: 0.08]\n",
      "5800 [D loss: 0.622846, acc.: 64.06%] [G loss: 0.932289] [epoch time: 0.08]\n",
      "6000 [D loss: 0.659384, acc.: 59.38%] [G loss: 0.984071] [epoch time: 0.08]\n",
      "6200 [D loss: 0.637746, acc.: 65.62%] [G loss: 0.866591] [epoch time: 0.08]\n",
      "6400 [D loss: 0.671081, acc.: 56.25%] [G loss: 0.888668] [epoch time: 0.08]\n",
      "6600 [D loss: 0.702780, acc.: 57.81%] [G loss: 0.873055] [epoch time: 0.08]\n",
      "6800 [D loss: 0.645625, acc.: 66.41%] [G loss: 0.868828] [epoch time: 0.08]\n",
      "7000 [D loss: 0.631148, acc.: 66.41%] [G loss: 0.897846] [epoch time: 0.08]\n",
      "7200 [D loss: 0.630362, acc.: 66.41%] [G loss: 0.902776] [epoch time: 0.08]\n",
      "7400 [D loss: 0.716592, acc.: 56.25%] [G loss: 0.917731] [epoch time: 0.08]\n",
      "7600 [D loss: 0.726504, acc.: 52.34%] [G loss: 0.928453] [epoch time: 0.08]\n",
      "7800 [D loss: 0.698094, acc.: 53.91%] [G loss: 0.986246] [epoch time: 0.08]\n",
      "8000 [D loss: 0.642981, acc.: 61.72%] [G loss: 0.889027] [epoch time: 0.08]\n",
      "8200 [D loss: 0.687681, acc.: 53.12%] [G loss: 0.892320] [epoch time: 0.08]\n",
      "8400 [D loss: 0.682361, acc.: 57.03%] [G loss: 0.810899] [epoch time: 0.08]\n",
      "8600 [D loss: 0.665212, acc.: 57.81%] [G loss: 0.988736] [epoch time: 0.08]\n",
      "8800 [D loss: 0.652602, acc.: 60.16%] [G loss: 1.024603] [epoch time: 0.08]\n",
      "9000 [D loss: 0.686417, acc.: 57.81%] [G loss: 0.794411] [epoch time: 0.08]\n",
      "9200 [D loss: 0.699122, acc.: 57.81%] [G loss: 0.915870] [epoch time: 0.08]\n",
      "9400 [D loss: 0.626969, acc.: 62.50%] [G loss: 0.961759] [epoch time: 0.08]\n",
      "9600 [D loss: 0.668280, acc.: 62.50%] [G loss: 0.928553] [epoch time: 0.08]\n",
      "9800 [D loss: 0.696439, acc.: 53.91%] [G loss: 0.911400] [epoch time: 0.08]\n",
      "10000 [D loss: 0.639804, acc.: 62.50%] [G loss: 0.918022] [epoch time: 0.08]\n",
      "10200 [D loss: 0.708720, acc.: 54.69%] [G loss: 0.938548] [epoch time: 0.08]\n",
      "10400 [D loss: 0.668229, acc.: 61.72%] [G loss: 0.840056] [epoch time: 0.08]\n",
      "10600 [D loss: 0.690620, acc.: 55.47%] [G loss: 0.872948] [epoch time: 0.08]\n",
      "10800 [D loss: 0.679373, acc.: 60.94%] [G loss: 0.944133] [epoch time: 0.08]\n",
      "11000 [D loss: 0.622678, acc.: 65.62%] [G loss: 1.106318] [epoch time: 0.08]\n",
      "11200 [D loss: 0.596154, acc.: 67.97%] [G loss: 0.893641] [epoch time: 0.08]\n",
      "11400 [D loss: 0.728093, acc.: 51.56%] [G loss: 0.839972] [epoch time: 0.08]\n",
      "11600 [D loss: 0.708380, acc.: 53.91%] [G loss: 0.930186] [epoch time: 0.08]\n",
      "11800 [D loss: 0.647518, acc.: 56.25%] [G loss: 0.849178] [epoch time: 0.08]\n",
      "12000 [D loss: 0.552970, acc.: 74.22%] [G loss: 0.970125] [epoch time: 0.08]\n",
      "12200 [D loss: 0.661350, acc.: 55.47%] [G loss: 0.892248] [epoch time: 0.08]\n",
      "12400 [D loss: 0.685888, acc.: 59.38%] [G loss: 0.891816] [epoch time: 0.08]\n",
      "12600 [D loss: 0.635106, acc.: 66.41%] [G loss: 1.098117] [epoch time: 0.08]\n",
      "12800 [D loss: 0.671396, acc.: 60.16%] [G loss: 0.874043] [epoch time: 0.08]\n",
      "13000 [D loss: 0.589124, acc.: 72.66%] [G loss: 0.960705] [epoch time: 0.08]\n",
      "13200 [D loss: 0.616986, acc.: 71.09%] [G loss: 0.959123] [epoch time: 0.08]\n",
      "13400 [D loss: 0.620414, acc.: 63.28%] [G loss: 0.838603] [epoch time: 0.08]\n",
      "13600 [D loss: 0.682930, acc.: 60.16%] [G loss: 0.975945] [epoch time: 0.08]\n",
      "13800 [D loss: 0.653693, acc.: 64.06%] [G loss: 0.951592] [epoch time: 0.08]\n",
      "14000 [D loss: 0.634577, acc.: 60.94%] [G loss: 0.804840] [epoch time: 0.08]\n",
      "14200 [D loss: 0.635658, acc.: 65.62%] [G loss: 0.864210] [epoch time: 0.08]\n",
      "14400 [D loss: 0.619163, acc.: 64.84%] [G loss: 0.985218] [epoch time: 0.08]\n",
      "14600 [D loss: 0.556731, acc.: 76.56%] [G loss: 1.065751] [epoch time: 0.08]\n",
      "14800 [D loss: 0.675487, acc.: 57.81%] [G loss: 0.903605] [epoch time: 0.08]\n",
      "15000 [D loss: 0.686544, acc.: 51.56%] [G loss: 0.983884] [epoch time: 0.08]\n",
      "15200 [D loss: 0.592108, acc.: 70.31%] [G loss: 0.991883] [epoch time: 0.08]\n",
      "15400 [D loss: 0.696608, acc.: 58.59%] [G loss: 1.060925] [epoch time: 0.08]\n",
      "15600 [D loss: 0.642464, acc.: 63.28%] [G loss: 1.033265] [epoch time: 0.08]\n",
      "15800 [D loss: 0.580315, acc.: 71.09%] [G loss: 0.928526] [epoch time: 0.08]\n",
      "16000 [D loss: 0.607771, acc.: 68.75%] [G loss: 0.924648] [epoch time: 0.08]\n",
      "16200 [D loss: 0.606700, acc.: 69.53%] [G loss: 0.936025] [epoch time: 0.08]\n",
      "16400 [D loss: 0.645991, acc.: 60.94%] [G loss: 0.969659] [epoch time: 0.08]\n",
      "16600 [D loss: 0.620823, acc.: 67.19%] [G loss: 1.050624] [epoch time: 0.08]\n",
      "16800 [D loss: 0.692166, acc.: 52.34%] [G loss: 1.104562] [epoch time: 0.08]\n",
      "17000 [D loss: 0.591629, acc.: 67.19%] [G loss: 1.033164] [epoch time: 0.08]\n",
      "17200 [D loss: 0.707716, acc.: 56.25%] [G loss: 0.841965] [epoch time: 0.08]\n",
      "17400 [D loss: 0.586759, acc.: 69.53%] [G loss: 0.876227] [epoch time: 0.08]\n",
      "17600 [D loss: 0.570949, acc.: 71.88%] [G loss: 1.045954] [epoch time: 0.08]\n",
      "17800 [D loss: 0.580190, acc.: 73.44%] [G loss: 0.942805] [epoch time: 0.08]\n",
      "18000 [D loss: 0.728387, acc.: 52.34%] [G loss: 0.837248] [epoch time: 0.08]\n",
      "18200 [D loss: 0.559869, acc.: 70.31%] [G loss: 1.074296] [epoch time: 0.08]\n",
      "18400 [D loss: 0.703137, acc.: 56.25%] [G loss: 0.813316] [epoch time: 0.08]\n",
      "18600 [D loss: 0.636190, acc.: 64.06%] [G loss: 0.959466] [epoch time: 0.08]\n",
      "18800 [D loss: 0.659359, acc.: 59.38%] [G loss: 0.929790] [epoch time: 0.08]\n",
      "19000 [D loss: 0.672751, acc.: 60.94%] [G loss: 0.838146] [epoch time: 0.08]\n",
      "19200 [D loss: 0.625304, acc.: 62.50%] [G loss: 1.069649] [epoch time: 0.08]\n",
      "19400 [D loss: 0.723368, acc.: 50.00%] [G loss: 0.917679] [epoch time: 0.08]\n",
      "19600 [D loss: 0.684674, acc.: 60.16%] [G loss: 0.958307] [epoch time: 0.08]\n",
      "19800 [D loss: 0.548406, acc.: 75.78%] [G loss: 1.017388] [epoch time: 0.08]\n",
      "20000 [D loss: 0.715184, acc.: 53.12%] [G loss: 0.823132] [epoch time: 0.08]\n",
      "elapsed training time: 27 min, 14 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.014787, acc.: 35.16%] [G loss: 1.010863] [epoch time: 3.77]\n",
      "200 [D loss: 0.727493, acc.: 53.91%] [G loss: 1.286718] [epoch time: 0.08]\n",
      "400 [D loss: 0.688185, acc.: 64.06%] [G loss: 1.416378] [epoch time: 0.08]\n",
      "600 [D loss: 0.636580, acc.: 64.06%] [G loss: 1.278563] [epoch time: 0.08]\n",
      "800 [D loss: 0.618653, acc.: 70.31%] [G loss: 1.434143] [epoch time: 0.08]\n",
      "1000 [D loss: 0.747510, acc.: 56.25%] [G loss: 1.249658] [epoch time: 0.08]\n",
      "1200 [D loss: 0.615622, acc.: 67.97%] [G loss: 1.326074] [epoch time: 0.08]\n",
      "1400 [D loss: 0.642278, acc.: 65.62%] [G loss: 1.347998] [epoch time: 0.08]\n",
      "1600 [D loss: 0.645095, acc.: 68.75%] [G loss: 1.093936] [epoch time: 0.08]\n",
      "1800 [D loss: 0.582064, acc.: 68.75%] [G loss: 1.483608] [epoch time: 0.08]\n",
      "2000 [D loss: 0.683885, acc.: 60.16%] [G loss: 1.269998] [epoch time: 0.08]\n",
      "2200 [D loss: 0.692835, acc.: 60.94%] [G loss: 1.260320] [epoch time: 0.08]\n",
      "2400 [D loss: 0.728156, acc.: 52.34%] [G loss: 1.008286] [epoch time: 0.08]\n",
      "2600 [D loss: 0.595063, acc.: 66.41%] [G loss: 1.145985] [epoch time: 0.08]\n",
      "2800 [D loss: 0.589912, acc.: 70.31%] [G loss: 1.121323] [epoch time: 0.08]\n",
      "3000 [D loss: 0.646867, acc.: 58.59%] [G loss: 1.120787] [epoch time: 0.08]\n",
      "3200 [D loss: 0.516654, acc.: 76.56%] [G loss: 1.442652] [epoch time: 0.08]\n",
      "3400 [D loss: 0.647719, acc.: 57.03%] [G loss: 1.298416] [epoch time: 0.08]\n",
      "3600 [D loss: 0.567588, acc.: 68.75%] [G loss: 1.472496] [epoch time: 0.08]\n",
      "3800 [D loss: 0.575381, acc.: 72.66%] [G loss: 1.363067] [epoch time: 0.08]\n",
      "4000 [D loss: 0.598725, acc.: 67.19%] [G loss: 1.242310] [epoch time: 0.08]\n",
      "4200 [D loss: 0.591185, acc.: 67.19%] [G loss: 1.174314] [epoch time: 0.08]\n",
      "4400 [D loss: 0.633155, acc.: 64.84%] [G loss: 1.172763] [epoch time: 0.08]\n",
      "4600 [D loss: 0.589710, acc.: 68.75%] [G loss: 1.493043] [epoch time: 0.08]\n",
      "4800 [D loss: 0.559632, acc.: 75.78%] [G loss: 1.331253] [epoch time: 0.08]\n",
      "5000 [D loss: 0.455128, acc.: 75.00%] [G loss: 1.215034] [epoch time: 0.08]\n",
      "5200 [D loss: 0.490847, acc.: 79.69%] [G loss: 1.241311] [epoch time: 0.08]\n",
      "5400 [D loss: 0.517696, acc.: 75.78%] [G loss: 1.396214] [epoch time: 0.08]\n",
      "5600 [D loss: 0.529284, acc.: 75.78%] [G loss: 1.377301] [epoch time: 0.08]\n",
      "5800 [D loss: 0.600427, acc.: 67.19%] [G loss: 1.300413] [epoch time: 0.08]\n",
      "6000 [D loss: 0.623802, acc.: 67.19%] [G loss: 1.353865] [epoch time: 0.08]\n",
      "6200 [D loss: 0.510029, acc.: 79.69%] [G loss: 1.286743] [epoch time: 0.08]\n",
      "6400 [D loss: 0.596012, acc.: 71.09%] [G loss: 1.745448] [epoch time: 0.08]\n",
      "6600 [D loss: 0.441249, acc.: 78.91%] [G loss: 1.495242] [epoch time: 0.08]\n",
      "6800 [D loss: 0.608303, acc.: 69.53%] [G loss: 1.645856] [epoch time: 0.08]\n",
      "7000 [D loss: 0.599786, acc.: 64.06%] [G loss: 1.111174] [epoch time: 0.08]\n",
      "7200 [D loss: 0.558273, acc.: 70.31%] [G loss: 1.242580] [epoch time: 0.08]\n",
      "7400 [D loss: 0.414588, acc.: 87.50%] [G loss: 1.374937] [epoch time: 0.08]\n",
      "7600 [D loss: 0.524157, acc.: 71.88%] [G loss: 1.371045] [epoch time: 0.08]\n",
      "7800 [D loss: 0.508027, acc.: 75.00%] [G loss: 1.196969] [epoch time: 0.08]\n",
      "8000 [D loss: 0.576857, acc.: 72.66%] [G loss: 1.331440] [epoch time: 0.08]\n",
      "8200 [D loss: 0.696175, acc.: 53.91%] [G loss: 1.085243] [epoch time: 0.08]\n",
      "8400 [D loss: 0.625439, acc.: 66.41%] [G loss: 1.307234] [epoch time: 0.08]\n",
      "8600 [D loss: 0.559676, acc.: 66.41%] [G loss: 1.289475] [epoch time: 0.08]\n",
      "8800 [D loss: 0.384211, acc.: 83.59%] [G loss: 2.055137] [epoch time: 0.08]\n",
      "9000 [D loss: 0.572061, acc.: 66.41%] [G loss: 1.452574] [epoch time: 0.08]\n",
      "9200 [D loss: 0.348686, acc.: 89.84%] [G loss: 1.637260] [epoch time: 0.08]\n",
      "9400 [D loss: 0.540310, acc.: 69.53%] [G loss: 1.432143] [epoch time: 0.08]\n",
      "9600 [D loss: 0.829689, acc.: 45.31%] [G loss: 1.310399] [epoch time: 0.08]\n",
      "9800 [D loss: 0.411071, acc.: 81.25%] [G loss: 1.624922] [epoch time: 0.08]\n",
      "10000 [D loss: 0.432977, acc.: 78.91%] [G loss: 1.871395] [epoch time: 0.08]\n",
      "10200 [D loss: 0.519342, acc.: 75.00%] [G loss: 1.482682] [epoch time: 0.08]\n",
      "10400 [D loss: 0.407496, acc.: 78.91%] [G loss: 1.351356] [epoch time: 0.08]\n",
      "10600 [D loss: 0.492396, acc.: 74.22%] [G loss: 1.447971] [epoch time: 0.08]\n",
      "10800 [D loss: 0.552288, acc.: 71.88%] [G loss: 1.389029] [epoch time: 0.08]\n",
      "11000 [D loss: 0.478076, acc.: 78.91%] [G loss: 1.531046] [epoch time: 0.08]\n",
      "11200 [D loss: 0.375668, acc.: 89.06%] [G loss: 1.515376] [epoch time: 0.08]\n",
      "11400 [D loss: 0.390357, acc.: 86.72%] [G loss: 1.797406] [epoch time: 0.08]\n",
      "11600 [D loss: 0.370709, acc.: 84.38%] [G loss: 1.792862] [epoch time: 0.08]\n",
      "11800 [D loss: 0.471818, acc.: 79.69%] [G loss: 1.126124] [epoch time: 0.08]\n",
      "12000 [D loss: 0.663174, acc.: 63.28%] [G loss: 0.935428] [epoch time: 0.08]\n",
      "12200 [D loss: 0.678912, acc.: 65.62%] [G loss: 1.353507] [epoch time: 0.08]\n",
      "12400 [D loss: 0.396620, acc.: 87.50%] [G loss: 1.424779] [epoch time: 0.08]\n",
      "12600 [D loss: 0.429774, acc.: 79.69%] [G loss: 1.577606] [epoch time: 0.08]\n",
      "12800 [D loss: 0.750889, acc.: 58.59%] [G loss: 1.637110] [epoch time: 0.08]\n",
      "13000 [D loss: 0.459278, acc.: 77.34%] [G loss: 1.619845] [epoch time: 0.08]\n",
      "13200 [D loss: 0.475602, acc.: 76.56%] [G loss: 1.357281] [epoch time: 0.08]\n",
      "13400 [D loss: 0.705566, acc.: 60.16%] [G loss: 1.200004] [epoch time: 0.08]\n",
      "13600 [D loss: 0.542756, acc.: 75.00%] [G loss: 1.649456] [epoch time: 0.08]\n",
      "13800 [D loss: 0.549571, acc.: 73.44%] [G loss: 1.653939] [epoch time: 0.08]\n",
      "14000 [D loss: 0.466596, acc.: 77.34%] [G loss: 1.657956] [epoch time: 0.08]\n",
      "14200 [D loss: 0.537325, acc.: 73.44%] [G loss: 1.613559] [epoch time: 0.08]\n",
      "14400 [D loss: 0.540987, acc.: 71.88%] [G loss: 1.663358] [epoch time: 0.08]\n",
      "14600 [D loss: 0.541611, acc.: 68.75%] [G loss: 1.477654] [epoch time: 0.08]\n",
      "14800 [D loss: 0.436459, acc.: 82.03%] [G loss: 1.765895] [epoch time: 0.08]\n",
      "15000 [D loss: 0.432078, acc.: 81.25%] [G loss: 1.922459] [epoch time: 0.08]\n",
      "15200 [D loss: 0.676599, acc.: 60.94%] [G loss: 2.038200] [epoch time: 0.08]\n",
      "15400 [D loss: 0.585982, acc.: 68.75%] [G loss: 1.459554] [epoch time: 0.08]\n",
      "15600 [D loss: 0.582992, acc.: 73.44%] [G loss: 1.915794] [epoch time: 0.08]\n",
      "15800 [D loss: 0.460027, acc.: 80.47%] [G loss: 1.799774] [epoch time: 0.08]\n",
      "16000 [D loss: 0.363726, acc.: 87.50%] [G loss: 1.432504] [epoch time: 0.08]\n",
      "16200 [D loss: 0.463135, acc.: 80.47%] [G loss: 1.760397] [epoch time: 0.08]\n",
      "16400 [D loss: 0.379374, acc.: 82.03%] [G loss: 2.833094] [epoch time: 0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.443559, acc.: 78.12%] [G loss: 3.102589] [epoch time: 0.08]\n",
      "16800 [D loss: 0.434371, acc.: 82.81%] [G loss: 1.837837] [epoch time: 0.08]\n",
      "17000 [D loss: 0.257286, acc.: 92.19%] [G loss: 2.639184] [epoch time: 0.08]\n",
      "17200 [D loss: 0.725681, acc.: 57.81%] [G loss: 0.886708] [epoch time: 0.08]\n",
      "17400 [D loss: 0.417361, acc.: 84.38%] [G loss: 1.607180] [epoch time: 0.08]\n",
      "17600 [D loss: 0.414896, acc.: 82.03%] [G loss: 1.606326] [epoch time: 0.08]\n",
      "17800 [D loss: 0.294145, acc.: 91.41%] [G loss: 1.958528] [epoch time: 0.08]\n",
      "18000 [D loss: 0.514707, acc.: 74.22%] [G loss: 1.336584] [epoch time: 0.08]\n",
      "18200 [D loss: 0.377778, acc.: 86.72%] [G loss: 2.229562] [epoch time: 0.08]\n",
      "18400 [D loss: 0.574477, acc.: 70.31%] [G loss: 2.381286] [epoch time: 0.08]\n",
      "18600 [D loss: 0.422223, acc.: 83.59%] [G loss: 1.029370] [epoch time: 0.08]\n",
      "18800 [D loss: 0.316643, acc.: 88.28%] [G loss: 1.888835] [epoch time: 0.08]\n",
      "19000 [D loss: 0.428740, acc.: 78.91%] [G loss: 1.714338] [epoch time: 0.08]\n",
      "19200 [D loss: 0.412312, acc.: 82.03%] [G loss: 1.909217] [epoch time: 0.08]\n",
      "19400 [D loss: 0.473138, acc.: 75.78%] [G loss: 1.911443] [epoch time: 0.08]\n",
      "19600 [D loss: 0.434503, acc.: 78.91%] [G loss: 2.275001] [epoch time: 0.08]\n",
      "19800 [D loss: 0.420767, acc.: 85.16%] [G loss: 1.395501] [epoch time: 0.08]\n",
      "20000 [D loss: 0.898914, acc.: 50.78%] [G loss: 0.811431] [epoch time: 0.08]\n",
      "elapsed training time: 20 min, 29 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.142276, acc.: 35.94%] [G loss: 0.846666] [epoch time: 4.72]\n",
      "200 [D loss: 0.899725, acc.: 47.66%] [G loss: 1.341305] [epoch time: 0.04]\n",
      "400 [D loss: 0.767426, acc.: 51.56%] [G loss: 1.180834] [epoch time: 0.04]\n",
      "600 [D loss: 0.624278, acc.: 61.72%] [G loss: 1.153434] [epoch time: 0.08]\n",
      "800 [D loss: 0.595944, acc.: 67.97%] [G loss: 1.375247] [epoch time: 0.04]\n",
      "1000 [D loss: 0.619426, acc.: 67.97%] [G loss: 1.136235] [epoch time: 0.04]\n",
      "1200 [D loss: 0.716500, acc.: 60.94%] [G loss: 1.123789] [epoch time: 0.08]\n",
      "1400 [D loss: 0.633808, acc.: 66.41%] [G loss: 1.133070] [epoch time: 0.04]\n",
      "1600 [D loss: 0.564948, acc.: 71.09%] [G loss: 1.348644] [epoch time: 0.04]\n",
      "1800 [D loss: 0.615690, acc.: 66.41%] [G loss: 1.150135] [epoch time: 0.08]\n",
      "2000 [D loss: 0.554851, acc.: 68.75%] [G loss: 1.339463] [epoch time: 0.04]\n",
      "2200 [D loss: 0.548886, acc.: 76.56%] [G loss: 1.258049] [epoch time: 0.04]\n",
      "2400 [D loss: 0.634817, acc.: 61.72%] [G loss: 1.492882] [epoch time: 0.08]\n",
      "2600 [D loss: 0.655990, acc.: 60.16%] [G loss: 1.380569] [epoch time: 0.04]\n",
      "2800 [D loss: 0.517718, acc.: 72.66%] [G loss: 1.159898] [epoch time: 0.04]\n",
      "3000 [D loss: 0.420691, acc.: 85.16%] [G loss: 1.470128] [epoch time: 0.08]\n",
      "3200 [D loss: 0.484618, acc.: 78.91%] [G loss: 1.348136] [epoch time: 0.04]\n",
      "3400 [D loss: 0.490396, acc.: 75.00%] [G loss: 1.603233] [epoch time: 0.04]\n",
      "3600 [D loss: 0.600320, acc.: 69.53%] [G loss: 1.548197] [epoch time: 0.08]\n",
      "3800 [D loss: 0.534611, acc.: 73.44%] [G loss: 1.602035] [epoch time: 0.04]\n",
      "4000 [D loss: 0.651478, acc.: 64.84%] [G loss: 1.457237] [epoch time: 0.04]\n",
      "4200 [D loss: 0.498647, acc.: 74.22%] [G loss: 1.747909] [epoch time: 0.08]\n",
      "4400 [D loss: 0.465911, acc.: 82.03%] [G loss: 2.110798] [epoch time: 0.04]\n",
      "4600 [D loss: 0.512399, acc.: 76.56%] [G loss: 1.963678] [epoch time: 0.04]\n",
      "4800 [D loss: 0.437167, acc.: 81.25%] [G loss: 2.221828] [epoch time: 0.08]\n",
      "5000 [D loss: 0.469483, acc.: 78.91%] [G loss: 1.746564] [epoch time: 0.04]\n",
      "5200 [D loss: 0.469863, acc.: 75.78%] [G loss: 1.703349] [epoch time: 0.04]\n",
      "5400 [D loss: 0.457409, acc.: 79.69%] [G loss: 2.042896] [epoch time: 0.08]\n",
      "5600 [D loss: 0.384975, acc.: 81.25%] [G loss: 1.809854] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 [D loss: 0.395692, acc.: 83.59%] [G loss: 2.316030] [epoch time: 0.04]\n",
      "6000 [D loss: 0.497255, acc.: 77.34%] [G loss: 2.182590] [epoch time: 0.08]\n",
      "6200 [D loss: 0.343831, acc.: 85.16%] [G loss: 1.559067] [epoch time: 0.04]\n",
      "6400 [D loss: 0.424887, acc.: 80.47%] [G loss: 2.430290] [epoch time: 0.04]\n",
      "6600 [D loss: 0.522868, acc.: 71.88%] [G loss: 1.511025] [epoch time: 0.08]\n",
      "6800 [D loss: 0.247237, acc.: 94.53%] [G loss: 2.025560] [epoch time: 0.04]\n",
      "7000 [D loss: 0.379540, acc.: 80.47%] [G loss: 2.280120] [epoch time: 0.04]\n",
      "7200 [D loss: 0.259717, acc.: 92.19%] [G loss: 2.576595] [epoch time: 0.08]\n",
      "7400 [D loss: 0.221823, acc.: 93.75%] [G loss: 1.995530] [epoch time: 0.04]\n",
      "7600 [D loss: 0.320211, acc.: 89.06%] [G loss: 1.867314] [epoch time: 0.04]\n",
      "7800 [D loss: 0.312481, acc.: 89.84%] [G loss: 2.236767] [epoch time: 0.08]\n",
      "8000 [D loss: 0.393584, acc.: 82.81%] [G loss: 2.444447] [epoch time: 0.04]\n",
      "8200 [D loss: 0.376096, acc.: 85.16%] [G loss: 1.985093] [epoch time: 0.04]\n",
      "8400 [D loss: 0.378927, acc.: 82.03%] [G loss: 1.984690] [epoch time: 0.08]\n",
      "8600 [D loss: 0.269763, acc.: 91.41%] [G loss: 3.419035] [epoch time: 0.04]\n",
      "8800 [D loss: 0.435324, acc.: 77.34%] [G loss: 1.465395] [epoch time: 0.04]\n",
      "9000 [D loss: 0.184944, acc.: 95.31%] [G loss: 2.425906] [epoch time: 0.08]\n",
      "9200 [D loss: 0.202799, acc.: 93.75%] [G loss: 1.896685] [epoch time: 0.04]\n",
      "9400 [D loss: 0.327158, acc.: 89.84%] [G loss: 3.153509] [epoch time: 0.04]\n",
      "9600 [D loss: 0.233683, acc.: 92.97%] [G loss: 2.000518] [epoch time: 0.08]\n",
      "9800 [D loss: 0.267252, acc.: 90.62%] [G loss: 1.995379] [epoch time: 0.04]\n",
      "10000 [D loss: 0.356333, acc.: 86.72%] [G loss: 2.686255] [epoch time: 0.04]\n",
      "10200 [D loss: 0.700112, acc.: 63.28%] [G loss: 2.697121] [epoch time: 0.08]\n",
      "10400 [D loss: 0.287165, acc.: 89.84%] [G loss: 2.165768] [epoch time: 0.04]\n",
      "10600 [D loss: 0.438942, acc.: 81.25%] [G loss: 3.510161] [epoch time: 0.04]\n",
      "10800 [D loss: 0.294666, acc.: 89.84%] [G loss: 2.111262] [epoch time: 0.08]\n",
      "11000 [D loss: 0.317962, acc.: 91.41%] [G loss: 4.016918] [epoch time: 0.04]\n",
      "11200 [D loss: 0.240313, acc.: 92.19%] [G loss: 3.400876] [epoch time: 0.04]\n",
      "11400 [D loss: 0.454972, acc.: 80.47%] [G loss: 1.925378] [epoch time: 0.08]\n",
      "11600 [D loss: 0.280255, acc.: 90.62%] [G loss: 3.047536] [epoch time: 0.04]\n",
      "11800 [D loss: 0.277299, acc.: 90.62%] [G loss: 2.685715] [epoch time: 0.04]\n",
      "12000 [D loss: 0.231756, acc.: 93.75%] [G loss: 2.701310] [epoch time: 0.08]\n",
      "12200 [D loss: 0.153787, acc.: 96.88%] [G loss: 3.482866] [epoch time: 0.04]\n",
      "12400 [D loss: 0.250763, acc.: 92.19%] [G loss: 1.928252] [epoch time: 0.04]\n",
      "12600 [D loss: 0.365217, acc.: 85.16%] [G loss: 2.961968] [epoch time: 0.08]\n",
      "12800 [D loss: 0.591628, acc.: 72.66%] [G loss: 3.521533] [epoch time: 0.04]\n",
      "13000 [D loss: 0.517911, acc.: 78.12%] [G loss: 3.064249] [epoch time: 0.04]\n",
      "13200 [D loss: 0.454671, acc.: 75.78%] [G loss: 2.320997] [epoch time: 0.08]\n",
      "13400 [D loss: 0.401770, acc.: 82.03%] [G loss: 1.573590] [epoch time: 0.04]\n",
      "13600 [D loss: 0.184226, acc.: 95.31%] [G loss: 2.241441] [epoch time: 0.04]\n",
      "13800 [D loss: 0.220669, acc.: 92.97%] [G loss: 3.407145] [epoch time: 0.08]\n",
      "14000 [D loss: 0.297064, acc.: 92.19%] [G loss: 3.742019] [epoch time: 0.04]\n",
      "14200 [D loss: 0.226373, acc.: 94.53%] [G loss: 3.947833] [epoch time: 0.04]\n",
      "14400 [D loss: 0.686273, acc.: 61.72%] [G loss: 2.035669] [epoch time: 0.08]\n",
      "14600 [D loss: 0.335294, acc.: 89.06%] [G loss: 2.213767] [epoch time: 0.04]\n",
      "14800 [D loss: 0.213627, acc.: 90.62%] [G loss: 2.529005] [epoch time: 0.04]\n",
      "15000 [D loss: 0.195312, acc.: 93.75%] [G loss: 2.288508] [epoch time: 0.08]\n",
      "15200 [D loss: 0.293588, acc.: 91.41%] [G loss: 2.470953] [epoch time: 0.04]\n",
      "15400 [D loss: 0.272561, acc.: 86.72%] [G loss: 3.551099] [epoch time: 0.04]\n",
      "15600 [D loss: 0.820260, acc.: 53.91%] [G loss: 3.342173] [epoch time: 0.08]\n",
      "15800 [D loss: 0.724544, acc.: 66.41%] [G loss: 3.441853] [epoch time: 0.04]\n",
      "16000 [D loss: 0.128318, acc.: 97.66%] [G loss: 2.307179] [epoch time: 0.04]\n",
      "16200 [D loss: 0.298972, acc.: 87.50%] [G loss: 4.058929] [epoch time: 0.08]\n",
      "16400 [D loss: 0.256459, acc.: 85.16%] [G loss: 2.664971] [epoch time: 0.04]\n",
      "16600 [D loss: 0.788785, acc.: 57.81%] [G loss: 3.076047] [epoch time: 0.04]\n",
      "16800 [D loss: 0.103564, acc.: 97.66%] [G loss: 2.929302] [epoch time: 0.08]\n",
      "17000 [D loss: 0.141496, acc.: 95.31%] [G loss: 3.145819] [epoch time: 0.04]\n",
      "17200 [D loss: 0.154305, acc.: 96.88%] [G loss: 2.063891] [epoch time: 0.04]\n",
      "17400 [D loss: 0.366498, acc.: 80.47%] [G loss: 2.195048] [epoch time: 0.08]\n",
      "17600 [D loss: 0.235153, acc.: 90.62%] [G loss: 2.828833] [epoch time: 0.04]\n",
      "17800 [D loss: 0.447273, acc.: 78.91%] [G loss: 3.681656] [epoch time: 0.04]\n",
      "18000 [D loss: 0.270673, acc.: 91.41%] [G loss: 2.358740] [epoch time: 0.08]\n",
      "18200 [D loss: 0.338321, acc.: 89.06%] [G loss: 3.712542] [epoch time: 0.04]\n",
      "18400 [D loss: 0.117307, acc.: 98.44%] [G loss: 3.117353] [epoch time: 0.04]\n",
      "18600 [D loss: 0.089401, acc.: 100.00%] [G loss: 3.269431] [epoch time: 0.08]\n",
      "18800 [D loss: 0.222720, acc.: 91.41%] [G loss: 2.743392] [epoch time: 0.04]\n",
      "19000 [D loss: 0.202148, acc.: 92.97%] [G loss: 2.874991] [epoch time: 0.04]\n",
      "19200 [D loss: 0.384124, acc.: 83.59%] [G loss: 1.964637] [epoch time: 0.08]\n",
      "19400 [D loss: 0.210124, acc.: 90.62%] [G loss: 3.880151] [epoch time: 0.04]\n",
      "19600 [D loss: 0.260936, acc.: 89.06%] [G loss: 2.843534] [epoch time: 0.04]\n",
      "19800 [D loss: 0.314831, acc.: 87.50%] [G loss: 1.480889] [epoch time: 0.08]\n",
      "20000 [D loss: 0.271647, acc.: 89.84%] [G loss: 3.252780] [epoch time: 0.04]\n",
      "elapsed training time: 18 min, 16 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.041931, acc.: 29.69%] [G loss: 0.785253] [epoch time: 5.19]\n",
      "200 [D loss: 0.932304, acc.: 36.72%] [G loss: 1.122961] [epoch time: 0.06]\n",
      "400 [D loss: 0.831359, acc.: 42.19%] [G loss: 0.964083] [epoch time: 0.05]\n",
      "600 [D loss: 0.852784, acc.: 41.41%] [G loss: 0.988011] [epoch time: 0.09]\n",
      "800 [D loss: 0.794831, acc.: 49.22%] [G loss: 0.939349] [epoch time: 0.06]\n",
      "1000 [D loss: 0.773723, acc.: 50.78%] [G loss: 0.930326] [epoch time: 0.05]\n",
      "1200 [D loss: 0.786315, acc.: 43.75%] [G loss: 0.945870] [epoch time: 0.09]\n",
      "1400 [D loss: 0.764640, acc.: 46.09%] [G loss: 0.928503] [epoch time: 0.06]\n",
      "1600 [D loss: 0.818188, acc.: 41.41%] [G loss: 0.887767] [epoch time: 0.05]\n",
      "1800 [D loss: 0.834590, acc.: 41.41%] [G loss: 0.850283] [epoch time: 0.09]\n",
      "2000 [D loss: 0.763545, acc.: 42.97%] [G loss: 0.885921] [epoch time: 0.06]\n",
      "2200 [D loss: 0.782736, acc.: 50.00%] [G loss: 0.884863] [epoch time: 0.05]\n",
      "2400 [D loss: 0.718891, acc.: 55.47%] [G loss: 0.874586] [epoch time: 0.08]\n",
      "2600 [D loss: 0.779912, acc.: 39.06%] [G loss: 0.875791] [epoch time: 0.06]\n",
      "2800 [D loss: 0.810371, acc.: 37.50%] [G loss: 0.843502] [epoch time: 0.05]\n",
      "3000 [D loss: 0.787250, acc.: 44.53%] [G loss: 0.824664] [epoch time: 0.08]\n",
      "3200 [D loss: 0.719815, acc.: 50.00%] [G loss: 0.813401] [epoch time: 0.06]\n",
      "3400 [D loss: 0.744550, acc.: 49.22%] [G loss: 0.795060] [epoch time: 0.05]\n",
      "3600 [D loss: 0.763550, acc.: 45.31%] [G loss: 0.836593] [epoch time: 0.08]\n",
      "3800 [D loss: 0.711187, acc.: 49.22%] [G loss: 0.724400] [epoch time: 0.06]\n",
      "4000 [D loss: 0.711557, acc.: 50.78%] [G loss: 0.892644] [epoch time: 0.05]\n",
      "4200 [D loss: 0.769033, acc.: 42.97%] [G loss: 0.784923] [epoch time: 0.08]\n",
      "4400 [D loss: 0.743245, acc.: 42.97%] [G loss: 0.805018] [epoch time: 0.06]\n",
      "4600 [D loss: 0.726375, acc.: 46.09%] [G loss: 0.815288] [epoch time: 0.05]\n",
      "4800 [D loss: 0.720143, acc.: 53.91%] [G loss: 0.769222] [epoch time: 0.09]\n",
      "5000 [D loss: 0.741158, acc.: 47.66%] [G loss: 0.825874] [epoch time: 0.06]\n",
      "5200 [D loss: 0.717298, acc.: 51.56%] [G loss: 0.833724] [epoch time: 0.05]\n",
      "5400 [D loss: 0.743235, acc.: 46.09%] [G loss: 0.857352] [epoch time: 0.09]\n",
      "5600 [D loss: 0.769227, acc.: 44.53%] [G loss: 0.755960] [epoch time: 0.06]\n",
      "5800 [D loss: 0.736935, acc.: 46.09%] [G loss: 0.827672] [epoch time: 0.05]\n",
      "6000 [D loss: 0.685927, acc.: 57.03%] [G loss: 0.783057] [epoch time: 0.08]\n",
      "6200 [D loss: 0.740471, acc.: 46.88%] [G loss: 0.780201] [epoch time: 0.06]\n",
      "6400 [D loss: 0.730037, acc.: 46.09%] [G loss: 0.813961] [epoch time: 0.05]\n",
      "6600 [D loss: 0.707161, acc.: 52.34%] [G loss: 0.831547] [epoch time: 0.09]\n",
      "6800 [D loss: 0.750209, acc.: 46.09%] [G loss: 0.768983] [epoch time: 0.06]\n",
      "7000 [D loss: 0.778023, acc.: 40.62%] [G loss: 0.825428] [epoch time: 0.05]\n",
      "7200 [D loss: 0.727430, acc.: 43.75%] [G loss: 0.765119] [epoch time: 0.09]\n",
      "7400 [D loss: 0.706562, acc.: 51.56%] [G loss: 0.757922] [epoch time: 0.06]\n",
      "7600 [D loss: 0.722341, acc.: 42.19%] [G loss: 0.718991] [epoch time: 0.05]\n",
      "7800 [D loss: 0.727675, acc.: 50.00%] [G loss: 0.814918] [epoch time: 0.09]\n",
      "8000 [D loss: 0.719033, acc.: 56.25%] [G loss: 0.767524] [epoch time: 0.06]\n",
      "8200 [D loss: 0.755939, acc.: 39.06%] [G loss: 0.784534] [epoch time: 0.05]\n",
      "8400 [D loss: 0.737032, acc.: 43.75%] [G loss: 0.787152] [epoch time: 0.09]\n",
      "8600 [D loss: 0.732280, acc.: 43.75%] [G loss: 0.749667] [epoch time: 0.06]\n",
      "8800 [D loss: 0.721152, acc.: 50.78%] [G loss: 0.765130] [epoch time: 0.05]\n",
      "9000 [D loss: 0.704493, acc.: 49.22%] [G loss: 0.755664] [epoch time: 0.09]\n",
      "9200 [D loss: 0.745670, acc.: 44.53%] [G loss: 0.768211] [epoch time: 0.06]\n",
      "9400 [D loss: 0.682769, acc.: 53.91%] [G loss: 0.755040] [epoch time: 0.05]\n",
      "9600 [D loss: 0.741930, acc.: 45.31%] [G loss: 0.809562] [epoch time: 0.09]\n",
      "9800 [D loss: 0.721903, acc.: 48.44%] [G loss: 0.737404] [epoch time: 0.05]\n",
      "10000 [D loss: 0.729444, acc.: 43.75%] [G loss: 0.803201] [epoch time: 0.05]\n",
      "10200 [D loss: 0.708782, acc.: 48.44%] [G loss: 0.751964] [epoch time: 0.09]\n",
      "10400 [D loss: 0.723033, acc.: 42.19%] [G loss: 0.746964] [epoch time: 0.06]\n",
      "10600 [D loss: 0.729871, acc.: 43.75%] [G loss: 0.752502] [epoch time: 0.05]\n",
      "10800 [D loss: 0.703825, acc.: 49.22%] [G loss: 0.714446] [epoch time: 0.09]\n",
      "11000 [D loss: 0.750717, acc.: 37.50%] [G loss: 0.740355] [epoch time: 0.06]\n",
      "11200 [D loss: 0.706895, acc.: 51.56%] [G loss: 0.739058] [epoch time: 0.05]\n",
      "11400 [D loss: 0.719198, acc.: 45.31%] [G loss: 0.751121] [epoch time: 0.09]\n",
      "11600 [D loss: 0.719761, acc.: 50.00%] [G loss: 0.748225] [epoch time: 0.06]\n",
      "11800 [D loss: 0.689872, acc.: 50.78%] [G loss: 0.762818] [epoch time: 0.05]\n",
      "12000 [D loss: 0.707092, acc.: 53.91%] [G loss: 0.771760] [epoch time: 0.08]\n",
      "12200 [D loss: 0.727958, acc.: 41.41%] [G loss: 0.756705] [epoch time: 0.06]\n",
      "12400 [D loss: 0.744443, acc.: 39.06%] [G loss: 0.780219] [epoch time: 0.05]\n",
      "12600 [D loss: 0.743480, acc.: 37.50%] [G loss: 0.705309] [epoch time: 0.09]\n",
      "12800 [D loss: 0.737758, acc.: 39.84%] [G loss: 0.744898] [epoch time: 0.06]\n",
      "13000 [D loss: 0.697260, acc.: 50.00%] [G loss: 0.774872] [epoch time: 0.05]\n",
      "13200 [D loss: 0.729430, acc.: 39.06%] [G loss: 0.724750] [epoch time: 0.09]\n",
      "13400 [D loss: 0.713523, acc.: 50.78%] [G loss: 0.760984] [epoch time: 0.06]\n",
      "13600 [D loss: 0.730215, acc.: 40.62%] [G loss: 0.727406] [epoch time: 0.05]\n",
      "13800 [D loss: 0.711500, acc.: 44.53%] [G loss: 0.810451] [epoch time: 0.09]\n",
      "14000 [D loss: 0.735988, acc.: 42.19%] [G loss: 0.719846] [epoch time: 0.06]\n",
      "14200 [D loss: 0.735962, acc.: 42.19%] [G loss: 0.725661] [epoch time: 0.05]\n",
      "14400 [D loss: 0.706281, acc.: 47.66%] [G loss: 0.774168] [epoch time: 0.09]\n",
      "14600 [D loss: 0.730382, acc.: 43.75%] [G loss: 0.706256] [epoch time: 0.06]\n",
      "14800 [D loss: 0.697598, acc.: 55.47%] [G loss: 0.722058] [epoch time: 0.05]\n",
      "15000 [D loss: 0.705569, acc.: 43.75%] [G loss: 0.767655] [epoch time: 0.09]\n",
      "15200 [D loss: 0.721808, acc.: 44.53%] [G loss: 0.717920] [epoch time: 0.06]\n",
      "15400 [D loss: 0.686966, acc.: 50.00%] [G loss: 0.728316] [epoch time: 0.05]\n",
      "15600 [D loss: 0.727907, acc.: 39.06%] [G loss: 0.738843] [epoch time: 0.09]\n",
      "15800 [D loss: 0.730439, acc.: 37.50%] [G loss: 0.762911] [epoch time: 0.05]\n",
      "16000 [D loss: 0.698850, acc.: 47.66%] [G loss: 0.729510] [epoch time: 0.05]\n",
      "16200 [D loss: 0.739443, acc.: 32.81%] [G loss: 0.761079] [epoch time: 0.09]\n",
      "16400 [D loss: 0.715798, acc.: 46.09%] [G loss: 0.742180] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.710979, acc.: 42.97%] [G loss: 0.724769] [epoch time: 0.05]\n",
      "16800 [D loss: 0.719630, acc.: 43.75%] [G loss: 0.751356] [epoch time: 0.09]\n",
      "17000 [D loss: 0.705509, acc.: 44.53%] [G loss: 0.721109] [epoch time: 0.06]\n",
      "17200 [D loss: 0.737238, acc.: 37.50%] [G loss: 0.729695] [epoch time: 0.05]\n",
      "17400 [D loss: 0.709872, acc.: 46.09%] [G loss: 0.700496] [epoch time: 0.09]\n",
      "17600 [D loss: 0.720067, acc.: 43.75%] [G loss: 0.704667] [epoch time: 0.06]\n",
      "17800 [D loss: 0.691556, acc.: 54.69%] [G loss: 0.745458] [epoch time: 0.05]\n",
      "18000 [D loss: 0.710656, acc.: 50.00%] [G loss: 0.705413] [epoch time: 0.09]\n",
      "18200 [D loss: 0.705431, acc.: 47.66%] [G loss: 0.738933] [epoch time: 0.06]\n",
      "18400 [D loss: 0.716108, acc.: 47.66%] [G loss: 0.737580] [epoch time: 0.05]\n",
      "18600 [D loss: 0.710208, acc.: 48.44%] [G loss: 0.760697] [epoch time: 0.09]\n",
      "18800 [D loss: 0.717026, acc.: 42.19%] [G loss: 0.758974] [epoch time: 0.06]\n",
      "19000 [D loss: 0.729214, acc.: 42.19%] [G loss: 0.733059] [epoch time: 0.05]\n",
      "19200 [D loss: 0.733966, acc.: 34.38%] [G loss: 0.746015] [epoch time: 0.09]\n",
      "19400 [D loss: 0.711853, acc.: 46.09%] [G loss: 0.698511] [epoch time: 0.05]\n",
      "19600 [D loss: 0.706050, acc.: 46.88%] [G loss: 0.733080] [epoch time: 0.05]\n",
      "19800 [D loss: 0.731649, acc.: 39.06%] [G loss: 0.726522] [epoch time: 0.09]\n",
      "20000 [D loss: 0.716619, acc.: 42.97%] [G loss: 0.746385] [epoch time: 0.06]\n",
      "elapsed training time: 22 min, 16 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.247760, acc.: 25.78%] [G loss: 0.572059] [epoch time: 5.88]\n",
      "200 [D loss: 0.996144, acc.: 38.28%] [G loss: 0.928915] [epoch time: 0.08]\n",
      "400 [D loss: 0.867148, acc.: 40.62%] [G loss: 0.988313] [epoch time: 0.08]\n",
      "600 [D loss: 0.794805, acc.: 47.66%] [G loss: 1.022734] [epoch time: 0.08]\n",
      "800 [D loss: 0.744598, acc.: 51.56%] [G loss: 0.961948] [epoch time: 0.08]\n",
      "1000 [D loss: 0.744965, acc.: 52.34%] [G loss: 0.989007] [epoch time: 0.09]\n",
      "1200 [D loss: 0.711671, acc.: 49.22%] [G loss: 0.954386] [epoch time: 0.08]\n",
      "1400 [D loss: 0.759895, acc.: 50.00%] [G loss: 0.966325] [epoch time: 0.08]\n",
      "1600 [D loss: 0.742012, acc.: 52.34%] [G loss: 0.958941] [epoch time: 0.08]\n",
      "1800 [D loss: 0.768945, acc.: 46.09%] [G loss: 0.934438] [epoch time: 0.09]\n",
      "2000 [D loss: 0.688627, acc.: 57.03%] [G loss: 0.872012] [epoch time: 0.09]\n",
      "2200 [D loss: 0.733515, acc.: 48.44%] [G loss: 0.844445] [epoch time: 0.08]\n",
      "2400 [D loss: 0.768744, acc.: 41.41%] [G loss: 0.844207] [epoch time: 0.09]\n",
      "2600 [D loss: 0.694740, acc.: 57.03%] [G loss: 0.780627] [epoch time: 0.09]\n",
      "2800 [D loss: 0.690929, acc.: 53.91%] [G loss: 0.840048] [epoch time: 0.08]\n",
      "3000 [D loss: 0.693341, acc.: 53.91%] [G loss: 0.871839] [epoch time: 0.08]\n",
      "3200 [D loss: 0.716807, acc.: 50.78%] [G loss: 0.906221] [epoch time: 0.09]\n",
      "3400 [D loss: 0.721322, acc.: 51.56%] [G loss: 0.818971] [epoch time: 0.08]\n",
      "3600 [D loss: 0.725181, acc.: 46.88%] [G loss: 0.804041] [epoch time: 0.08]\n",
      "3800 [D loss: 0.718387, acc.: 49.22%] [G loss: 0.826123] [epoch time: 0.09]\n",
      "4000 [D loss: 0.724000, acc.: 55.47%] [G loss: 0.819738] [epoch time: 0.09]\n",
      "4200 [D loss: 0.704752, acc.: 52.34%] [G loss: 0.878084] [epoch time: 0.08]\n",
      "4400 [D loss: 0.723498, acc.: 52.34%] [G loss: 0.757558] [epoch time: 0.08]\n",
      "4600 [D loss: 0.736139, acc.: 51.56%] [G loss: 0.862819] [epoch time: 0.08]\n",
      "4800 [D loss: 0.678888, acc.: 55.47%] [G loss: 0.909430] [epoch time: 0.09]\n",
      "5000 [D loss: 0.755392, acc.: 46.09%] [G loss: 0.789528] [epoch time: 0.08]\n",
      "5200 [D loss: 0.753147, acc.: 46.88%] [G loss: 0.837195] [epoch time: 0.08]\n",
      "5400 [D loss: 0.730835, acc.: 46.88%] [G loss: 0.809293] [epoch time: 0.08]\n",
      "5600 [D loss: 0.679964, acc.: 59.38%] [G loss: 0.819144] [epoch time: 0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 [D loss: 0.722839, acc.: 48.44%] [G loss: 0.877461] [epoch time: 0.08]\n",
      "6000 [D loss: 0.684932, acc.: 54.69%] [G loss: 0.828190] [epoch time: 0.08]\n",
      "6200 [D loss: 0.666680, acc.: 59.38%] [G loss: 0.796255] [epoch time: 0.08]\n",
      "6400 [D loss: 0.716506, acc.: 52.34%] [G loss: 0.831496] [epoch time: 0.08]\n",
      "6600 [D loss: 0.714690, acc.: 50.78%] [G loss: 0.765954] [epoch time: 0.08]\n",
      "6800 [D loss: 0.710444, acc.: 47.66%] [G loss: 0.853668] [epoch time: 0.08]\n",
      "7000 [D loss: 0.706361, acc.: 49.22%] [G loss: 0.769446] [epoch time: 0.08]\n",
      "7200 [D loss: 0.694693, acc.: 50.78%] [G loss: 0.813298] [epoch time: 0.08]\n",
      "7400 [D loss: 0.719565, acc.: 53.12%] [G loss: 0.839168] [epoch time: 0.08]\n",
      "7600 [D loss: 0.707710, acc.: 50.00%] [G loss: 0.772770] [epoch time: 0.08]\n",
      "7800 [D loss: 0.733787, acc.: 43.75%] [G loss: 0.706316] [epoch time: 0.08]\n",
      "8000 [D loss: 0.727664, acc.: 39.84%] [G loss: 0.785847] [epoch time: 0.08]\n",
      "8200 [D loss: 0.723152, acc.: 42.97%] [G loss: 0.759234] [epoch time: 0.08]\n",
      "8400 [D loss: 0.723636, acc.: 46.09%] [G loss: 0.798466] [epoch time: 0.08]\n",
      "8600 [D loss: 0.728046, acc.: 40.62%] [G loss: 0.769529] [epoch time: 0.08]\n",
      "8800 [D loss: 0.710623, acc.: 50.00%] [G loss: 0.814334] [epoch time: 0.08]\n",
      "9000 [D loss: 0.722516, acc.: 49.22%] [G loss: 0.772382] [epoch time: 0.08]\n",
      "9200 [D loss: 0.733430, acc.: 49.22%] [G loss: 0.775194] [epoch time: 0.08]\n",
      "9400 [D loss: 0.722721, acc.: 46.88%] [G loss: 0.770887] [epoch time: 0.08]\n",
      "9600 [D loss: 0.707869, acc.: 50.00%] [G loss: 0.757316] [epoch time: 0.08]\n",
      "9800 [D loss: 0.714845, acc.: 53.12%] [G loss: 0.794725] [epoch time: 0.08]\n",
      "10000 [D loss: 0.739653, acc.: 44.53%] [G loss: 0.762847] [epoch time: 0.08]\n",
      "10200 [D loss: 0.701586, acc.: 46.88%] [G loss: 0.776552] [epoch time: 0.08]\n",
      "10400 [D loss: 0.726489, acc.: 42.19%] [G loss: 0.765148] [epoch time: 0.09]\n",
      "10600 [D loss: 0.729627, acc.: 41.41%] [G loss: 0.793879] [epoch time: 0.08]\n",
      "10800 [D loss: 0.719211, acc.: 45.31%] [G loss: 0.729778] [epoch time: 0.08]\n",
      "11000 [D loss: 0.707656, acc.: 55.47%] [G loss: 0.746906] [epoch time: 0.08]\n",
      "11200 [D loss: 0.708587, acc.: 51.56%] [G loss: 0.739199] [epoch time: 0.08]\n",
      "11400 [D loss: 0.704212, acc.: 50.00%] [G loss: 0.734010] [epoch time: 0.08]\n",
      "11600 [D loss: 0.720366, acc.: 45.31%] [G loss: 0.755189] [epoch time: 0.08]\n",
      "11800 [D loss: 0.716751, acc.: 45.31%] [G loss: 0.773930] [epoch time: 0.08]\n",
      "12000 [D loss: 0.713230, acc.: 50.00%] [G loss: 0.739681] [epoch time: 0.08]\n",
      "12200 [D loss: 0.725606, acc.: 50.00%] [G loss: 0.771410] [epoch time: 0.08]\n",
      "12400 [D loss: 0.729356, acc.: 44.53%] [G loss: 0.760581] [epoch time: 0.08]\n",
      "12600 [D loss: 0.706120, acc.: 50.00%] [G loss: 0.754912] [epoch time: 0.09]\n",
      "12800 [D loss: 0.719691, acc.: 51.56%] [G loss: 0.787957] [epoch time: 0.08]\n",
      "13000 [D loss: 0.720068, acc.: 42.19%] [G loss: 0.754025] [epoch time: 0.08]\n",
      "13200 [D loss: 0.686020, acc.: 56.25%] [G loss: 0.766033] [epoch time: 0.08]\n",
      "13400 [D loss: 0.690105, acc.: 51.56%] [G loss: 0.808177] [epoch time: 0.08]\n",
      "13600 [D loss: 0.730670, acc.: 42.19%] [G loss: 0.737009] [epoch time: 0.08]\n",
      "13800 [D loss: 0.718870, acc.: 42.19%] [G loss: 0.752899] [epoch time: 0.08]\n",
      "14000 [D loss: 0.719314, acc.: 46.09%] [G loss: 0.755985] [epoch time: 0.08]\n",
      "14200 [D loss: 0.728879, acc.: 42.97%] [G loss: 0.732399] [epoch time: 0.08]\n",
      "14400 [D loss: 0.691506, acc.: 52.34%] [G loss: 0.761161] [epoch time: 0.08]\n",
      "14600 [D loss: 0.736808, acc.: 38.28%] [G loss: 0.714607] [epoch time: 0.08]\n",
      "14800 [D loss: 0.691882, acc.: 55.47%] [G loss: 0.769674] [epoch time: 0.08]\n",
      "15000 [D loss: 0.695328, acc.: 48.44%] [G loss: 0.729265] [epoch time: 0.08]\n",
      "15200 [D loss: 0.715353, acc.: 46.09%] [G loss: 0.742753] [epoch time: 0.08]\n",
      "15400 [D loss: 0.702145, acc.: 46.88%] [G loss: 0.735919] [epoch time: 0.08]\n",
      "15600 [D loss: 0.693126, acc.: 53.12%] [G loss: 0.800314] [epoch time: 0.08]\n",
      "15800 [D loss: 0.700660, acc.: 47.66%] [G loss: 0.726770] [epoch time: 0.08]\n",
      "16000 [D loss: 0.687481, acc.: 46.09%] [G loss: 0.758822] [epoch time: 0.08]\n",
      "16200 [D loss: 0.702144, acc.: 49.22%] [G loss: 0.747718] [epoch time: 0.08]\n",
      "16400 [D loss: 0.714519, acc.: 46.88%] [G loss: 0.760050] [epoch time: 0.08]\n",
      "16600 [D loss: 0.697211, acc.: 54.69%] [G loss: 0.767840] [epoch time: 0.09]\n",
      "16800 [D loss: 0.707096, acc.: 47.66%] [G loss: 0.747057] [epoch time: 0.08]\n",
      "17000 [D loss: 0.717783, acc.: 44.53%] [G loss: 0.723302] [epoch time: 0.09]\n",
      "17200 [D loss: 0.698573, acc.: 50.00%] [G loss: 0.745041] [epoch time: 0.08]\n",
      "17400 [D loss: 0.695752, acc.: 47.66%] [G loss: 0.768821] [epoch time: 0.08]\n",
      "17600 [D loss: 0.689573, acc.: 56.25%] [G loss: 0.777384] [epoch time: 0.08]\n",
      "17800 [D loss: 0.718181, acc.: 39.84%] [G loss: 0.714274] [epoch time: 0.08]\n",
      "18000 [D loss: 0.703900, acc.: 50.00%] [G loss: 0.769213] [epoch time: 0.08]\n",
      "18200 [D loss: 0.701955, acc.: 50.00%] [G loss: 0.747119] [epoch time: 0.08]\n",
      "18400 [D loss: 0.724239, acc.: 43.75%] [G loss: 0.778866] [epoch time: 0.08]\n",
      "18600 [D loss: 0.702904, acc.: 55.47%] [G loss: 0.746472] [epoch time: 0.08]\n",
      "18800 [D loss: 0.730385, acc.: 42.19%] [G loss: 0.710187] [epoch time: 0.08]\n",
      "19000 [D loss: 0.689256, acc.: 54.69%] [G loss: 0.768059] [epoch time: 0.08]\n",
      "19200 [D loss: 0.705255, acc.: 45.31%] [G loss: 0.727368] [epoch time: 0.08]\n",
      "19400 [D loss: 0.705304, acc.: 46.88%] [G loss: 0.741665] [epoch time: 0.08]\n",
      "19600 [D loss: 0.714446, acc.: 47.66%] [G loss: 0.764854] [epoch time: 0.08]\n",
      "19800 [D loss: 0.696952, acc.: 54.69%] [G loss: 0.766431] [epoch time: 0.08]\n",
      "20000 [D loss: 0.709966, acc.: 50.78%] [G loss: 0.712176] [epoch time: 0.08]\n",
      "elapsed training time: 23 min, 39 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.096850, acc.: 28.12%] [G loss: 1.074914] [epoch time: 6.68]\n",
      "200 [D loss: 1.096490, acc.: 33.59%] [G loss: 1.387902] [epoch time: 0.09]\n",
      "400 [D loss: 0.995145, acc.: 35.94%] [G loss: 1.224740] [epoch time: 0.08]\n",
      "600 [D loss: 1.027714, acc.: 34.38%] [G loss: 1.213097] [epoch time: 0.08]\n",
      "800 [D loss: 0.942465, acc.: 40.62%] [G loss: 1.146537] [epoch time: 0.08]\n",
      "1000 [D loss: 1.070365, acc.: 25.78%] [G loss: 1.010962] [epoch time: 0.08]\n",
      "1200 [D loss: 0.979192, acc.: 28.91%] [G loss: 0.964872] [epoch time: 0.08]\n",
      "1400 [D loss: 0.898754, acc.: 39.84%] [G loss: 1.007191] [epoch time: 0.08]\n",
      "1600 [D loss: 0.908892, acc.: 32.81%] [G loss: 1.056762] [epoch time: 0.08]\n",
      "1800 [D loss: 0.840342, acc.: 42.97%] [G loss: 1.032580] [epoch time: 0.08]\n",
      "2000 [D loss: 0.854740, acc.: 44.53%] [G loss: 1.003434] [epoch time: 0.08]\n",
      "2200 [D loss: 0.857528, acc.: 36.72%] [G loss: 0.900476] [epoch time: 0.09]\n",
      "2400 [D loss: 0.882006, acc.: 37.50%] [G loss: 1.080325] [epoch time: 0.08]\n",
      "2600 [D loss: 0.799173, acc.: 47.66%] [G loss: 0.916638] [epoch time: 0.08]\n",
      "2800 [D loss: 0.757798, acc.: 45.31%] [G loss: 0.926869] [epoch time: 0.08]\n",
      "3000 [D loss: 0.839179, acc.: 42.19%] [G loss: 0.974689] [epoch time: 0.08]\n",
      "3200 [D loss: 0.865295, acc.: 39.06%] [G loss: 0.966201] [epoch time: 0.08]\n",
      "3400 [D loss: 0.797269, acc.: 40.62%] [G loss: 0.910141] [epoch time: 0.08]\n",
      "3600 [D loss: 0.832854, acc.: 36.72%] [G loss: 0.941158] [epoch time: 0.08]\n",
      "3800 [D loss: 0.809008, acc.: 43.75%] [G loss: 0.852159] [epoch time: 0.08]\n",
      "4000 [D loss: 0.751144, acc.: 49.22%] [G loss: 0.861895] [epoch time: 0.08]\n",
      "4200 [D loss: 0.848380, acc.: 33.59%] [G loss: 0.889469] [epoch time: 0.09]\n",
      "4400 [D loss: 0.830050, acc.: 35.94%] [G loss: 0.810495] [epoch time: 0.08]\n",
      "4600 [D loss: 0.788985, acc.: 41.41%] [G loss: 1.023943] [epoch time: 0.09]\n",
      "4800 [D loss: 0.786850, acc.: 41.41%] [G loss: 0.821819] [epoch time: 0.08]\n",
      "5000 [D loss: 0.810054, acc.: 39.06%] [G loss: 0.814810] [epoch time: 0.08]\n",
      "5200 [D loss: 0.759953, acc.: 45.31%] [G loss: 0.881770] [epoch time: 0.09]\n",
      "5400 [D loss: 0.818481, acc.: 42.19%] [G loss: 0.795691] [epoch time: 0.08]\n",
      "5600 [D loss: 0.806390, acc.: 39.84%] [G loss: 0.766542] [epoch time: 0.08]\n",
      "5800 [D loss: 0.809305, acc.: 42.19%] [G loss: 0.819427] [epoch time: 0.08]\n",
      "6000 [D loss: 0.782457, acc.: 42.97%] [G loss: 0.771773] [epoch time: 0.08]\n",
      "6200 [D loss: 0.726864, acc.: 52.34%] [G loss: 0.762426] [epoch time: 0.09]\n",
      "6400 [D loss: 0.760368, acc.: 42.19%] [G loss: 0.833900] [epoch time: 0.09]\n",
      "6600 [D loss: 0.745865, acc.: 45.31%] [G loss: 0.800444] [epoch time: 0.08]\n",
      "6800 [D loss: 0.784372, acc.: 42.97%] [G loss: 0.856294] [epoch time: 0.09]\n",
      "7000 [D loss: 0.755829, acc.: 40.62%] [G loss: 0.892795] [epoch time: 0.08]\n",
      "7200 [D loss: 0.734564, acc.: 50.78%] [G loss: 0.782540] [epoch time: 0.08]\n",
      "7400 [D loss: 0.741276, acc.: 46.88%] [G loss: 0.915294] [epoch time: 0.08]\n",
      "7600 [D loss: 0.770799, acc.: 48.44%] [G loss: 0.779276] [epoch time: 0.08]\n",
      "7800 [D loss: 0.772577, acc.: 40.62%] [G loss: 0.798192] [epoch time: 0.09]\n",
      "8000 [D loss: 0.789244, acc.: 43.75%] [G loss: 0.816568] [epoch time: 0.09]\n",
      "8200 [D loss: 0.768941, acc.: 39.06%] [G loss: 0.860323] [epoch time: 0.08]\n",
      "8400 [D loss: 0.807894, acc.: 42.19%] [G loss: 0.773138] [epoch time: 0.09]\n",
      "8600 [D loss: 0.775985, acc.: 39.06%] [G loss: 0.756376] [epoch time: 0.08]\n",
      "8800 [D loss: 0.758229, acc.: 43.75%] [G loss: 0.829868] [epoch time: 0.08]\n",
      "9000 [D loss: 0.760225, acc.: 42.19%] [G loss: 0.789961] [epoch time: 0.08]\n",
      "9200 [D loss: 0.770195, acc.: 43.75%] [G loss: 0.769595] [epoch time: 0.09]\n",
      "9400 [D loss: 0.796288, acc.: 35.94%] [G loss: 0.770883] [epoch time: 0.09]\n",
      "9600 [D loss: 0.813669, acc.: 32.81%] [G loss: 0.777764] [epoch time: 0.09]\n",
      "9800 [D loss: 0.811944, acc.: 32.03%] [G loss: 0.732544] [epoch time: 0.09]\n",
      "10000 [D loss: 0.738216, acc.: 46.09%] [G loss: 0.777186] [epoch time: 0.08]\n",
      "10200 [D loss: 0.760451, acc.: 37.50%] [G loss: 0.782090] [epoch time: 0.09]\n",
      "10400 [D loss: 0.730194, acc.: 48.44%] [G loss: 0.783893] [epoch time: 0.08]\n",
      "10600 [D loss: 0.723087, acc.: 50.00%] [G loss: 0.756770] [epoch time: 0.08]\n",
      "10800 [D loss: 0.767194, acc.: 40.62%] [G loss: 0.820760] [epoch time: 0.08]\n",
      "11000 [D loss: 0.772445, acc.: 40.62%] [G loss: 0.791106] [epoch time: 0.08]\n",
      "11200 [D loss: 0.787320, acc.: 40.62%] [G loss: 0.796505] [epoch time: 0.08]\n",
      "11400 [D loss: 0.761811, acc.: 36.72%] [G loss: 0.716570] [epoch time: 0.08]\n",
      "11600 [D loss: 0.731563, acc.: 43.75%] [G loss: 0.859429] [epoch time: 0.08]\n",
      "11800 [D loss: 0.734584, acc.: 41.41%] [G loss: 0.806348] [epoch time: 0.08]\n",
      "12000 [D loss: 0.749841, acc.: 42.19%] [G loss: 0.747113] [epoch time: 0.09]\n",
      "12200 [D loss: 0.757361, acc.: 41.41%] [G loss: 0.773553] [epoch time: 0.08]\n",
      "12400 [D loss: 0.758004, acc.: 42.19%] [G loss: 0.766200] [epoch time: 0.08]\n",
      "12600 [D loss: 0.784456, acc.: 35.94%] [G loss: 0.767150] [epoch time: 0.08]\n",
      "12800 [D loss: 0.760231, acc.: 38.28%] [G loss: 0.742866] [epoch time: 0.08]\n",
      "13000 [D loss: 0.744956, acc.: 43.75%] [G loss: 0.736668] [epoch time: 0.08]\n",
      "13200 [D loss: 0.758947, acc.: 45.31%] [G loss: 0.811658] [epoch time: 0.08]\n",
      "13400 [D loss: 0.745258, acc.: 44.53%] [G loss: 0.766914] [epoch time: 0.08]\n",
      "13600 [D loss: 0.765339, acc.: 40.62%] [G loss: 0.781121] [epoch time: 0.08]\n",
      "13800 [D loss: 0.767715, acc.: 38.28%] [G loss: 0.763229] [epoch time: 0.08]\n",
      "14000 [D loss: 0.746866, acc.: 39.06%] [G loss: 0.783578] [epoch time: 0.09]\n",
      "14200 [D loss: 0.749344, acc.: 46.88%] [G loss: 0.797777] [epoch time: 0.08]\n",
      "14400 [D loss: 0.761672, acc.: 43.75%] [G loss: 0.799279] [epoch time: 0.08]\n",
      "14600 [D loss: 0.729842, acc.: 49.22%] [G loss: 0.746563] [epoch time: 0.08]\n",
      "14800 [D loss: 0.765499, acc.: 39.84%] [G loss: 0.749761] [epoch time: 0.08]\n",
      "15000 [D loss: 0.724902, acc.: 45.31%] [G loss: 0.753438] [epoch time: 0.08]\n",
      "15200 [D loss: 0.743545, acc.: 45.31%] [G loss: 0.826024] [epoch time: 0.08]\n",
      "15400 [D loss: 0.768182, acc.: 35.16%] [G loss: 0.782175] [epoch time: 0.08]\n",
      "15600 [D loss: 0.730867, acc.: 42.97%] [G loss: 0.716191] [epoch time: 0.08]\n",
      "15800 [D loss: 0.733172, acc.: 45.31%] [G loss: 0.765085] [epoch time: 0.08]\n",
      "16000 [D loss: 0.748437, acc.: 43.75%] [G loss: 0.762756] [epoch time: 0.09]\n",
      "16200 [D loss: 0.757089, acc.: 42.97%] [G loss: 0.782109] [epoch time: 0.09]\n",
      "16400 [D loss: 0.753294, acc.: 39.84%] [G loss: 0.769075] [epoch time: 0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.760490, acc.: 35.94%] [G loss: 0.737926] [epoch time: 0.08]\n",
      "16800 [D loss: 0.763631, acc.: 39.84%] [G loss: 0.754189] [epoch time: 0.08]\n",
      "17000 [D loss: 0.731065, acc.: 44.53%] [G loss: 0.765585] [epoch time: 0.08]\n",
      "17200 [D loss: 0.756153, acc.: 40.62%] [G loss: 0.757754] [epoch time: 0.08]\n",
      "17400 [D loss: 0.706992, acc.: 50.00%] [G loss: 0.742817] [epoch time: 0.09]\n",
      "17600 [D loss: 0.746555, acc.: 42.97%] [G loss: 0.751473] [epoch time: 0.08]\n",
      "17800 [D loss: 0.757543, acc.: 33.59%] [G loss: 0.742291] [epoch time: 0.08]\n",
      "18000 [D loss: 0.751359, acc.: 32.03%] [G loss: 0.776199] [epoch time: 0.08]\n",
      "18200 [D loss: 0.720358, acc.: 49.22%] [G loss: 0.768896] [epoch time: 0.08]\n",
      "18400 [D loss: 0.768546, acc.: 35.94%] [G loss: 0.763355] [epoch time: 0.08]\n",
      "18600 [D loss: 0.705022, acc.: 54.69%] [G loss: 0.751350] [epoch time: 0.08]\n",
      "18800 [D loss: 0.772249, acc.: 35.16%] [G loss: 0.800243] [epoch time: 0.09]\n",
      "19000 [D loss: 0.738285, acc.: 37.50%] [G loss: 0.804371] [epoch time: 0.09]\n",
      "19200 [D loss: 0.735552, acc.: 45.31%] [G loss: 0.780993] [epoch time: 0.08]\n",
      "19400 [D loss: 0.768982, acc.: 32.81%] [G loss: 0.765051] [epoch time: 0.08]\n",
      "19600 [D loss: 0.755733, acc.: 37.50%] [G loss: 0.731044] [epoch time: 0.08]\n",
      "19800 [D loss: 0.724813, acc.: 47.66%] [G loss: 0.742088] [epoch time: 0.09]\n",
      "20000 [D loss: 0.762076, acc.: 40.62%] [G loss: 0.750780] [epoch time: 0.09]\n",
      "elapsed training time: 20 min, 34 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.173789, acc.: 27.34%] [G loss: 0.950134] [epoch time: 7.37]\n",
      "200 [D loss: 0.041281, acc.: 98.44%] [G loss: 1.067889] [epoch time: 0.08]\n",
      "400 [D loss: 0.551486, acc.: 71.09%] [G loss: 0.160695] [epoch time: 0.08]\n",
      "600 [D loss: 0.024062, acc.: 100.00%] [G loss: 0.211711] [epoch time: 0.08]\n",
      "800 [D loss: 0.035945, acc.: 100.00%] [G loss: 1.920975] [epoch time: 0.08]\n",
      "1000 [D loss: 0.153287, acc.: 97.66%] [G loss: 1.363699] [epoch time: 0.08]\n",
      "1200 [D loss: 0.526325, acc.: 73.44%] [G loss: 0.362346] [epoch time: 0.08]\n",
      "1400 [D loss: 0.600911, acc.: 66.41%] [G loss: 1.698573] [epoch time: 0.08]\n",
      "1600 [D loss: 0.385518, acc.: 84.38%] [G loss: 2.271150] [epoch time: 0.08]\n",
      "1800 [D loss: 0.136365, acc.: 98.44%] [G loss: 1.397987] [epoch time: 0.08]\n",
      "2000 [D loss: 0.093175, acc.: 99.22%] [G loss: 1.071032] [epoch time: 0.08]\n",
      "2200 [D loss: 0.256949, acc.: 92.97%] [G loss: 1.432802] [epoch time: 0.08]\n",
      "2400 [D loss: 0.397736, acc.: 81.25%] [G loss: 1.612908] [epoch time: 0.08]\n",
      "2600 [D loss: 0.466496, acc.: 78.12%] [G loss: 1.791970] [epoch time: 0.08]\n",
      "2800 [D loss: 0.427518, acc.: 79.69%] [G loss: 2.419193] [epoch time: 0.08]\n",
      "3000 [D loss: 0.485338, acc.: 74.22%] [G loss: 2.269349] [epoch time: 0.08]\n",
      "3200 [D loss: 0.531289, acc.: 74.22%] [G loss: 1.272002] [epoch time: 0.08]\n",
      "3400 [D loss: 0.386605, acc.: 82.81%] [G loss: 2.101432] [epoch time: 0.08]\n",
      "3600 [D loss: 0.140240, acc.: 99.22%] [G loss: 1.655995] [epoch time: 0.08]\n",
      "3800 [D loss: 0.349317, acc.: 84.38%] [G loss: 3.172929] [epoch time: 0.08]\n",
      "4000 [D loss: 0.288265, acc.: 92.19%] [G loss: 3.605827] [epoch time: 0.08]\n",
      "4200 [D loss: 0.659509, acc.: 59.38%] [G loss: 2.350591] [epoch time: 0.08]\n",
      "4400 [D loss: 0.083747, acc.: 100.00%] [G loss: 3.492569] [epoch time: 0.08]\n",
      "4600 [D loss: 0.159400, acc.: 98.44%] [G loss: 2.958954] [epoch time: 0.08]\n",
      "4800 [D loss: 0.197867, acc.: 94.53%] [G loss: 3.818738] [epoch time: 0.08]\n",
      "5000 [D loss: 0.445754, acc.: 77.34%] [G loss: 3.550368] [epoch time: 0.08]\n",
      "5200 [D loss: 0.259922, acc.: 90.62%] [G loss: 2.227768] [epoch time: 0.08]\n",
      "5400 [D loss: 0.051513, acc.: 100.00%] [G loss: 4.508044] [epoch time: 0.08]\n",
      "5600 [D loss: 0.609100, acc.: 70.31%] [G loss: 3.160340] [epoch time: 0.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 [D loss: 0.216571, acc.: 92.19%] [G loss: 4.029155] [epoch time: 0.08]\n",
      "6000 [D loss: 0.036145, acc.: 100.00%] [G loss: 5.333659] [epoch time: 0.08]\n",
      "6200 [D loss: 0.457286, acc.: 76.56%] [G loss: 3.282429] [epoch time: 0.08]\n",
      "6400 [D loss: 0.185234, acc.: 93.75%] [G loss: 4.230646] [epoch time: 0.08]\n",
      "6600 [D loss: 0.138591, acc.: 95.31%] [G loss: 3.158509] [epoch time: 0.08]\n",
      "6800 [D loss: 0.326813, acc.: 85.16%] [G loss: 2.521412] [epoch time: 0.08]\n",
      "7000 [D loss: 0.183853, acc.: 92.19%] [G loss: 2.980062] [epoch time: 0.08]\n",
      "7200 [D loss: 0.116752, acc.: 97.66%] [G loss: 5.343913] [epoch time: 0.08]\n",
      "7400 [D loss: 0.099202, acc.: 98.44%] [G loss: 4.908726] [epoch time: 0.08]\n",
      "7600 [D loss: 0.023572, acc.: 100.00%] [G loss: 5.947902] [epoch time: 0.08]\n",
      "7800 [D loss: 0.037766, acc.: 100.00%] [G loss: 4.367404] [epoch time: 0.08]\n",
      "8000 [D loss: 0.104033, acc.: 99.22%] [G loss: 3.719856] [epoch time: 0.08]\n",
      "8200 [D loss: 0.126268, acc.: 95.31%] [G loss: 3.551684] [epoch time: 0.08]\n",
      "8400 [D loss: 0.046294, acc.: 100.00%] [G loss: 3.043314] [epoch time: 0.08]\n",
      "8600 [D loss: 0.122627, acc.: 96.88%] [G loss: 2.933137] [epoch time: 0.08]\n",
      "8800 [D loss: 0.019559, acc.: 100.00%] [G loss: 7.511353] [epoch time: 0.08]\n",
      "9000 [D loss: 0.467596, acc.: 76.56%] [G loss: 5.421585] [epoch time: 0.08]\n",
      "9200 [D loss: 0.115265, acc.: 97.66%] [G loss: 3.022111] [epoch time: 0.08]\n",
      "9400 [D loss: 0.042769, acc.: 100.00%] [G loss: 4.376412] [epoch time: 0.08]\n",
      "9600 [D loss: 0.129706, acc.: 96.09%] [G loss: 3.627053] [epoch time: 0.08]\n",
      "9800 [D loss: 0.072430, acc.: 97.66%] [G loss: 5.042071] [epoch time: 0.08]\n",
      "10000 [D loss: 0.040620, acc.: 100.00%] [G loss: 3.877426] [epoch time: 0.08]\n",
      "10200 [D loss: 0.053855, acc.: 100.00%] [G loss: 5.436683] [epoch time: 0.08]\n",
      "10400 [D loss: 0.063352, acc.: 99.22%] [G loss: 4.663062] [epoch time: 0.08]\n",
      "10600 [D loss: 0.008948, acc.: 100.00%] [G loss: 6.446187] [epoch time: 0.08]\n",
      "10800 [D loss: 0.191979, acc.: 95.31%] [G loss: 3.117776] [epoch time: 0.08]\n",
      "11000 [D loss: 0.067503, acc.: 99.22%] [G loss: 5.449679] [epoch time: 0.08]\n",
      "11200 [D loss: 0.103751, acc.: 95.31%] [G loss: 4.913091] [epoch time: 0.08]\n",
      "11400 [D loss: 0.011227, acc.: 100.00%] [G loss: 7.713404] [epoch time: 0.08]\n",
      "11600 [D loss: 0.120136, acc.: 98.44%] [G loss: 5.177663] [epoch time: 0.08]\n",
      "11800 [D loss: 0.242125, acc.: 87.50%] [G loss: 3.005136] [epoch time: 0.08]\n",
      "12000 [D loss: 0.029317, acc.: 99.22%] [G loss: 4.828873] [epoch time: 0.08]\n",
      "12200 [D loss: 0.048545, acc.: 98.44%] [G loss: 6.967980] [epoch time: 0.08]\n",
      "12400 [D loss: 0.009650, acc.: 100.00%] [G loss: 7.165219] [epoch time: 0.08]\n",
      "12600 [D loss: 0.012966, acc.: 100.00%] [G loss: 6.246383] [epoch time: 0.08]\n",
      "12800 [D loss: 0.061509, acc.: 98.44%] [G loss: 4.755124] [epoch time: 0.08]\n",
      "13000 [D loss: 0.013135, acc.: 100.00%] [G loss: 4.132714] [epoch time: 0.08]\n",
      "13200 [D loss: 0.036771, acc.: 99.22%] [G loss: 5.152984] [epoch time: 0.08]\n",
      "13400 [D loss: 0.025453, acc.: 100.00%] [G loss: 4.186843] [epoch time: 0.08]\n",
      "13600 [D loss: 0.009443, acc.: 100.00%] [G loss: 5.501567] [epoch time: 0.08]\n",
      "13800 [D loss: 0.007683, acc.: 100.00%] [G loss: 8.814184] [epoch time: 0.08]\n",
      "14000 [D loss: 0.034918, acc.: 100.00%] [G loss: 4.398733] [epoch time: 0.08]\n",
      "14200 [D loss: 0.062295, acc.: 97.66%] [G loss: 7.941184] [epoch time: 0.08]\n",
      "14400 [D loss: 0.014446, acc.: 100.00%] [G loss: 6.901535] [epoch time: 0.08]\n",
      "14600 [D loss: 0.102665, acc.: 96.88%] [G loss: 6.716616] [epoch time: 0.08]\n",
      "14800 [D loss: 0.095664, acc.: 98.44%] [G loss: 5.007065] [epoch time: 0.08]\n",
      "15000 [D loss: 0.092171, acc.: 97.66%] [G loss: 5.388015] [epoch time: 0.08]\n",
      "15200 [D loss: 0.009777, acc.: 100.00%] [G loss: 6.551803] [epoch time: 0.08]\n",
      "15400 [D loss: 0.012224, acc.: 100.00%] [G loss: 4.168412] [epoch time: 0.08]\n",
      "15600 [D loss: 0.358823, acc.: 85.16%] [G loss: 2.646043] [epoch time: 0.08]\n",
      "15800 [D loss: 0.099038, acc.: 97.66%] [G loss: 4.793054] [epoch time: 0.08]\n",
      "16000 [D loss: 0.047057, acc.: 99.22%] [G loss: 7.348523] [epoch time: 0.08]\n",
      "16200 [D loss: 0.080705, acc.: 96.88%] [G loss: 4.805623] [epoch time: 0.08]\n",
      "16400 [D loss: 0.013990, acc.: 100.00%] [G loss: 8.442093] [epoch time: 0.08]\n",
      "16600 [D loss: 0.142648, acc.: 93.75%] [G loss: 7.722595] [epoch time: 0.08]\n",
      "16800 [D loss: 0.021168, acc.: 100.00%] [G loss: 5.500090] [epoch time: 0.08]\n",
      "17000 [D loss: 0.167275, acc.: 95.31%] [G loss: 4.201541] [epoch time: 0.08]\n",
      "17200 [D loss: 0.162863, acc.: 94.53%] [G loss: 2.486617] [epoch time: 0.08]\n",
      "17400 [D loss: 0.004739, acc.: 100.00%] [G loss: 8.318016] [epoch time: 0.08]\n",
      "17600 [D loss: 0.015408, acc.: 100.00%] [G loss: 5.959994] [epoch time: 0.08]\n",
      "17800 [D loss: 0.111470, acc.: 98.44%] [G loss: 4.410182] [epoch time: 0.08]\n",
      "18000 [D loss: 0.056052, acc.: 98.44%] [G loss: 4.020304] [epoch time: 0.08]\n",
      "18200 [D loss: 0.038228, acc.: 99.22%] [G loss: 5.792257] [epoch time: 0.08]\n",
      "18400 [D loss: 0.016757, acc.: 100.00%] [G loss: 6.449482] [epoch time: 0.08]\n",
      "18600 [D loss: 0.011277, acc.: 100.00%] [G loss: 5.400466] [epoch time: 0.08]\n",
      "18800 [D loss: 0.221141, acc.: 88.28%] [G loss: 6.373772] [epoch time: 0.08]\n",
      "19000 [D loss: 0.212620, acc.: 93.75%] [G loss: 3.966104] [epoch time: 0.08]\n",
      "19200 [D loss: 0.104909, acc.: 95.31%] [G loss: 9.092480] [epoch time: 0.08]\n",
      "19400 [D loss: 0.067600, acc.: 98.44%] [G loss: 4.680977] [epoch time: 0.08]\n",
      "19600 [D loss: 0.057066, acc.: 96.88%] [G loss: 8.310422] [epoch time: 0.08]\n",
      "19800 [D loss: 0.011554, acc.: 100.00%] [G loss: 7.439604] [epoch time: 0.08]\n",
      "20000 [D loss: 0.242489, acc.: 86.72%] [G loss: 5.255831] [epoch time: 0.08]\n",
      "elapsed training time: 15 min, 11 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.821405, acc.: 41.41%] [G loss: 0.556790] [epoch time: 7.19]\n",
      "200 [D loss: 0.389461, acc.: 87.50%] [G loss: 1.461714] [epoch time: 0.04]\n",
      "400 [D loss: 0.075621, acc.: 98.44%] [G loss: 3.290173] [epoch time: 0.04]\n",
      "600 [D loss: 0.018307, acc.: 100.00%] [G loss: 4.597416] [epoch time: 0.04]\n",
      "800 [D loss: 0.006851, acc.: 100.00%] [G loss: 5.887719] [epoch time: 0.04]\n",
      "1000 [D loss: 0.005432, acc.: 100.00%] [G loss: 6.421815] [epoch time: 0.04]\n",
      "1200 [D loss: 0.004186, acc.: 100.00%] [G loss: 6.718071] [epoch time: 0.04]\n",
      "1400 [D loss: 0.000970, acc.: 100.00%] [G loss: 6.970044] [epoch time: 0.04]\n",
      "1600 [D loss: 0.000915, acc.: 100.00%] [G loss: 7.474401] [epoch time: 0.04]\n",
      "1800 [D loss: 0.000696, acc.: 100.00%] [G loss: 7.745823] [epoch time: 0.04]\n",
      "2000 [D loss: 0.000358, acc.: 100.00%] [G loss: 8.458976] [epoch time: 0.04]\n",
      "2200 [D loss: 0.001122, acc.: 100.00%] [G loss: 8.611206] [epoch time: 0.04]\n",
      "2400 [D loss: 0.000347, acc.: 100.00%] [G loss: 8.708296] [epoch time: 0.04]\n",
      "2600 [D loss: 0.000117, acc.: 100.00%] [G loss: 8.979011] [epoch time: 0.04]\n",
      "2800 [D loss: 0.000397, acc.: 100.00%] [G loss: 9.879903] [epoch time: 0.04]\n",
      "3000 [D loss: 0.000063, acc.: 100.00%] [G loss: 9.980155] [epoch time: 0.04]\n",
      "3200 [D loss: 0.001219, acc.: 100.00%] [G loss: 9.327557] [epoch time: 0.04]\n",
      "3400 [D loss: 0.000029, acc.: 100.00%] [G loss: 10.210733] [epoch time: 0.04]\n",
      "3600 [D loss: 0.000038, acc.: 100.00%] [G loss: 10.473637] [epoch time: 0.04]\n",
      "3800 [D loss: 0.000013, acc.: 100.00%] [G loss: 10.831248] [epoch time: 0.04]\n",
      "4000 [D loss: 0.000117, acc.: 100.00%] [G loss: 11.295703] [epoch time: 0.04]\n",
      "4200 [D loss: 0.000059, acc.: 100.00%] [G loss: 11.150469] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000033, acc.: 100.00%] [G loss: 11.629544] [epoch time: 0.04]\n",
      "4600 [D loss: 0.000020, acc.: 100.00%] [G loss: 12.212416] [epoch time: 0.04]\n",
      "4800 [D loss: 0.000017, acc.: 100.00%] [G loss: 12.126993] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000013, acc.: 100.00%] [G loss: 12.296539] [epoch time: 0.04]\n",
      "5200 [D loss: 0.000029, acc.: 100.00%] [G loss: 12.168795] [epoch time: 0.04]\n",
      "5400 [D loss: 0.000003, acc.: 100.00%] [G loss: 12.676327] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.027226] [epoch time: 0.04]\n",
      "5800 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.241529] [epoch time: 0.04]\n",
      "6000 [D loss: 0.000005, acc.: 100.00%] [G loss: 13.550713] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.546210] [epoch time: 0.04]\n",
      "6400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.027996] [epoch time: 0.04]\n",
      "6600 [D loss: 0.000001, acc.: 100.00%] [G loss: 13.869503] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.237255] [epoch time: 0.04]\n",
      "7000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.359892] [epoch time: 0.04]\n",
      "7200 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.819912] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.439947] [epoch time: 0.04]\n",
      "7600 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.821314] [epoch time: 0.04]\n",
      "7800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.353137] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.336508] [epoch time: 0.04]\n",
      "8200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.597951] [epoch time: 0.04]\n",
      "8400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.567877] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.754688] [epoch time: 0.04]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.728514] [epoch time: 0.04]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.802825] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.900063] [epoch time: 0.04]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.041727] [epoch time: 0.04]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.020935] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.995444] [epoch time: 0.04]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.011669] [epoch time: 0.04]\n",
      "10200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.090956] [epoch time: 0.04]\n",
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.075150] [epoch time: 0.04]\n",
      "10600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.074993] [epoch time: 0.04]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.042377] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.056900] [epoch time: 0.04]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.112604] [epoch time: 0.04]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.072144] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.103523] [epoch time: 0.04]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101774] [epoch time: 0.04]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.962094] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.04]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.04]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.091848] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 14.893023] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.789318] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.890792] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.912552] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.011286] [epoch time: 0.04]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.000727] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.013872] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.037174] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.076742] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.103523] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.091190] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101774] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "elapsed training time: 13 min, 38 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.750748, acc.: 47.66%] [G loss: 0.689975] [epoch time: 7.67]\n",
      "200 [D loss: 0.295914, acc.: 92.97%] [G loss: 1.928221] [epoch time: 0.04]\n",
      "400 [D loss: 0.055794, acc.: 99.22%] [G loss: 3.621342] [epoch time: 0.04]\n",
      "600 [D loss: 0.011195, acc.: 100.00%] [G loss: 5.143559] [epoch time: 0.04]\n",
      "800 [D loss: 0.003484, acc.: 100.00%] [G loss: 5.951209] [epoch time: 0.04]\n",
      "1000 [D loss: 0.001699, acc.: 100.00%] [G loss: 6.929198] [epoch time: 0.04]\n",
      "1200 [D loss: 0.002478, acc.: 100.00%] [G loss: 7.309478] [epoch time: 0.04]\n",
      "1400 [D loss: 0.000691, acc.: 100.00%] [G loss: 7.187221] [epoch time: 0.04]\n",
      "1600 [D loss: 0.000489, acc.: 100.00%] [G loss: 7.859197] [epoch time: 0.04]\n",
      "1800 [D loss: 0.001260, acc.: 100.00%] [G loss: 7.622782] [epoch time: 0.04]\n",
      "2000 [D loss: 0.001579, acc.: 100.00%] [G loss: 8.702696] [epoch time: 0.04]\n",
      "2200 [D loss: 0.000198, acc.: 100.00%] [G loss: 8.509575] [epoch time: 0.04]\n",
      "2400 [D loss: 0.000224, acc.: 100.00%] [G loss: 9.642639] [epoch time: 0.04]\n",
      "2600 [D loss: 0.000112, acc.: 100.00%] [G loss: 9.591302] [epoch time: 0.04]\n",
      "2800 [D loss: 0.000092, acc.: 100.00%] [G loss: 10.240505] [epoch time: 0.04]\n",
      "3000 [D loss: 0.000175, acc.: 100.00%] [G loss: 10.145714] [epoch time: 0.04]\n",
      "3200 [D loss: 0.000145, acc.: 100.00%] [G loss: 10.176929] [epoch time: 0.04]\n",
      "3400 [D loss: 0.000096, acc.: 100.00%] [G loss: 10.592861] [epoch time: 0.04]\n",
      "3600 [D loss: 0.000073, acc.: 100.00%] [G loss: 10.935781] [epoch time: 0.04]\n",
      "3800 [D loss: 0.000018, acc.: 100.00%] [G loss: 11.273132] [epoch time: 0.04]\n",
      "4000 [D loss: 0.000021, acc.: 100.00%] [G loss: 11.257236] [epoch time: 0.04]\n",
      "4200 [D loss: 0.000010, acc.: 100.00%] [G loss: 11.589933] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000019, acc.: 100.00%] [G loss: 11.677452] [epoch time: 0.04]\n",
      "4600 [D loss: 0.000009, acc.: 100.00%] [G loss: 12.383213] [epoch time: 0.04]\n",
      "4800 [D loss: 0.000011, acc.: 100.00%] [G loss: 12.635727] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000006, acc.: 100.00%] [G loss: 13.012255] [epoch time: 0.04]\n",
      "5200 [D loss: 0.000004, acc.: 100.00%] [G loss: 12.797005] [epoch time: 0.04]\n",
      "5400 [D loss: 0.000007, acc.: 100.00%] [G loss: 12.621328] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000008, acc.: 100.00%] [G loss: 12.794321] [epoch time: 0.04]\n",
      "5800 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.070538] [epoch time: 0.04]\n",
      "6000 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.103018] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000001, acc.: 100.00%] [G loss: 13.951481] [epoch time: 0.04]\n",
      "6400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.828264] [epoch time: 0.04]\n",
      "6600 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.508776] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.867269] [epoch time: 0.04]\n",
      "7000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.291841] [epoch time: 0.04]\n",
      "7200 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.920101] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.253849] [epoch time: 0.04]\n",
      "7600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.471620] [epoch time: 0.04]\n",
      "7800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.693876] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.692112] [epoch time: 0.04]\n",
      "8200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.904821] [epoch time: 0.04]\n",
      "8400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.730688] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.967665] [epoch time: 0.04]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.946010] [epoch time: 0.04]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.864767] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.943417] [epoch time: 0.04]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.021492] [epoch time: 0.04]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.925986] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.892605] [epoch time: 0.04]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.056068] [epoch time: 0.04]\n",
      "10200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.037651] [epoch time: 0.04]\n",
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.067965] [epoch time: 0.04]\n",
      "10600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.086357] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.085209] [epoch time: 0.04]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.084608] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.093029] [epoch time: 0.04]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.087574] [epoch time: 0.04]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.087456] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.970881] [epoch time: 0.04]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.099030] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.112604] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "elapsed training time: 10 min, 36 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.955189, acc.: 28.91%] [G loss: 0.566286] [epoch time: 8.01]\n",
      "200 [D loss: 0.343683, acc.: 87.50%] [G loss: 1.795501] [epoch time: 0.02]\n",
      "400 [D loss: 0.053660, acc.: 99.22%] [G loss: 3.471687] [epoch time: 0.02]\n",
      "600 [D loss: 0.009684, acc.: 100.00%] [G loss: 5.224584] [epoch time: 0.04]\n",
      "800 [D loss: 0.004650, acc.: 100.00%] [G loss: 5.920507] [epoch time: 0.02]\n",
      "1000 [D loss: 0.002571, acc.: 100.00%] [G loss: 6.424726] [epoch time: 0.02]\n",
      "1200 [D loss: 0.001456, acc.: 100.00%] [G loss: 6.816175] [epoch time: 0.04]\n",
      "1400 [D loss: 0.000840, acc.: 100.00%] [G loss: 7.542142] [epoch time: 0.02]\n",
      "1600 [D loss: 0.000783, acc.: 100.00%] [G loss: 7.982253] [epoch time: 0.02]\n",
      "1800 [D loss: 0.000338, acc.: 100.00%] [G loss: 8.450304] [epoch time: 0.04]\n",
      "2000 [D loss: 0.000316, acc.: 100.00%] [G loss: 8.392935] [epoch time: 0.02]\n",
      "2200 [D loss: 0.000297, acc.: 100.00%] [G loss: 8.571217] [epoch time: 0.02]\n",
      "2400 [D loss: 0.000184, acc.: 100.00%] [G loss: 9.341293] [epoch time: 0.04]\n",
      "2600 [D loss: 0.000085, acc.: 100.00%] [G loss: 9.466473] [epoch time: 0.02]\n",
      "2800 [D loss: 0.000181, acc.: 100.00%] [G loss: 9.675327] [epoch time: 0.02]\n",
      "3000 [D loss: 0.000067, acc.: 100.00%] [G loss: 10.121913] [epoch time: 0.04]\n",
      "3200 [D loss: 0.000267, acc.: 100.00%] [G loss: 10.041003] [epoch time: 0.02]\n",
      "3400 [D loss: 0.000022, acc.: 100.00%] [G loss: 10.527781] [epoch time: 0.02]\n",
      "3600 [D loss: 0.000031, acc.: 100.00%] [G loss: 10.867322] [epoch time: 0.04]\n",
      "3800 [D loss: 0.000017, acc.: 100.00%] [G loss: 11.395514] [epoch time: 0.02]\n",
      "4000 [D loss: 0.000033, acc.: 100.00%] [G loss: 11.546855] [epoch time: 0.02]\n",
      "4200 [D loss: 0.000019, acc.: 100.00%] [G loss: 11.880682] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000031, acc.: 100.00%] [G loss: 11.958494] [epoch time: 0.02]\n",
      "4600 [D loss: 0.000008, acc.: 100.00%] [G loss: 11.686928] [epoch time: 0.02]\n",
      "4800 [D loss: 0.000011, acc.: 100.00%] [G loss: 12.091795] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000007, acc.: 100.00%] [G loss: 12.652914] [epoch time: 0.02]\n",
      "5200 [D loss: 0.000006, acc.: 100.00%] [G loss: 12.946205] [epoch time: 0.02]\n",
      "5400 [D loss: 0.000008, acc.: 100.00%] [G loss: 12.722372] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000006, acc.: 100.00%] [G loss: 12.960590] [epoch time: 0.02]\n",
      "5800 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.574938] [epoch time: 0.02]\n",
      "6000 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.183083] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.180448] [epoch time: 0.02]\n",
      "6400 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.202724] [epoch time: 0.02]\n",
      "6600 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.712511] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.487480] [epoch time: 0.02]\n",
      "7000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.320165] [epoch time: 0.02]\n",
      "7200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.239120] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.357826] [epoch time: 0.02]\n",
      "7600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.177017] [epoch time: 0.02]\n",
      "7800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.204439] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.628043] [epoch time: 0.02]\n",
      "8200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.591526] [epoch time: 0.02]\n",
      "8400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.705879] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.763042] [epoch time: 0.02]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.734894] [epoch time: 0.02]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.869013] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.014839] [epoch time: 0.02]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.037994] [epoch time: 0.02]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.962006] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.005154] [epoch time: 0.02]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.044312] [epoch time: 0.02]\n",
      "10200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.065554] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.095541] [epoch time: 0.02]\n",
      "10600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.057571] [epoch time: 0.02]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.008833] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.100037] [epoch time: 0.02]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.02]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.02]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.112604] [epoch time: 0.02]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.112604] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.02]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.02]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109859] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.02]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.102680] [epoch time: 0.02]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.088018] [epoch time: 0.02]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.02]\n",
      "elapsed training time: 9 min, 44 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_59 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.686528, acc.: 51.56%] [G loss: 0.654495] [epoch time: 8.46]\n",
      "200 [D loss: 0.681278, acc.: 57.03%] [G loss: 0.892225] [epoch time: 0.03]\n",
      "400 [D loss: 0.484395, acc.: 77.34%] [G loss: 1.140873] [epoch time: 0.03]\n",
      "600 [D loss: 0.290845, acc.: 92.19%] [G loss: 2.019281] [epoch time: 0.04]\n",
      "800 [D loss: 0.100001, acc.: 99.22%] [G loss: 2.781689] [epoch time: 0.03]\n",
      "1000 [D loss: 0.059438, acc.: 99.22%] [G loss: 3.521449] [epoch time: 0.03]\n",
      "1200 [D loss: 0.031450, acc.: 100.00%] [G loss: 4.422948] [epoch time: 0.04]\n",
      "1400 [D loss: 0.017131, acc.: 100.00%] [G loss: 4.635131] [epoch time: 0.03]\n",
      "1600 [D loss: 0.018997, acc.: 100.00%] [G loss: 4.847371] [epoch time: 0.03]\n",
      "1800 [D loss: 0.007824, acc.: 100.00%] [G loss: 4.888099] [epoch time: 0.04]\n",
      "2000 [D loss: 0.007603, acc.: 100.00%] [G loss: 5.733485] [epoch time: 0.03]\n",
      "2200 [D loss: 0.004987, acc.: 100.00%] [G loss: 6.292714] [epoch time: 0.03]\n",
      "2400 [D loss: 0.002546, acc.: 100.00%] [G loss: 6.046216] [epoch time: 0.04]\n",
      "2600 [D loss: 0.003736, acc.: 100.00%] [G loss: 6.448219] [epoch time: 0.03]\n",
      "2800 [D loss: 0.003847, acc.: 100.00%] [G loss: 6.651927] [epoch time: 0.03]\n",
      "3000 [D loss: 0.001307, acc.: 100.00%] [G loss: 6.783445] [epoch time: 0.04]\n",
      "3200 [D loss: 0.001791, acc.: 100.00%] [G loss: 6.774985] [epoch time: 0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 [D loss: 0.001060, acc.: 100.00%] [G loss: 6.946610] [epoch time: 0.03]\n",
      "3600 [D loss: 0.000980, acc.: 100.00%] [G loss: 7.068894] [epoch time: 0.04]\n",
      "3800 [D loss: 0.001449, acc.: 100.00%] [G loss: 7.178057] [epoch time: 0.03]\n",
      "4000 [D loss: 0.001162, acc.: 100.00%] [G loss: 7.518727] [epoch time: 0.03]\n",
      "4200 [D loss: 0.000865, acc.: 100.00%] [G loss: 7.281645] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000852, acc.: 100.00%] [G loss: 7.768158] [epoch time: 0.03]\n",
      "4600 [D loss: 0.000695, acc.: 100.00%] [G loss: 7.909703] [epoch time: 0.03]\n",
      "4800 [D loss: 0.000660, acc.: 100.00%] [G loss: 7.755116] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000642, acc.: 100.00%] [G loss: 7.724156] [epoch time: 0.03]\n",
      "5200 [D loss: 0.000599, acc.: 100.00%] [G loss: 7.942773] [epoch time: 0.03]\n",
      "5400 [D loss: 0.000411, acc.: 100.00%] [G loss: 8.153809] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000512, acc.: 100.00%] [G loss: 8.336724] [epoch time: 0.03]\n",
      "5800 [D loss: 0.000379, acc.: 100.00%] [G loss: 8.474594] [epoch time: 0.03]\n",
      "6000 [D loss: 0.000279, acc.: 100.00%] [G loss: 8.788267] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000180, acc.: 100.00%] [G loss: 9.500044] [epoch time: 0.03]\n",
      "6400 [D loss: 0.000087, acc.: 100.00%] [G loss: 10.040522] [epoch time: 0.03]\n",
      "6600 [D loss: 0.000107, acc.: 100.00%] [G loss: 10.284222] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000037, acc.: 100.00%] [G loss: 10.721684] [epoch time: 0.03]\n",
      "7000 [D loss: 0.000048, acc.: 100.00%] [G loss: 10.483051] [epoch time: 0.03]\n",
      "7200 [D loss: 0.000072, acc.: 100.00%] [G loss: 10.125517] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000132, acc.: 100.00%] [G loss: 8.892464] [epoch time: 0.03]\n",
      "7600 [D loss: 0.000367, acc.: 100.00%] [G loss: 8.203475] [epoch time: 0.03]\n",
      "7800 [D loss: 0.000125, acc.: 100.00%] [G loss: 9.045399] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000182, acc.: 100.00%] [G loss: 9.484055] [epoch time: 0.03]\n",
      "8200 [D loss: 0.000111, acc.: 100.00%] [G loss: 9.179169] [epoch time: 0.03]\n",
      "8400 [D loss: 0.000116, acc.: 100.00%] [G loss: 9.702744] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000152, acc.: 100.00%] [G loss: 10.220163] [epoch time: 0.03]\n",
      "8800 [D loss: 0.000137, acc.: 100.00%] [G loss: 10.611607] [epoch time: 0.03]\n",
      "9000 [D loss: 0.000030, acc.: 100.00%] [G loss: 10.373329] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000150, acc.: 100.00%] [G loss: 9.503613] [epoch time: 0.03]\n",
      "9400 [D loss: 0.000075, acc.: 100.00%] [G loss: 9.873087] [epoch time: 0.03]\n",
      "9600 [D loss: 0.000067, acc.: 100.00%] [G loss: 9.884037] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000141, acc.: 100.00%] [G loss: 10.391397] [epoch time: 0.03]\n",
      "10000 [D loss: 0.000062, acc.: 100.00%] [G loss: 10.044924] [epoch time: 0.03]\n",
      "10200 [D loss: 0.000078, acc.: 100.00%] [G loss: 10.623803] [epoch time: 0.04]\n",
      "10400 [D loss: 0.000104, acc.: 100.00%] [G loss: 10.801921] [epoch time: 0.03]\n",
      "10600 [D loss: 0.000047, acc.: 100.00%] [G loss: 10.833115] [epoch time: 0.03]\n",
      "10800 [D loss: 0.000052, acc.: 100.00%] [G loss: 10.106112] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000230, acc.: 100.00%] [G loss: 10.481434] [epoch time: 0.03]\n",
      "11200 [D loss: 0.000018, acc.: 100.00%] [G loss: 10.917047] [epoch time: 0.02]\n",
      "11400 [D loss: 0.000024, acc.: 100.00%] [G loss: 11.188128] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000011, acc.: 100.00%] [G loss: 11.860903] [epoch time: 0.03]\n",
      "11800 [D loss: 0.000036, acc.: 100.00%] [G loss: 11.575439] [epoch time: 0.03]\n",
      "12000 [D loss: 0.000023, acc.: 100.00%] [G loss: 11.511021] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000013, acc.: 100.00%] [G loss: 11.187086] [epoch time: 0.03]\n",
      "12400 [D loss: 0.000020, acc.: 100.00%] [G loss: 11.553976] [epoch time: 0.03]\n",
      "12600 [D loss: 0.000022, acc.: 100.00%] [G loss: 11.135242] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000084, acc.: 100.00%] [G loss: 11.596931] [epoch time: 0.03]\n",
      "13000 [D loss: 0.000013, acc.: 100.00%] [G loss: 11.527682] [epoch time: 0.03]\n",
      "13200 [D loss: 0.000020, acc.: 100.00%] [G loss: 11.369280] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000052, acc.: 100.00%] [G loss: 12.025034] [epoch time: 0.03]\n",
      "13600 [D loss: 0.000009, acc.: 100.00%] [G loss: 12.197620] [epoch time: 0.03]\n",
      "13800 [D loss: 0.000010, acc.: 100.00%] [G loss: 11.883359] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000015, acc.: 100.00%] [G loss: 11.564918] [epoch time: 0.03]\n",
      "14200 [D loss: 0.000011, acc.: 100.00%] [G loss: 11.953399] [epoch time: 0.03]\n",
      "14400 [D loss: 0.000017, acc.: 100.00%] [G loss: 12.157276] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000009, acc.: 100.00%] [G loss: 12.308394] [epoch time: 0.03]\n",
      "14800 [D loss: 0.000008, acc.: 100.00%] [G loss: 12.032598] [epoch time: 0.03]\n",
      "15000 [D loss: 0.000008, acc.: 100.00%] [G loss: 12.308725] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000009, acc.: 100.00%] [G loss: 12.950531] [epoch time: 0.03]\n",
      "15400 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.012238] [epoch time: 0.03]\n",
      "15600 [D loss: 0.000007, acc.: 100.00%] [G loss: 12.736139] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000005, acc.: 100.00%] [G loss: 12.681973] [epoch time: 0.02]\n",
      "16000 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.348671] [epoch time: 0.03]\n",
      "16200 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.077583] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000012, acc.: 100.00%] [G loss: 12.770659] [epoch time: 0.03]\n",
      "16600 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.369971] [epoch time: 0.03]\n",
      "16800 [D loss: 0.000031, acc.: 100.00%] [G loss: 12.938048] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.291441] [epoch time: 0.03]\n",
      "17200 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.552092] [epoch time: 0.03]\n",
      "17400 [D loss: 0.000005, acc.: 100.00%] [G loss: 13.750095] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.873439] [epoch time: 0.03]\n",
      "17800 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.872890] [epoch time: 0.03]\n",
      "18000 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.017250] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.063763] [epoch time: 0.03]\n",
      "18400 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.987474] [epoch time: 0.03]\n",
      "18600 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.791575] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.998144] [epoch time: 0.03]\n",
      "19000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.550194] [epoch time: 0.03]\n",
      "19200 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.300671] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.697131] [epoch time: 0.03]\n",
      "19600 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.551291] [epoch time: 0.03]\n",
      "19800 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.724676] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.846963] [epoch time: 0.03]\n",
      "elapsed training time: 10 min, 53 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_62 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.797569, acc.: 39.06%] [G loss: 0.684654] [epoch time: 8.94]\n",
      "200 [D loss: 0.531218, acc.: 73.44%] [G loss: 1.063174] [epoch time: 0.04]\n",
      "400 [D loss: 0.116516, acc.: 100.00%] [G loss: 2.454700] [epoch time: 0.04]\n",
      "600 [D loss: 0.034248, acc.: 100.00%] [G loss: 3.942434] [epoch time: 0.04]\n",
      "800 [D loss: 0.013655, acc.: 100.00%] [G loss: 4.784153] [epoch time: 0.04]\n",
      "1000 [D loss: 0.013503, acc.: 100.00%] [G loss: 5.189765] [epoch time: 0.04]\n",
      "1200 [D loss: 0.004308, acc.: 100.00%] [G loss: 5.658784] [epoch time: 0.04]\n",
      "1400 [D loss: 0.003858, acc.: 100.00%] [G loss: 5.865928] [epoch time: 0.04]\n",
      "1600 [D loss: 0.002309, acc.: 100.00%] [G loss: 6.288311] [epoch time: 0.04]\n",
      "1800 [D loss: 0.002631, acc.: 100.00%] [G loss: 6.709453] [epoch time: 0.04]\n",
      "2000 [D loss: 0.001582, acc.: 100.00%] [G loss: 7.091619] [epoch time: 0.04]\n",
      "2200 [D loss: 0.001181, acc.: 100.00%] [G loss: 6.778369] [epoch time: 0.04]\n",
      "2400 [D loss: 0.000954, acc.: 100.00%] [G loss: 7.206077] [epoch time: 0.04]\n",
      "2600 [D loss: 0.000539, acc.: 100.00%] [G loss: 7.947069] [epoch time: 0.04]\n",
      "2800 [D loss: 0.000213, acc.: 100.00%] [G loss: 8.611005] [epoch time: 0.04]\n",
      "3000 [D loss: 0.000670, acc.: 100.00%] [G loss: 7.657814] [epoch time: 0.04]\n",
      "3200 [D loss: 0.000490, acc.: 100.00%] [G loss: 7.955925] [epoch time: 0.04]\n",
      "3400 [D loss: 0.000398, acc.: 100.00%] [G loss: 8.162062] [epoch time: 0.04]\n",
      "3600 [D loss: 0.000375, acc.: 100.00%] [G loss: 8.494484] [epoch time: 0.04]\n",
      "3800 [D loss: 0.000163, acc.: 100.00%] [G loss: 8.303941] [epoch time: 0.04]\n",
      "4000 [D loss: 0.000244, acc.: 100.00%] [G loss: 8.748829] [epoch time: 0.04]\n",
      "4200 [D loss: 0.000366, acc.: 100.00%] [G loss: 8.750242] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000120, acc.: 100.00%] [G loss: 9.063576] [epoch time: 0.04]\n",
      "4600 [D loss: 0.000161, acc.: 100.00%] [G loss: 9.064632] [epoch time: 0.04]\n",
      "4800 [D loss: 0.000133, acc.: 100.00%] [G loss: 8.972195] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000137, acc.: 100.00%] [G loss: 9.446624] [epoch time: 0.04]\n",
      "5200 [D loss: 0.000082, acc.: 100.00%] [G loss: 9.621382] [epoch time: 0.04]\n",
      "5400 [D loss: 0.000107, acc.: 100.00%] [G loss: 9.730932] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000060, acc.: 100.00%] [G loss: 9.875297] [epoch time: 0.04]\n",
      "5800 [D loss: 0.000053, acc.: 100.00%] [G loss: 9.936896] [epoch time: 0.04]\n",
      "6000 [D loss: 0.000073, acc.: 100.00%] [G loss: 10.145812] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000047, acc.: 100.00%] [G loss: 10.685865] [epoch time: 0.04]\n",
      "6400 [D loss: 0.000045, acc.: 100.00%] [G loss: 10.759170] [epoch time: 0.04]\n",
      "6600 [D loss: 0.000115, acc.: 100.00%] [G loss: 10.880065] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000146, acc.: 100.00%] [G loss: 10.789042] [epoch time: 0.04]\n",
      "7000 [D loss: 0.000023, acc.: 100.00%] [G loss: 11.169414] [epoch time: 0.04]\n",
      "7200 [D loss: 0.000143, acc.: 100.00%] [G loss: 11.364973] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000009, acc.: 100.00%] [G loss: 11.801792] [epoch time: 0.04]\n",
      "7600 [D loss: 0.000015, acc.: 100.00%] [G loss: 11.368044] [epoch time: 0.04]\n",
      "7800 [D loss: 0.000012, acc.: 100.00%] [G loss: 11.568995] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000013, acc.: 100.00%] [G loss: 11.896466] [epoch time: 0.04]\n",
      "8200 [D loss: 0.000016, acc.: 100.00%] [G loss: 11.843505] [epoch time: 0.04]\n",
      "8400 [D loss: 0.000011, acc.: 100.00%] [G loss: 11.841936] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000012, acc.: 100.00%] [G loss: 12.232113] [epoch time: 0.04]\n",
      "8800 [D loss: 0.000010, acc.: 100.00%] [G loss: 12.058678] [epoch time: 0.04]\n",
      "9000 [D loss: 0.000015, acc.: 100.00%] [G loss: 12.560969] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000021, acc.: 100.00%] [G loss: 12.577580] [epoch time: 0.04]\n",
      "9400 [D loss: 0.000006, acc.: 100.00%] [G loss: 12.535648] [epoch time: 0.04]\n",
      "9600 [D loss: 0.000006, acc.: 100.00%] [G loss: 12.526508] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.287340] [epoch time: 0.04]\n",
      "10000 [D loss: 0.000005, acc.: 100.00%] [G loss: 13.164561] [epoch time: 0.04]\n",
      "10200 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.103144] [epoch time: 0.04]\n",
      "10400 [D loss: 0.000004, acc.: 100.00%] [G loss: 12.826688] [epoch time: 0.04]\n",
      "10600 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.270243] [epoch time: 0.04]\n",
      "10800 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.268661] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.408800] [epoch time: 0.04]\n",
      "11200 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.019684] [epoch time: 0.04]\n",
      "11400 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.735432] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.675083] [epoch time: 0.04]\n",
      "11800 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.106930] [epoch time: 0.04]\n",
      "12000 [D loss: 0.000001, acc.: 100.00%] [G loss: 13.993955] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.758848] [epoch time: 0.04]\n",
      "12400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.170307] [epoch time: 0.04]\n",
      "12600 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.115616] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.328539] [epoch time: 0.04]\n",
      "13000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.053898] [epoch time: 0.04]\n",
      "13200 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.657022] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.698711] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.783417] [epoch time: 0.04]\n",
      "13800 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.752304] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.040703] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.035997] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.167640] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.506922] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.556015] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.493265] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.254221] [epoch time: 0.04]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.477366] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.490673] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.513121] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.517260] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.746555] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.748911] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.819749] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.281172] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.764789] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.651848] [epoch time: 0.04]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.021351] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.865080] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.852071] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.032082] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.987929] [epoch time: 0.04]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.029333] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.044842] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.979233] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.989616] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.072226] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.022478] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.038670] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.061676] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.089104] [epoch time: 0.04]\n",
      "elapsed training time: 11 min, 53 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.640629, acc.: 55.47%] [G loss: 0.760422] [epoch time: 9.35]\n",
      "200 [D loss: 0.833657, acc.: 44.53%] [G loss: 0.845794] [epoch time: 0.04]\n",
      "400 [D loss: 0.713227, acc.: 57.03%] [G loss: 1.017279] [epoch time: 0.04]\n",
      "600 [D loss: 0.579868, acc.: 71.88%] [G loss: 1.348175] [epoch time: 0.04]\n",
      "800 [D loss: 0.410506, acc.: 83.59%] [G loss: 1.594538] [epoch time: 0.04]\n",
      "1000 [D loss: 0.323352, acc.: 90.62%] [G loss: 2.090205] [epoch time: 0.04]\n",
      "1200 [D loss: 0.177400, acc.: 96.09%] [G loss: 2.305816] [epoch time: 0.04]\n",
      "1400 [D loss: 0.181482, acc.: 94.53%] [G loss: 2.465166] [epoch time: 0.04]\n",
      "1600 [D loss: 0.093121, acc.: 97.66%] [G loss: 2.749139] [epoch time: 0.04]\n",
      "1800 [D loss: 0.097856, acc.: 98.44%] [G loss: 3.231533] [epoch time: 0.04]\n",
      "2000 [D loss: 0.054376, acc.: 100.00%] [G loss: 3.486478] [epoch time: 0.04]\n",
      "2200 [D loss: 0.036100, acc.: 100.00%] [G loss: 3.519965] [epoch time: 0.04]\n",
      "2400 [D loss: 0.037465, acc.: 100.00%] [G loss: 3.634997] [epoch time: 0.04]\n",
      "2600 [D loss: 0.031538, acc.: 100.00%] [G loss: 3.853466] [epoch time: 0.04]\n",
      "2800 [D loss: 0.033650, acc.: 100.00%] [G loss: 3.834084] [epoch time: 0.04]\n",
      "3000 [D loss: 0.018497, acc.: 100.00%] [G loss: 4.472657] [epoch time: 0.04]\n",
      "3200 [D loss: 0.018556, acc.: 100.00%] [G loss: 4.392926] [epoch time: 0.04]\n",
      "3400 [D loss: 0.020547, acc.: 100.00%] [G loss: 4.606736] [epoch time: 0.04]\n",
      "3600 [D loss: 0.018874, acc.: 100.00%] [G loss: 4.576190] [epoch time: 0.04]\n",
      "3800 [D loss: 0.016986, acc.: 100.00%] [G loss: 4.687274] [epoch time: 0.04]\n",
      "4000 [D loss: 0.021946, acc.: 100.00%] [G loss: 4.819547] [epoch time: 0.04]\n",
      "4200 [D loss: 0.011540, acc.: 100.00%] [G loss: 4.889569] [epoch time: 0.04]\n",
      "4400 [D loss: 0.008391, acc.: 100.00%] [G loss: 4.874342] [epoch time: 0.04]\n",
      "4600 [D loss: 0.011038, acc.: 100.00%] [G loss: 5.228252] [epoch time: 0.04]\n",
      "4800 [D loss: 0.010651, acc.: 100.00%] [G loss: 5.303860] [epoch time: 0.04]\n",
      "5000 [D loss: 0.008456, acc.: 100.00%] [G loss: 5.613462] [epoch time: 0.04]\n",
      "5200 [D loss: 0.003261, acc.: 100.00%] [G loss: 6.158916] [epoch time: 0.04]\n",
      "5400 [D loss: 0.003598, acc.: 100.00%] [G loss: 6.618574] [epoch time: 0.04]\n",
      "5600 [D loss: 0.003654, acc.: 100.00%] [G loss: 6.515192] [epoch time: 0.04]\n",
      "5800 [D loss: 0.002665, acc.: 100.00%] [G loss: 6.589075] [epoch time: 0.04]\n",
      "6000 [D loss: 0.001164, acc.: 100.00%] [G loss: 7.020179] [epoch time: 0.04]\n",
      "6200 [D loss: 0.001766, acc.: 100.00%] [G loss: 7.009122] [epoch time: 0.04]\n",
      "6400 [D loss: 0.022431, acc.: 99.22%] [G loss: 7.093724] [epoch time: 0.04]\n",
      "6600 [D loss: 0.004282, acc.: 100.00%] [G loss: 6.063063] [epoch time: 0.04]\n",
      "6800 [D loss: 0.004344, acc.: 100.00%] [G loss: 6.048052] [epoch time: 0.04]\n",
      "7000 [D loss: 0.002550, acc.: 100.00%] [G loss: 6.276846] [epoch time: 0.04]\n",
      "7200 [D loss: 0.008239, acc.: 100.00%] [G loss: 5.494610] [epoch time: 0.04]\n",
      "7400 [D loss: 0.006602, acc.: 100.00%] [G loss: 5.075590] [epoch time: 0.04]\n",
      "7600 [D loss: 0.005627, acc.: 100.00%] [G loss: 5.517708] [epoch time: 0.04]\n",
      "7800 [D loss: 0.004921, acc.: 100.00%] [G loss: 5.846579] [epoch time: 0.04]\n",
      "8000 [D loss: 0.004764, acc.: 100.00%] [G loss: 5.725153] [epoch time: 0.04]\n",
      "8200 [D loss: 0.005286, acc.: 100.00%] [G loss: 5.609069] [epoch time: 0.04]\n",
      "8400 [D loss: 0.002995, acc.: 100.00%] [G loss: 6.091817] [epoch time: 0.04]\n",
      "8600 [D loss: 0.004101, acc.: 100.00%] [G loss: 5.583028] [epoch time: 0.04]\n",
      "8800 [D loss: 0.004346, acc.: 100.00%] [G loss: 5.836262] [epoch time: 0.04]\n",
      "9000 [D loss: 0.003807, acc.: 100.00%] [G loss: 5.839463] [epoch time: 0.04]\n",
      "9200 [D loss: 0.002709, acc.: 100.00%] [G loss: 6.182060] [epoch time: 0.04]\n",
      "9400 [D loss: 0.003187, acc.: 100.00%] [G loss: 6.013057] [epoch time: 0.04]\n",
      "9600 [D loss: 0.003731, acc.: 100.00%] [G loss: 6.048376] [epoch time: 0.04]\n",
      "9800 [D loss: 0.005908, acc.: 100.00%] [G loss: 6.370398] [epoch time: 0.04]\n",
      "10000 [D loss: 0.002947, acc.: 100.00%] [G loss: 6.343787] [epoch time: 0.04]\n",
      "10200 [D loss: 0.006531, acc.: 100.00%] [G loss: 5.972581] [epoch time: 0.04]\n",
      "10400 [D loss: 0.001699, acc.: 100.00%] [G loss: 6.534309] [epoch time: 0.04]\n",
      "10600 [D loss: 0.002116, acc.: 100.00%] [G loss: 6.502109] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800 [D loss: 0.007029, acc.: 100.00%] [G loss: 6.691125] [epoch time: 0.04]\n",
      "11000 [D loss: 0.006213, acc.: 100.00%] [G loss: 6.332062] [epoch time: 0.04]\n",
      "11200 [D loss: 0.001663, acc.: 100.00%] [G loss: 6.555335] [epoch time: 0.04]\n",
      "11400 [D loss: 0.001954, acc.: 100.00%] [G loss: 7.091159] [epoch time: 0.04]\n",
      "11600 [D loss: 0.002680, acc.: 100.00%] [G loss: 6.760265] [epoch time: 0.04]\n",
      "11800 [D loss: 0.001313, acc.: 100.00%] [G loss: 6.669460] [epoch time: 0.04]\n",
      "12000 [D loss: 0.002052, acc.: 100.00%] [G loss: 6.923394] [epoch time: 0.04]\n",
      "12200 [D loss: 0.001301, acc.: 100.00%] [G loss: 6.681144] [epoch time: 0.04]\n",
      "12400 [D loss: 0.002462, acc.: 100.00%] [G loss: 7.275173] [epoch time: 0.04]\n",
      "12600 [D loss: 0.001904, acc.: 100.00%] [G loss: 7.175433] [epoch time: 0.04]\n",
      "12800 [D loss: 0.001418, acc.: 100.00%] [G loss: 6.977655] [epoch time: 0.04]\n",
      "13000 [D loss: 0.001592, acc.: 100.00%] [G loss: 7.289886] [epoch time: 0.04]\n",
      "13200 [D loss: 0.001546, acc.: 100.00%] [G loss: 7.095203] [epoch time: 0.04]\n",
      "13400 [D loss: 0.001010, acc.: 100.00%] [G loss: 7.127736] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000728, acc.: 100.00%] [G loss: 7.297804] [epoch time: 0.04]\n",
      "13800 [D loss: 0.002369, acc.: 100.00%] [G loss: 7.170116] [epoch time: 0.04]\n",
      "14000 [D loss: 0.002336, acc.: 100.00%] [G loss: 7.134892] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000792, acc.: 100.00%] [G loss: 7.567280] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000621, acc.: 100.00%] [G loss: 7.432980] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000600, acc.: 100.00%] [G loss: 7.524974] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000605, acc.: 100.00%] [G loss: 7.480618] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000717, acc.: 100.00%] [G loss: 7.499110] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000456, acc.: 100.00%] [G loss: 8.024877] [epoch time: 0.04]\n",
      "15400 [D loss: 0.001181, acc.: 100.00%] [G loss: 7.742641] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000967, acc.: 100.00%] [G loss: 7.078429] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000659, acc.: 100.00%] [G loss: 7.857958] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000547, acc.: 100.00%] [G loss: 7.888489] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000860, acc.: 100.00%] [G loss: 7.513312] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000421, acc.: 100.00%] [G loss: 7.423866] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000636, acc.: 100.00%] [G loss: 7.944514] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000371, acc.: 100.00%] [G loss: 8.107301] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000853, acc.: 100.00%] [G loss: 7.821126] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000402, acc.: 100.00%] [G loss: 7.640067] [epoch time: 0.04]\n",
      "17400 [D loss: 0.000429, acc.: 100.00%] [G loss: 7.968587] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000778, acc.: 100.00%] [G loss: 8.202582] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000816, acc.: 100.00%] [G loss: 7.698882] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000832, acc.: 100.00%] [G loss: 7.776206] [epoch time: 0.04]\n",
      "18200 [D loss: 0.001197, acc.: 100.00%] [G loss: 7.295154] [epoch time: 0.04]\n",
      "18400 [D loss: 0.001009, acc.: 100.00%] [G loss: 7.859894] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000274, acc.: 100.00%] [G loss: 8.510339] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000363, acc.: 100.00%] [G loss: 8.460033] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000404, acc.: 100.00%] [G loss: 8.352056] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000581, acc.: 100.00%] [G loss: 8.098528] [epoch time: 0.04]\n",
      "19400 [D loss: 0.001075, acc.: 100.00%] [G loss: 8.231218] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000286, acc.: 100.00%] [G loss: 8.448671] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000298, acc.: 100.00%] [G loss: 8.233912] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000343, acc.: 100.00%] [G loss: 8.473634] [epoch time: 0.04]\n",
      "elapsed training time: 9 min, 58 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.738902, acc.: 50.00%] [G loss: 0.929817] [epoch time: 9.61]\n",
      "200 [D loss: 0.245037, acc.: 92.97%] [G loss: 2.142789] [epoch time: 0.04]\n",
      "400 [D loss: 0.079366, acc.: 99.22%] [G loss: 3.495905] [epoch time: 0.04]\n",
      "600 [D loss: 0.023356, acc.: 100.00%] [G loss: 4.970362] [epoch time: 0.04]\n",
      "800 [D loss: 0.006586, acc.: 100.00%] [G loss: 5.512315] [epoch time: 0.04]\n",
      "1000 [D loss: 0.002502, acc.: 100.00%] [G loss: 6.466543] [epoch time: 0.04]\n",
      "1200 [D loss: 0.002834, acc.: 100.00%] [G loss: 6.716066] [epoch time: 0.04]\n",
      "1400 [D loss: 0.001438, acc.: 100.00%] [G loss: 7.132530] [epoch time: 0.04]\n",
      "1600 [D loss: 0.000749, acc.: 100.00%] [G loss: 7.955678] [epoch time: 0.04]\n",
      "1800 [D loss: 0.000767, acc.: 100.00%] [G loss: 7.858432] [epoch time: 0.04]\n",
      "2000 [D loss: 0.000522, acc.: 100.00%] [G loss: 7.943628] [epoch time: 0.04]\n",
      "2200 [D loss: 0.000219, acc.: 100.00%] [G loss: 8.765160] [epoch time: 0.04]\n",
      "2400 [D loss: 0.000277, acc.: 100.00%] [G loss: 9.181953] [epoch time: 0.04]\n",
      "2600 [D loss: 0.000108, acc.: 100.00%] [G loss: 9.456104] [epoch time: 0.04]\n",
      "2800 [D loss: 0.000110, acc.: 100.00%] [G loss: 9.771047] [epoch time: 0.04]\n",
      "3000 [D loss: 0.000083, acc.: 100.00%] [G loss: 9.973623] [epoch time: 0.04]\n",
      "3200 [D loss: 0.000068, acc.: 100.00%] [G loss: 10.186148] [epoch time: 0.04]\n",
      "3400 [D loss: 0.000048, acc.: 100.00%] [G loss: 10.190023] [epoch time: 0.04]\n",
      "3600 [D loss: 0.000110, acc.: 100.00%] [G loss: 10.481112] [epoch time: 0.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800 [D loss: 0.000073, acc.: 100.00%] [G loss: 11.247931] [epoch time: 0.04]\n",
      "4000 [D loss: 0.000019, acc.: 100.00%] [G loss: 11.011753] [epoch time: 0.04]\n",
      "4200 [D loss: 0.000016, acc.: 100.00%] [G loss: 11.599451] [epoch time: 0.04]\n",
      "4400 [D loss: 0.000042, acc.: 100.00%] [G loss: 11.788247] [epoch time: 0.04]\n",
      "4600 [D loss: 0.000011, acc.: 100.00%] [G loss: 12.173189] [epoch time: 0.04]\n",
      "4800 [D loss: 0.000011, acc.: 100.00%] [G loss: 11.977645] [epoch time: 0.04]\n",
      "5000 [D loss: 0.000011, acc.: 100.00%] [G loss: 12.798634] [epoch time: 0.04]\n",
      "5200 [D loss: 0.000005, acc.: 100.00%] [G loss: 12.906839] [epoch time: 0.04]\n",
      "5400 [D loss: 0.000006, acc.: 100.00%] [G loss: 12.792347] [epoch time: 0.04]\n",
      "5600 [D loss: 0.000007, acc.: 100.00%] [G loss: 12.981548] [epoch time: 0.04]\n",
      "5800 [D loss: 0.000002, acc.: 100.00%] [G loss: 13.338526] [epoch time: 0.04]\n",
      "6000 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.658338] [epoch time: 0.04]\n",
      "6200 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.193363] [epoch time: 0.04]\n",
      "6400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.490662] [epoch time: 0.04]\n",
      "6600 [D loss: 0.000005, acc.: 100.00%] [G loss: 14.420444] [epoch time: 0.04]\n",
      "6800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.003052] [epoch time: 0.04]\n",
      "7000 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.784296] [epoch time: 0.04]\n",
      "7200 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.921739] [epoch time: 0.04]\n",
      "7400 [D loss: 0.000001, acc.: 100.00%] [G loss: 14.745580] [epoch time: 0.04]\n",
      "7600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.705530] [epoch time: 0.04]\n",
      "7800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.384619] [epoch time: 0.04]\n",
      "8000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.022339] [epoch time: 0.04]\n",
      "8200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.452600] [epoch time: 0.04]\n",
      "8400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.545273] [epoch time: 0.04]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.833670] [epoch time: 0.04]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.929635] [epoch time: 0.04]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.844149] [epoch time: 0.04]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.081814] [epoch time: 0.04]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.890373] [epoch time: 0.04]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.008293] [epoch time: 0.04]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.877460] [epoch time: 0.04]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.923352] [epoch time: 0.04]\n",
      "10200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.022272] [epoch time: 0.04]\n",
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.033934] [epoch time: 0.04]\n",
      "10600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.015354] [epoch time: 0.04]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.997097] [epoch time: 0.04]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.064468] [epoch time: 0.04]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.059679] [epoch time: 0.04]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.085802] [epoch time: 0.04]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.080124] [epoch time: 0.04]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.100372] [epoch time: 0.04]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109118] [epoch time: 0.04]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.04]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.096550] [epoch time: 0.04]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.104519] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109015] [epoch time: 0.04]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "elapsed training time: 8 min, 25 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_71 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_30 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.758364, acc.: 41.41%] [G loss: 0.529098] [epoch time: 10.75]\n",
      "200 [D loss: 0.786003, acc.: 50.00%] [G loss: 0.803721] [epoch time: 0.07]\n",
      "400 [D loss: 0.821785, acc.: 41.41%] [G loss: 0.783735] [epoch time: 0.07]\n",
      "600 [D loss: 0.814926, acc.: 35.94%] [G loss: 0.750906] [epoch time: 0.07]\n",
      "800 [D loss: 0.778549, acc.: 42.19%] [G loss: 0.797877] [epoch time: 0.07]\n",
      "1000 [D loss: 0.758859, acc.: 46.09%] [G loss: 0.764269] [epoch time: 0.07]\n",
      "1200 [D loss: 0.728630, acc.: 46.88%] [G loss: 0.746775] [epoch time: 0.07]\n",
      "1400 [D loss: 0.735308, acc.: 46.88%] [G loss: 0.748233] [epoch time: 0.07]\n",
      "1600 [D loss: 0.707168, acc.: 49.22%] [G loss: 0.785657] [epoch time: 0.07]\n",
      "1800 [D loss: 0.729500, acc.: 47.66%] [G loss: 0.730588] [epoch time: 0.07]\n",
      "2000 [D loss: 0.687547, acc.: 52.34%] [G loss: 0.771870] [epoch time: 0.07]\n",
      "2200 [D loss: 0.743902, acc.: 45.31%] [G loss: 0.749862] [epoch time: 0.06]\n",
      "2400 [D loss: 0.724289, acc.: 46.88%] [G loss: 0.755589] [epoch time: 0.07]\n",
      "2600 [D loss: 0.703017, acc.: 48.44%] [G loss: 0.697158] [epoch time: 0.07]\n",
      "2800 [D loss: 0.739812, acc.: 42.19%] [G loss: 0.729786] [epoch time: 0.07]\n",
      "3000 [D loss: 0.727785, acc.: 48.44%] [G loss: 0.786352] [epoch time: 0.06]\n",
      "3200 [D loss: 0.716845, acc.: 52.34%] [G loss: 0.760185] [epoch time: 0.07]\n",
      "3400 [D loss: 0.720157, acc.: 49.22%] [G loss: 0.723502] [epoch time: 0.07]\n",
      "3600 [D loss: 0.708077, acc.: 48.44%] [G loss: 0.723314] [epoch time: 0.07]\n",
      "3800 [D loss: 0.698669, acc.: 50.78%] [G loss: 0.774409] [epoch time: 0.07]\n",
      "4000 [D loss: 0.703851, acc.: 47.66%] [G loss: 0.726707] [epoch time: 0.06]\n",
      "4200 [D loss: 0.698365, acc.: 47.66%] [G loss: 0.773160] [epoch time: 0.07]\n",
      "4400 [D loss: 0.703522, acc.: 53.91%] [G loss: 0.733730] [epoch time: 0.07]\n",
      "4600 [D loss: 0.719929, acc.: 44.53%] [G loss: 0.738723] [epoch time: 0.07]\n",
      "4800 [D loss: 0.704421, acc.: 54.69%] [G loss: 0.749482] [epoch time: 0.07]\n",
      "5000 [D loss: 0.717777, acc.: 46.09%] [G loss: 0.696264] [epoch time: 0.07]\n",
      "5200 [D loss: 0.714371, acc.: 47.66%] [G loss: 0.780764] [epoch time: 0.07]\n",
      "5400 [D loss: 0.707812, acc.: 50.00%] [G loss: 0.703520] [epoch time: 0.07]\n",
      "5600 [D loss: 0.705469, acc.: 51.56%] [G loss: 0.743776] [epoch time: 0.07]\n",
      "5800 [D loss: 0.693601, acc.: 46.09%] [G loss: 0.739154] [epoch time: 0.07]\n",
      "6000 [D loss: 0.715488, acc.: 44.53%] [G loss: 0.737272] [epoch time: 0.07]\n",
      "6200 [D loss: 0.704502, acc.: 45.31%] [G loss: 0.717264] [epoch time: 0.07]\n",
      "6400 [D loss: 0.718605, acc.: 42.19%] [G loss: 0.663743] [epoch time: 0.07]\n",
      "6600 [D loss: 0.698699, acc.: 52.34%] [G loss: 0.727861] [epoch time: 0.07]\n",
      "6800 [D loss: 0.712770, acc.: 42.19%] [G loss: 0.716265] [epoch time: 0.07]\n",
      "7000 [D loss: 0.717385, acc.: 49.22%] [G loss: 0.718460] [epoch time: 0.07]\n",
      "7200 [D loss: 0.695078, acc.: 53.91%] [G loss: 0.757549] [epoch time: 0.07]\n",
      "7400 [D loss: 0.711184, acc.: 50.78%] [G loss: 0.713719] [epoch time: 0.07]\n",
      "7600 [D loss: 0.690868, acc.: 54.69%] [G loss: 0.709820] [epoch time: 0.07]\n",
      "7800 [D loss: 0.711075, acc.: 47.66%] [G loss: 0.722789] [epoch time: 0.07]\n",
      "8000 [D loss: 0.697349, acc.: 54.69%] [G loss: 0.723107] [epoch time: 0.07]\n",
      "8200 [D loss: 0.692062, acc.: 50.00%] [G loss: 0.710175] [epoch time: 0.07]\n",
      "8400 [D loss: 0.700077, acc.: 50.78%] [G loss: 0.719468] [epoch time: 0.07]\n",
      "8600 [D loss: 0.706642, acc.: 48.44%] [G loss: 0.707184] [epoch time: 0.07]\n",
      "8800 [D loss: 0.702364, acc.: 50.00%] [G loss: 0.731827] [epoch time: 0.07]\n",
      "9000 [D loss: 0.699366, acc.: 52.34%] [G loss: 0.716215] [epoch time: 0.07]\n",
      "9200 [D loss: 0.698296, acc.: 52.34%] [G loss: 0.706306] [epoch time: 0.07]\n",
      "9400 [D loss: 0.697187, acc.: 51.56%] [G loss: 0.732096] [epoch time: 0.07]\n",
      "9600 [D loss: 0.711056, acc.: 43.75%] [G loss: 0.716121] [epoch time: 0.07]\n",
      "9800 [D loss: 0.715169, acc.: 45.31%] [G loss: 0.707913] [epoch time: 0.06]\n",
      "10000 [D loss: 0.690230, acc.: 49.22%] [G loss: 0.722790] [epoch time: 0.07]\n",
      "10200 [D loss: 0.690781, acc.: 51.56%] [G loss: 0.727804] [epoch time: 0.07]\n",
      "10400 [D loss: 0.704184, acc.: 43.75%] [G loss: 0.710869] [epoch time: 0.07]\n",
      "10600 [D loss: 0.690899, acc.: 52.34%] [G loss: 0.717410] [epoch time: 0.07]\n",
      "10800 [D loss: 0.688913, acc.: 55.47%] [G loss: 0.731924] [epoch time: 0.07]\n",
      "11000 [D loss: 0.706345, acc.: 48.44%] [G loss: 0.723574] [epoch time: 0.07]\n",
      "11200 [D loss: 0.715002, acc.: 44.53%] [G loss: 0.708413] [epoch time: 0.07]\n",
      "11400 [D loss: 0.705612, acc.: 45.31%] [G loss: 0.709322] [epoch time: 0.07]\n",
      "11600 [D loss: 0.708202, acc.: 42.97%] [G loss: 0.685398] [epoch time: 0.07]\n",
      "11800 [D loss: 0.702353, acc.: 50.78%] [G loss: 0.744137] [epoch time: 0.07]\n",
      "12000 [D loss: 0.713232, acc.: 42.19%] [G loss: 0.709719] [epoch time: 0.07]\n",
      "12200 [D loss: 0.706223, acc.: 46.88%] [G loss: 0.717519] [epoch time: 0.07]\n",
      "12400 [D loss: 0.701594, acc.: 47.66%] [G loss: 0.709756] [epoch time: 0.07]\n",
      "12600 [D loss: 0.703103, acc.: 53.12%] [G loss: 0.720396] [epoch time: 0.07]\n",
      "12800 [D loss: 0.693165, acc.: 52.34%] [G loss: 0.715809] [epoch time: 0.07]\n",
      "13000 [D loss: 0.704343, acc.: 47.66%] [G loss: 0.698028] [epoch time: 0.07]\n",
      "13200 [D loss: 0.690317, acc.: 56.25%] [G loss: 0.703893] [epoch time: 0.07]\n",
      "13400 [D loss: 0.701459, acc.: 47.66%] [G loss: 0.722011] [epoch time: 0.07]\n",
      "13600 [D loss: 0.704359, acc.: 47.66%] [G loss: 0.731350] [epoch time: 0.07]\n",
      "13800 [D loss: 0.703908, acc.: 52.34%] [G loss: 0.712317] [epoch time: 0.07]\n",
      "14000 [D loss: 0.693265, acc.: 51.56%] [G loss: 0.704297] [epoch time: 0.07]\n",
      "14200 [D loss: 0.692383, acc.: 51.56%] [G loss: 0.730035] [epoch time: 0.07]\n",
      "14400 [D loss: 0.694505, acc.: 53.91%] [G loss: 0.694530] [epoch time: 0.07]\n",
      "14600 [D loss: 0.697537, acc.: 46.88%] [G loss: 0.725509] [epoch time: 0.07]\n",
      "14800 [D loss: 0.696863, acc.: 52.34%] [G loss: 0.723541] [epoch time: 0.07]\n",
      "15000 [D loss: 0.714569, acc.: 42.19%] [G loss: 0.722043] [epoch time: 0.06]\n",
      "15200 [D loss: 0.701708, acc.: 42.97%] [G loss: 0.731754] [epoch time: 0.07]\n",
      "15400 [D loss: 0.699094, acc.: 48.44%] [G loss: 0.708486] [epoch time: 0.07]\n",
      "15600 [D loss: 0.684883, acc.: 53.91%] [G loss: 0.708571] [epoch time: 0.07]\n",
      "15800 [D loss: 0.699394, acc.: 49.22%] [G loss: 0.727461] [epoch time: 0.07]\n",
      "16000 [D loss: 0.705799, acc.: 48.44%] [G loss: 0.737712] [epoch time: 0.07]\n",
      "16200 [D loss: 0.700662, acc.: 44.53%] [G loss: 0.722588] [epoch time: 0.07]\n",
      "16400 [D loss: 0.698728, acc.: 51.56%] [G loss: 0.714481] [epoch time: 0.07]\n",
      "16600 [D loss: 0.694872, acc.: 57.03%] [G loss: 0.690695] [epoch time: 0.07]\n",
      "16800 [D loss: 0.692082, acc.: 53.12%] [G loss: 0.699241] [epoch time: 0.07]\n",
      "17000 [D loss: 0.704317, acc.: 48.44%] [G loss: 0.710093] [epoch time: 0.07]\n",
      "17200 [D loss: 0.698892, acc.: 50.00%] [G loss: 0.729447] [epoch time: 0.07]\n",
      "17400 [D loss: 0.699428, acc.: 47.66%] [G loss: 0.716414] [epoch time: 0.07]\n",
      "17600 [D loss: 0.696677, acc.: 45.31%] [G loss: 0.714048] [epoch time: 0.07]\n",
      "17800 [D loss: 0.704208, acc.: 46.88%] [G loss: 0.735036] [epoch time: 0.06]\n",
      "18000 [D loss: 0.699158, acc.: 50.00%] [G loss: 0.688095] [epoch time: 0.07]\n",
      "18200 [D loss: 0.703208, acc.: 45.31%] [G loss: 0.711788] [epoch time: 0.07]\n",
      "18400 [D loss: 0.693860, acc.: 50.00%] [G loss: 0.719664] [epoch time: 0.07]\n",
      "18600 [D loss: 0.698269, acc.: 52.34%] [G loss: 0.712924] [epoch time: 0.07]\n",
      "18800 [D loss: 0.703602, acc.: 47.66%] [G loss: 0.719161] [epoch time: 0.07]\n",
      "19000 [D loss: 0.703763, acc.: 48.44%] [G loss: 0.728437] [epoch time: 0.07]\n",
      "19200 [D loss: 0.687564, acc.: 52.34%] [G loss: 0.716413] [epoch time: 0.07]\n",
      "19400 [D loss: 0.704371, acc.: 45.31%] [G loss: 0.704917] [epoch time: 0.07]\n",
      "19600 [D loss: 0.708282, acc.: 46.09%] [G loss: 0.707483] [epoch time: 0.07]\n",
      "19800 [D loss: 0.695309, acc.: 50.00%] [G loss: 0.721022] [epoch time: 0.07]\n",
      "20000 [D loss: 0.688565, acc.: 49.22%] [G loss: 0.725127] [epoch time: 0.06]\n",
      "elapsed training time: 22 min, 59 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_31 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_32 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.762717, acc.: 53.91%] [G loss: 1.116913] [epoch time: 12.09]\n",
      "200 [D loss: 0.780453, acc.: 45.31%] [G loss: 0.809675] [epoch time: 0.06]\n",
      "400 [D loss: 0.760692, acc.: 45.31%] [G loss: 0.918605] [epoch time: 0.07]\n",
      "600 [D loss: 0.724547, acc.: 51.56%] [G loss: 0.825244] [epoch time: 0.07]\n",
      "800 [D loss: 0.676823, acc.: 62.50%] [G loss: 0.846291] [epoch time: 0.06]\n",
      "1000 [D loss: 0.659230, acc.: 58.59%] [G loss: 0.832640] [epoch time: 0.07]\n",
      "1200 [D loss: 0.731138, acc.: 47.66%] [G loss: 0.830210] [epoch time: 0.06]\n",
      "1400 [D loss: 0.744377, acc.: 49.22%] [G loss: 0.843290] [epoch time: 0.07]\n",
      "1600 [D loss: 0.696114, acc.: 55.47%] [G loss: 0.830848] [epoch time: 0.06]\n",
      "1800 [D loss: 0.751160, acc.: 45.31%] [G loss: 0.802705] [epoch time: 0.06]\n",
      "2000 [D loss: 0.703085, acc.: 54.69%] [G loss: 0.791475] [epoch time: 0.06]\n",
      "2200 [D loss: 0.699670, acc.: 53.91%] [G loss: 0.781795] [epoch time: 0.06]\n",
      "2400 [D loss: 0.664533, acc.: 56.25%] [G loss: 0.863964] [epoch time: 0.06]\n",
      "2600 [D loss: 0.688810, acc.: 53.91%] [G loss: 0.782290] [epoch time: 0.06]\n",
      "2800 [D loss: 0.670605, acc.: 58.59%] [G loss: 0.793357] [epoch time: 0.06]\n",
      "3000 [D loss: 0.660192, acc.: 57.81%] [G loss: 0.817997] [epoch time: 0.07]\n",
      "3200 [D loss: 0.698658, acc.: 55.47%] [G loss: 0.726142] [epoch time: 0.06]\n",
      "3400 [D loss: 0.731757, acc.: 45.31%] [G loss: 0.726272] [epoch time: 0.07]\n",
      "3600 [D loss: 0.673309, acc.: 64.06%] [G loss: 0.792872] [epoch time: 0.06]\n",
      "3800 [D loss: 0.659746, acc.: 60.94%] [G loss: 0.822519] [epoch time: 0.06]\n",
      "4000 [D loss: 0.694170, acc.: 56.25%] [G loss: 0.825079] [epoch time: 0.07]\n",
      "4200 [D loss: 0.689116, acc.: 54.69%] [G loss: 0.824837] [epoch time: 0.07]\n",
      "4400 [D loss: 0.728392, acc.: 46.09%] [G loss: 0.824595] [epoch time: 0.07]\n",
      "4600 [D loss: 0.698636, acc.: 55.47%] [G loss: 0.761503] [epoch time: 0.07]\n",
      "4800 [D loss: 0.669407, acc.: 54.69%] [G loss: 0.773894] [epoch time: 0.07]\n",
      "5000 [D loss: 0.715338, acc.: 48.44%] [G loss: 0.781095] [epoch time: 0.07]\n",
      "5200 [D loss: 0.700484, acc.: 50.00%] [G loss: 0.744910] [epoch time: 0.06]\n",
      "5400 [D loss: 0.745062, acc.: 40.62%] [G loss: 0.761119] [epoch time: 0.06]\n",
      "5600 [D loss: 0.720201, acc.: 53.91%] [G loss: 0.780023] [epoch time: 0.07]\n",
      "5800 [D loss: 0.716773, acc.: 47.66%] [G loss: 0.786238] [epoch time: 0.06]\n",
      "6000 [D loss: 0.686881, acc.: 55.47%] [G loss: 0.788139] [epoch time: 0.06]\n",
      "6200 [D loss: 0.686779, acc.: 57.03%] [G loss: 0.778856] [epoch time: 0.06]\n",
      "6400 [D loss: 0.668252, acc.: 57.03%] [G loss: 0.721101] [epoch time: 0.06]\n",
      "6600 [D loss: 0.693398, acc.: 50.78%] [G loss: 0.751945] [epoch time: 0.06]\n",
      "6800 [D loss: 0.674987, acc.: 55.47%] [G loss: 0.776774] [epoch time: 0.07]\n",
      "7000 [D loss: 0.747021, acc.: 40.62%] [G loss: 0.777376] [epoch time: 0.06]\n",
      "7200 [D loss: 0.681563, acc.: 59.38%] [G loss: 0.741492] [epoch time: 0.06]\n",
      "7400 [D loss: 0.641590, acc.: 67.19%] [G loss: 0.798421] [epoch time: 0.06]\n",
      "7600 [D loss: 0.680400, acc.: 57.03%] [G loss: 0.801468] [epoch time: 0.07]\n",
      "7800 [D loss: 0.639083, acc.: 68.75%] [G loss: 0.804096] [epoch time: 0.06]\n",
      "8000 [D loss: 0.708576, acc.: 51.56%] [G loss: 0.729735] [epoch time: 0.06]\n",
      "8200 [D loss: 0.691585, acc.: 53.91%] [G loss: 0.699061] [epoch time: 0.06]\n",
      "8400 [D loss: 0.668420, acc.: 60.16%] [G loss: 0.785664] [epoch time: 0.06]\n",
      "8600 [D loss: 0.671315, acc.: 57.81%] [G loss: 0.785287] [epoch time: 0.06]\n",
      "8800 [D loss: 0.721990, acc.: 49.22%] [G loss: 0.733117] [epoch time: 0.06]\n",
      "9000 [D loss: 0.707945, acc.: 50.78%] [G loss: 0.730763] [epoch time: 0.06]\n",
      "9200 [D loss: 0.711736, acc.: 50.78%] [G loss: 0.773936] [epoch time: 0.06]\n",
      "9400 [D loss: 0.702734, acc.: 53.12%] [G loss: 0.745569] [epoch time: 0.07]\n",
      "9600 [D loss: 0.631671, acc.: 69.53%] [G loss: 0.765531] [epoch time: 0.06]\n",
      "9800 [D loss: 0.697701, acc.: 55.47%] [G loss: 0.782169] [epoch time: 0.06]\n",
      "10000 [D loss: 0.703992, acc.: 53.91%] [G loss: 0.747082] [epoch time: 0.06]\n",
      "10200 [D loss: 0.721331, acc.: 45.31%] [G loss: 0.766363] [epoch time: 0.06]\n",
      "10400 [D loss: 0.698626, acc.: 51.56%] [G loss: 0.703909] [epoch time: 0.07]\n",
      "10600 [D loss: 0.738021, acc.: 42.19%] [G loss: 0.701886] [epoch time: 0.07]\n",
      "10800 [D loss: 0.726529, acc.: 48.44%] [G loss: 0.777768] [epoch time: 0.06]\n",
      "11000 [D loss: 0.696655, acc.: 56.25%] [G loss: 0.735962] [epoch time: 0.07]\n",
      "11200 [D loss: 0.681330, acc.: 57.81%] [G loss: 0.756243] [epoch time: 0.06]\n",
      "11400 [D loss: 0.684711, acc.: 61.72%] [G loss: 0.791399] [epoch time: 0.06]\n",
      "11600 [D loss: 0.743449, acc.: 42.97%] [G loss: 0.721547] [epoch time: 0.06]\n",
      "11800 [D loss: 0.693398, acc.: 56.25%] [G loss: 0.766311] [epoch time: 0.06]\n",
      "12000 [D loss: 0.734583, acc.: 44.53%] [G loss: 0.786710] [epoch time: 0.06]\n",
      "12200 [D loss: 0.682513, acc.: 57.81%] [G loss: 0.756761] [epoch time: 0.06]\n",
      "12400 [D loss: 0.698554, acc.: 50.78%] [G loss: 0.796357] [epoch time: 0.06]\n",
      "12600 [D loss: 0.668109, acc.: 57.81%] [G loss: 0.792559] [epoch time: 0.06]\n",
      "12800 [D loss: 0.707177, acc.: 52.34%] [G loss: 0.749686] [epoch time: 0.06]\n",
      "13000 [D loss: 0.695976, acc.: 50.78%] [G loss: 0.737571] [epoch time: 0.06]\n",
      "13200 [D loss: 0.677001, acc.: 54.69%] [G loss: 0.782854] [epoch time: 0.06]\n",
      "13400 [D loss: 0.721255, acc.: 47.66%] [G loss: 0.792823] [epoch time: 0.06]\n",
      "13600 [D loss: 0.709045, acc.: 57.81%] [G loss: 0.756587] [epoch time: 0.06]\n",
      "13800 [D loss: 0.592375, acc.: 74.22%] [G loss: 0.846715] [epoch time: 0.06]\n",
      "14000 [D loss: 0.655420, acc.: 63.28%] [G loss: 0.770591] [epoch time: 0.06]\n",
      "14200 [D loss: 0.709625, acc.: 49.22%] [G loss: 0.728501] [epoch time: 0.07]\n",
      "14400 [D loss: 0.710702, acc.: 48.44%] [G loss: 0.805844] [epoch time: 0.06]\n",
      "14600 [D loss: 0.667612, acc.: 60.94%] [G loss: 0.746885] [epoch time: 0.07]\n",
      "14800 [D loss: 0.694691, acc.: 55.47%] [G loss: 0.712722] [epoch time: 0.07]\n",
      "15000 [D loss: 0.730512, acc.: 43.75%] [G loss: 0.759015] [epoch time: 0.06]\n",
      "15200 [D loss: 0.695166, acc.: 51.56%] [G loss: 0.735461] [epoch time: 0.06]\n",
      "15400 [D loss: 0.722975, acc.: 45.31%] [G loss: 0.749204] [epoch time: 0.07]\n",
      "15600 [D loss: 0.713610, acc.: 46.88%] [G loss: 0.757459] [epoch time: 0.07]\n",
      "15800 [D loss: 0.700566, acc.: 49.22%] [G loss: 0.704091] [epoch time: 0.06]\n",
      "16000 [D loss: 0.661080, acc.: 60.94%] [G loss: 0.773775] [epoch time: 0.06]\n",
      "16200 [D loss: 0.735302, acc.: 44.53%] [G loss: 0.746206] [epoch time: 0.06]\n",
      "16400 [D loss: 0.704492, acc.: 53.12%] [G loss: 0.740076] [epoch time: 0.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.681729, acc.: 54.69%] [G loss: 0.732888] [epoch time: 0.07]\n",
      "16800 [D loss: 0.677414, acc.: 52.34%] [G loss: 0.682912] [epoch time: 0.06]\n",
      "17000 [D loss: 0.598919, acc.: 71.09%] [G loss: 0.728768] [epoch time: 0.06]\n",
      "17200 [D loss: 0.652735, acc.: 64.84%] [G loss: 0.752142] [epoch time: 0.07]\n",
      "17400 [D loss: 0.665769, acc.: 61.72%] [G loss: 0.735902] [epoch time: 0.06]\n",
      "17600 [D loss: 0.664569, acc.: 59.38%] [G loss: 0.855004] [epoch time: 0.07]\n",
      "17800 [D loss: 0.675700, acc.: 53.12%] [G loss: 0.778850] [epoch time: 0.06]\n",
      "18000 [D loss: 0.688663, acc.: 54.69%] [G loss: 0.742150] [epoch time: 0.06]\n",
      "18200 [D loss: 0.646384, acc.: 67.19%] [G loss: 0.811509] [epoch time: 0.06]\n",
      "18400 [D loss: 0.697764, acc.: 54.69%] [G loss: 0.743856] [epoch time: 0.06]\n",
      "18600 [D loss: 0.736196, acc.: 40.62%] [G loss: 0.730072] [epoch time: 0.06]\n",
      "18800 [D loss: 0.727392, acc.: 46.09%] [G loss: 0.749971] [epoch time: 0.06]\n",
      "19000 [D loss: 0.685878, acc.: 51.56%] [G loss: 0.742254] [epoch time: 0.06]\n",
      "19200 [D loss: 0.718778, acc.: 48.44%] [G loss: 0.771339] [epoch time: 0.06]\n",
      "19400 [D loss: 0.720509, acc.: 49.22%] [G loss: 0.706080] [epoch time: 0.06]\n",
      "19600 [D loss: 0.704932, acc.: 55.47%] [G loss: 0.730069] [epoch time: 0.06]\n",
      "19800 [D loss: 0.671498, acc.: 57.03%] [G loss: 0.766997] [epoch time: 0.06]\n",
      "20000 [D loss: 0.679713, acc.: 57.03%] [G loss: 0.783760] [epoch time: 0.06]\n",
      "elapsed training time: 16 min, 26 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_17 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_33 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_34 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.562472, acc.: 60.94%] [G loss: 0.659743] [epoch time: 11.91]\n",
      "200 [D loss: 0.818806, acc.: 45.31%] [G loss: 0.889403] [epoch time: 0.03]\n",
      "400 [D loss: 0.777528, acc.: 48.44%] [G loss: 0.975446] [epoch time: 0.03]\n",
      "600 [D loss: 0.743626, acc.: 50.78%] [G loss: 0.857768] [epoch time: 0.06]\n",
      "800 [D loss: 0.761434, acc.: 45.31%] [G loss: 0.773367] [epoch time: 0.03]\n",
      "1000 [D loss: 0.764440, acc.: 52.34%] [G loss: 0.770944] [epoch time: 0.03]\n",
      "1200 [D loss: 0.735167, acc.: 50.78%] [G loss: 0.828463] [epoch time: 0.07]\n",
      "1400 [D loss: 0.695859, acc.: 55.47%] [G loss: 0.854676] [epoch time: 0.03]\n",
      "1600 [D loss: 0.739430, acc.: 51.56%] [G loss: 0.908398] [epoch time: 0.03]\n",
      "1800 [D loss: 0.698538, acc.: 50.00%] [G loss: 0.807395] [epoch time: 0.06]\n",
      "2000 [D loss: 0.678497, acc.: 59.38%] [G loss: 0.835823] [epoch time: 0.03]\n",
      "2200 [D loss: 0.638014, acc.: 71.09%] [G loss: 0.819549] [epoch time: 0.03]\n",
      "2400 [D loss: 0.703269, acc.: 49.22%] [G loss: 0.880213] [epoch time: 0.06]\n",
      "2600 [D loss: 0.667543, acc.: 61.72%] [G loss: 0.855706] [epoch time: 0.03]\n",
      "2800 [D loss: 0.700660, acc.: 55.47%] [G loss: 0.871666] [epoch time: 0.03]\n",
      "3000 [D loss: 0.723484, acc.: 51.56%] [G loss: 0.839266] [epoch time: 0.06]\n",
      "3200 [D loss: 0.699416, acc.: 50.78%] [G loss: 0.768358] [epoch time: 0.03]\n",
      "3400 [D loss: 0.706634, acc.: 48.44%] [G loss: 0.863928] [epoch time: 0.03]\n",
      "3600 [D loss: 0.689754, acc.: 53.91%] [G loss: 0.859917] [epoch time: 0.06]\n",
      "3800 [D loss: 0.684105, acc.: 55.47%] [G loss: 0.773150] [epoch time: 0.03]\n",
      "4000 [D loss: 0.701761, acc.: 52.34%] [G loss: 0.811336] [epoch time: 0.03]\n",
      "4200 [D loss: 0.646064, acc.: 59.38%] [G loss: 0.855286] [epoch time: 0.06]\n",
      "4400 [D loss: 0.707275, acc.: 52.34%] [G loss: 0.850002] [epoch time: 0.03]\n",
      "4600 [D loss: 0.771622, acc.: 40.62%] [G loss: 0.758752] [epoch time: 0.03]\n",
      "4800 [D loss: 0.662377, acc.: 61.72%] [G loss: 0.859564] [epoch time: 0.06]\n",
      "5000 [D loss: 0.694958, acc.: 53.12%] [G loss: 0.880874] [epoch time: 0.03]\n",
      "5200 [D loss: 0.636728, acc.: 74.22%] [G loss: 0.850839] [epoch time: 0.03]\n",
      "5400 [D loss: 0.671593, acc.: 59.38%] [G loss: 0.874437] [epoch time: 0.07]\n",
      "5600 [D loss: 0.727420, acc.: 45.31%] [G loss: 0.862193] [epoch time: 0.03]\n",
      "5800 [D loss: 0.728126, acc.: 47.66%] [G loss: 0.790960] [epoch time: 0.03]\n",
      "6000 [D loss: 0.644175, acc.: 62.50%] [G loss: 0.768667] [epoch time: 0.06]\n",
      "6200 [D loss: 0.701231, acc.: 49.22%] [G loss: 0.817904] [epoch time: 0.03]\n",
      "6400 [D loss: 0.670827, acc.: 54.69%] [G loss: 0.768517] [epoch time: 0.03]\n",
      "6600 [D loss: 0.607633, acc.: 71.09%] [G loss: 0.848948] [epoch time: 0.06]\n",
      "6800 [D loss: 0.624522, acc.: 65.62%] [G loss: 0.772114] [epoch time: 0.03]\n",
      "7000 [D loss: 0.700710, acc.: 53.91%] [G loss: 0.759614] [epoch time: 0.03]\n",
      "7200 [D loss: 0.600206, acc.: 71.88%] [G loss: 0.870050] [epoch time: 0.06]\n",
      "7400 [D loss: 0.713865, acc.: 50.00%] [G loss: 0.789264] [epoch time: 0.03]\n",
      "7600 [D loss: 0.711886, acc.: 54.69%] [G loss: 0.737603] [epoch time: 0.03]\n",
      "7800 [D loss: 0.631335, acc.: 62.50%] [G loss: 0.854119] [epoch time: 0.06]\n",
      "8000 [D loss: 0.675790, acc.: 55.47%] [G loss: 0.819192] [epoch time: 0.03]\n",
      "8200 [D loss: 0.674902, acc.: 60.94%] [G loss: 0.887392] [epoch time: 0.03]\n",
      "8400 [D loss: 0.678985, acc.: 57.81%] [G loss: 0.774006] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600 [D loss: 0.718985, acc.: 50.78%] [G loss: 0.845888] [epoch time: 0.03]\n",
      "8800 [D loss: 0.675109, acc.: 56.25%] [G loss: 0.799870] [epoch time: 0.03]\n",
      "9000 [D loss: 0.607449, acc.: 73.44%] [G loss: 0.804722] [epoch time: 0.06]\n",
      "9200 [D loss: 0.625366, acc.: 65.62%] [G loss: 0.775362] [epoch time: 0.03]\n",
      "9400 [D loss: 0.653143, acc.: 62.50%] [G loss: 0.805588] [epoch time: 0.03]\n",
      "9600 [D loss: 0.676823, acc.: 53.91%] [G loss: 0.825168] [epoch time: 0.06]\n",
      "9800 [D loss: 0.763928, acc.: 47.66%] [G loss: 0.781081] [epoch time: 0.03]\n",
      "10000 [D loss: 0.667262, acc.: 56.25%] [G loss: 0.880612] [epoch time: 0.03]\n",
      "10200 [D loss: 0.669921, acc.: 55.47%] [G loss: 0.735975] [epoch time: 0.07]\n",
      "10400 [D loss: 0.710880, acc.: 50.00%] [G loss: 0.717265] [epoch time: 0.03]\n",
      "10600 [D loss: 0.686467, acc.: 52.34%] [G loss: 0.889014] [epoch time: 0.03]\n",
      "10800 [D loss: 0.713774, acc.: 49.22%] [G loss: 0.764721] [epoch time: 0.06]\n",
      "11000 [D loss: 0.696596, acc.: 57.03%] [G loss: 0.786173] [epoch time: 0.03]\n",
      "11200 [D loss: 0.595971, acc.: 71.09%] [G loss: 0.692860] [epoch time: 0.03]\n",
      "11400 [D loss: 0.603139, acc.: 73.44%] [G loss: 0.851338] [epoch time: 0.07]\n",
      "11600 [D loss: 0.666821, acc.: 61.72%] [G loss: 0.791142] [epoch time: 0.03]\n",
      "11800 [D loss: 0.722872, acc.: 51.56%] [G loss: 0.727810] [epoch time: 0.03]\n",
      "12000 [D loss: 0.682086, acc.: 57.81%] [G loss: 0.823242] [epoch time: 0.06]\n",
      "12200 [D loss: 0.675247, acc.: 57.03%] [G loss: 0.774661] [epoch time: 0.03]\n",
      "12400 [D loss: 0.715072, acc.: 50.00%] [G loss: 0.737604] [epoch time: 0.03]\n",
      "12600 [D loss: 0.677998, acc.: 55.47%] [G loss: 0.855514] [epoch time: 0.06]\n",
      "12800 [D loss: 0.644217, acc.: 64.06%] [G loss: 0.798316] [epoch time: 0.03]\n",
      "13000 [D loss: 0.714480, acc.: 53.12%] [G loss: 0.768633] [epoch time: 0.03]\n",
      "13200 [D loss: 0.705275, acc.: 49.22%] [G loss: 0.833576] [epoch time: 0.06]\n",
      "13400 [D loss: 0.734150, acc.: 44.53%] [G loss: 0.770344] [epoch time: 0.03]\n",
      "13600 [D loss: 0.651612, acc.: 62.50%] [G loss: 0.869743] [epoch time: 0.03]\n",
      "13800 [D loss: 0.640624, acc.: 67.19%] [G loss: 0.794790] [epoch time: 0.06]\n",
      "14000 [D loss: 0.780026, acc.: 40.62%] [G loss: 0.876602] [epoch time: 0.03]\n",
      "14200 [D loss: 0.610948, acc.: 68.75%] [G loss: 0.830038] [epoch time: 0.03]\n",
      "14400 [D loss: 0.719985, acc.: 46.88%] [G loss: 0.706060] [epoch time: 0.06]\n",
      "14600 [D loss: 0.706874, acc.: 50.78%] [G loss: 0.790154] [epoch time: 0.03]\n",
      "14800 [D loss: 0.719517, acc.: 52.34%] [G loss: 0.838769] [epoch time: 0.03]\n",
      "15000 [D loss: 0.652046, acc.: 64.06%] [G loss: 0.811275] [epoch time: 0.07]\n",
      "15200 [D loss: 0.655693, acc.: 60.94%] [G loss: 0.809674] [epoch time: 0.03]\n",
      "15400 [D loss: 0.639236, acc.: 64.06%] [G loss: 0.870125] [epoch time: 0.03]\n",
      "15600 [D loss: 0.634441, acc.: 64.06%] [G loss: 0.888864] [epoch time: 0.06]\n",
      "15800 [D loss: 0.732191, acc.: 48.44%] [G loss: 0.846601] [epoch time: 0.03]\n",
      "16000 [D loss: 0.700776, acc.: 56.25%] [G loss: 0.746395] [epoch time: 0.03]\n",
      "16200 [D loss: 0.725693, acc.: 46.09%] [G loss: 0.841321] [epoch time: 0.06]\n",
      "16400 [D loss: 0.577458, acc.: 82.03%] [G loss: 0.700145] [epoch time: 0.03]\n",
      "16600 [D loss: 0.717883, acc.: 50.00%] [G loss: 0.780841] [epoch time: 0.03]\n",
      "16800 [D loss: 0.711088, acc.: 53.91%] [G loss: 0.764885] [epoch time: 0.06]\n",
      "17000 [D loss: 0.666098, acc.: 60.16%] [G loss: 0.895857] [epoch time: 0.03]\n",
      "17200 [D loss: 0.690251, acc.: 55.47%] [G loss: 0.750937] [epoch time: 0.03]\n",
      "17400 [D loss: 0.650671, acc.: 65.62%] [G loss: 0.800146] [epoch time: 0.06]\n",
      "17600 [D loss: 0.667092, acc.: 59.38%] [G loss: 0.843047] [epoch time: 0.03]\n",
      "17800 [D loss: 0.692596, acc.: 58.59%] [G loss: 0.801102] [epoch time: 0.03]\n",
      "18000 [D loss: 0.664632, acc.: 60.94%] [G loss: 0.855636] [epoch time: 0.06]\n",
      "18200 [D loss: 0.625457, acc.: 64.84%] [G loss: 0.695699] [epoch time: 0.03]\n",
      "18400 [D loss: 0.681361, acc.: 56.25%] [G loss: 0.770417] [epoch time: 0.03]\n",
      "18600 [D loss: 0.700968, acc.: 53.12%] [G loss: 0.743924] [epoch time: 0.06]\n",
      "18800 [D loss: 0.655415, acc.: 62.50%] [G loss: 0.833374] [epoch time: 0.03]\n",
      "19000 [D loss: 0.667755, acc.: 60.94%] [G loss: 0.783207] [epoch time: 0.03]\n",
      "19200 [D loss: 0.703882, acc.: 57.03%] [G loss: 0.771282] [epoch time: 0.06]\n",
      "19400 [D loss: 0.678010, acc.: 57.03%] [G loss: 0.789968] [epoch time: 0.03]\n",
      "19600 [D loss: 0.714559, acc.: 48.44%] [G loss: 0.754181] [epoch time: 0.03]\n",
      "19800 [D loss: 0.655145, acc.: 58.59%] [G loss: 0.721269] [epoch time: 0.06]\n",
      "20000 [D loss: 0.701597, acc.: 48.44%] [G loss: 0.788357] [epoch time: 0.03]\n",
      "elapsed training time: 14 min, 25 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_86 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_35 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.709171, acc.: 49.22%] [G loss: 0.754323] [epoch time: 12.51]\n",
      "200 [D loss: 0.874808, acc.: 43.75%] [G loss: 0.772235] [epoch time: 0.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 [D loss: 0.873656, acc.: 36.72%] [G loss: 0.820503] [epoch time: 0.05]\n",
      "600 [D loss: 0.853121, acc.: 37.50%] [G loss: 0.759046] [epoch time: 0.07]\n",
      "800 [D loss: 0.812623, acc.: 42.19%] [G loss: 0.699305] [epoch time: 0.05]\n",
      "1000 [D loss: 0.821578, acc.: 44.53%] [G loss: 0.748928] [epoch time: 0.05]\n",
      "1200 [D loss: 0.836141, acc.: 31.25%] [G loss: 0.747428] [epoch time: 0.07]\n",
      "1400 [D loss: 0.778649, acc.: 43.75%] [G loss: 0.832285] [epoch time: 0.05]\n",
      "1600 [D loss: 0.777765, acc.: 42.97%] [G loss: 0.733941] [epoch time: 0.05]\n",
      "1800 [D loss: 0.746388, acc.: 46.09%] [G loss: 0.861735] [epoch time: 0.07]\n",
      "2000 [D loss: 0.804375, acc.: 37.50%] [G loss: 0.745250] [epoch time: 0.05]\n",
      "2200 [D loss: 0.775131, acc.: 42.19%] [G loss: 0.725751] [epoch time: 0.05]\n",
      "2400 [D loss: 0.769823, acc.: 36.72%] [G loss: 0.721588] [epoch time: 0.07]\n",
      "2600 [D loss: 0.776665, acc.: 46.88%] [G loss: 0.793090] [epoch time: 0.05]\n",
      "2800 [D loss: 0.755350, acc.: 42.19%] [G loss: 0.752207] [epoch time: 0.05]\n",
      "3000 [D loss: 0.711338, acc.: 47.66%] [G loss: 0.746424] [epoch time: 0.07]\n",
      "3200 [D loss: 0.757328, acc.: 47.66%] [G loss: 0.695237] [epoch time: 0.05]\n",
      "3400 [D loss: 0.730695, acc.: 49.22%] [G loss: 0.741161] [epoch time: 0.05]\n",
      "3600 [D loss: 0.748759, acc.: 46.88%] [G loss: 0.773673] [epoch time: 0.07]\n",
      "3800 [D loss: 0.753034, acc.: 44.53%] [G loss: 0.776427] [epoch time: 0.05]\n",
      "4000 [D loss: 0.763830, acc.: 46.88%] [G loss: 0.689246] [epoch time: 0.05]\n",
      "4200 [D loss: 0.744109, acc.: 45.31%] [G loss: 0.777172] [epoch time: 0.07]\n",
      "4400 [D loss: 0.741686, acc.: 40.62%] [G loss: 0.702159] [epoch time: 0.05]\n",
      "4600 [D loss: 0.724642, acc.: 46.09%] [G loss: 0.719952] [epoch time: 0.05]\n",
      "4800 [D loss: 0.731269, acc.: 50.00%] [G loss: 0.706212] [epoch time: 0.07]\n",
      "5000 [D loss: 0.723883, acc.: 46.09%] [G loss: 0.747969] [epoch time: 0.05]\n",
      "5200 [D loss: 0.755410, acc.: 37.50%] [G loss: 0.728842] [epoch time: 0.05]\n",
      "5400 [D loss: 0.752454, acc.: 44.53%] [G loss: 0.720105] [epoch time: 0.07]\n",
      "5600 [D loss: 0.729807, acc.: 42.97%] [G loss: 0.705716] [epoch time: 0.05]\n",
      "5800 [D loss: 0.760775, acc.: 42.97%] [G loss: 0.722890] [epoch time: 0.05]\n",
      "6000 [D loss: 0.741117, acc.: 41.41%] [G loss: 0.699286] [epoch time: 0.07]\n",
      "6200 [D loss: 0.769000, acc.: 34.38%] [G loss: 0.738753] [epoch time: 0.05]\n",
      "6400 [D loss: 0.722176, acc.: 44.53%] [G loss: 0.694055] [epoch time: 0.05]\n",
      "6600 [D loss: 0.720815, acc.: 46.88%] [G loss: 0.734088] [epoch time: 0.07]\n",
      "6800 [D loss: 0.742336, acc.: 39.84%] [G loss: 0.727879] [epoch time: 0.05]\n",
      "7000 [D loss: 0.741403, acc.: 41.41%] [G loss: 0.780785] [epoch time: 0.05]\n",
      "7200 [D loss: 0.728897, acc.: 45.31%] [G loss: 0.704646] [epoch time: 0.07]\n",
      "7400 [D loss: 0.744792, acc.: 39.84%] [G loss: 0.661008] [epoch time: 0.05]\n",
      "7600 [D loss: 0.723112, acc.: 42.19%] [G loss: 0.731931] [epoch time: 0.05]\n",
      "7800 [D loss: 0.735109, acc.: 46.88%] [G loss: 0.739799] [epoch time: 0.07]\n",
      "8000 [D loss: 0.711912, acc.: 47.66%] [G loss: 0.721691] [epoch time: 0.05]\n",
      "8200 [D loss: 0.728770, acc.: 46.09%] [G loss: 0.742608] [epoch time: 0.05]\n",
      "8400 [D loss: 0.714218, acc.: 45.31%] [G loss: 0.750152] [epoch time: 0.07]\n",
      "8600 [D loss: 0.740999, acc.: 41.41%] [G loss: 0.707149] [epoch time: 0.05]\n",
      "8800 [D loss: 0.728338, acc.: 43.75%] [G loss: 0.726779] [epoch time: 0.05]\n",
      "9000 [D loss: 0.714253, acc.: 45.31%] [G loss: 0.705739] [epoch time: 0.07]\n",
      "9200 [D loss: 0.736554, acc.: 42.19%] [G loss: 0.740427] [epoch time: 0.05]\n",
      "9400 [D loss: 0.739801, acc.: 42.97%] [G loss: 0.706156] [epoch time: 0.05]\n",
      "9600 [D loss: 0.712648, acc.: 47.66%] [G loss: 0.715500] [epoch time: 0.07]\n",
      "9800 [D loss: 0.741135, acc.: 35.94%] [G loss: 0.720457] [epoch time: 0.05]\n",
      "10000 [D loss: 0.736344, acc.: 39.06%] [G loss: 0.713825] [epoch time: 0.05]\n",
      "10200 [D loss: 0.727855, acc.: 43.75%] [G loss: 0.703314] [epoch time: 0.07]\n",
      "10400 [D loss: 0.730063, acc.: 39.06%] [G loss: 0.716576] [epoch time: 0.05]\n",
      "10600 [D loss: 0.737365, acc.: 40.62%] [G loss: 0.712306] [epoch time: 0.05]\n",
      "10800 [D loss: 0.749461, acc.: 35.16%] [G loss: 0.706445] [epoch time: 0.07]\n",
      "11000 [D loss: 0.720747, acc.: 42.19%] [G loss: 0.704701] [epoch time: 0.05]\n",
      "11200 [D loss: 0.740582, acc.: 39.06%] [G loss: 0.708877] [epoch time: 0.05]\n",
      "11400 [D loss: 0.722007, acc.: 46.09%] [G loss: 0.719011] [epoch time: 0.07]\n",
      "11600 [D loss: 0.726848, acc.: 43.75%] [G loss: 0.721214] [epoch time: 0.05]\n",
      "11800 [D loss: 0.730821, acc.: 39.84%] [G loss: 0.723039] [epoch time: 0.05]\n",
      "12000 [D loss: 0.728499, acc.: 42.19%] [G loss: 0.690418] [epoch time: 0.07]\n",
      "12200 [D loss: 0.725521, acc.: 35.16%] [G loss: 0.714423] [epoch time: 0.05]\n",
      "12400 [D loss: 0.718095, acc.: 42.19%] [G loss: 0.705803] [epoch time: 0.05]\n",
      "12600 [D loss: 0.716906, acc.: 46.09%] [G loss: 0.723556] [epoch time: 0.07]\n",
      "12800 [D loss: 0.716755, acc.: 48.44%] [G loss: 0.678676] [epoch time: 0.05]\n",
      "13000 [D loss: 0.724359, acc.: 42.19%] [G loss: 0.711954] [epoch time: 0.05]\n",
      "13200 [D loss: 0.726304, acc.: 37.50%] [G loss: 0.700966] [epoch time: 0.07]\n",
      "13400 [D loss: 0.710423, acc.: 44.53%] [G loss: 0.727902] [epoch time: 0.05]\n",
      "13600 [D loss: 0.710005, acc.: 45.31%] [G loss: 0.698128] [epoch time: 0.05]\n",
      "13800 [D loss: 0.703172, acc.: 46.88%] [G loss: 0.712116] [epoch time: 0.07]\n",
      "14000 [D loss: 0.736622, acc.: 39.06%] [G loss: 0.721112] [epoch time: 0.05]\n",
      "14200 [D loss: 0.714897, acc.: 43.75%] [G loss: 0.714102] [epoch time: 0.05]\n",
      "14400 [D loss: 0.714516, acc.: 39.06%] [G loss: 0.692785] [epoch time: 0.07]\n",
      "14600 [D loss: 0.724187, acc.: 43.75%] [G loss: 0.711046] [epoch time: 0.05]\n",
      "14800 [D loss: 0.720168, acc.: 42.97%] [G loss: 0.696743] [epoch time: 0.05]\n",
      "15000 [D loss: 0.717385, acc.: 37.50%] [G loss: 0.685150] [epoch time: 0.07]\n",
      "15200 [D loss: 0.725996, acc.: 35.94%] [G loss: 0.688301] [epoch time: 0.05]\n",
      "15400 [D loss: 0.707999, acc.: 50.78%] [G loss: 0.711457] [epoch time: 0.05]\n",
      "15600 [D loss: 0.730343, acc.: 38.28%] [G loss: 0.721062] [epoch time: 0.07]\n",
      "15800 [D loss: 0.706723, acc.: 45.31%] [G loss: 0.696711] [epoch time: 0.05]\n",
      "16000 [D loss: 0.710114, acc.: 43.75%] [G loss: 0.719749] [epoch time: 0.05]\n",
      "16200 [D loss: 0.708790, acc.: 45.31%] [G loss: 0.707831] [epoch time: 0.07]\n",
      "16400 [D loss: 0.705617, acc.: 46.88%] [G loss: 0.699572] [epoch time: 0.05]\n",
      "16600 [D loss: 0.707031, acc.: 46.09%] [G loss: 0.707868] [epoch time: 0.05]\n",
      "16800 [D loss: 0.710124, acc.: 41.41%] [G loss: 0.752299] [epoch time: 0.07]\n",
      "17000 [D loss: 0.704738, acc.: 46.88%] [G loss: 0.724568] [epoch time: 0.05]\n",
      "17200 [D loss: 0.711720, acc.: 46.88%] [G loss: 0.716455] [epoch time: 0.05]\n",
      "17400 [D loss: 0.712111, acc.: 40.62%] [G loss: 0.724808] [epoch time: 0.07]\n",
      "17600 [D loss: 0.713704, acc.: 45.31%] [G loss: 0.733765] [epoch time: 0.05]\n",
      "17800 [D loss: 0.712458, acc.: 42.97%] [G loss: 0.689876] [epoch time: 0.05]\n",
      "18000 [D loss: 0.715489, acc.: 38.28%] [G loss: 0.725845] [epoch time: 0.07]\n",
      "18200 [D loss: 0.698382, acc.: 53.12%] [G loss: 0.690546] [epoch time: 0.05]\n",
      "18400 [D loss: 0.704327, acc.: 43.75%] [G loss: 0.722019] [epoch time: 0.05]\n",
      "18600 [D loss: 0.709179, acc.: 42.97%] [G loss: 0.698156] [epoch time: 0.07]\n",
      "18800 [D loss: 0.730860, acc.: 31.25%] [G loss: 0.689081] [epoch time: 0.05]\n",
      "19000 [D loss: 0.695134, acc.: 50.78%] [G loss: 0.693312] [epoch time: 0.05]\n",
      "19200 [D loss: 0.714548, acc.: 38.28%] [G loss: 0.727459] [epoch time: 0.07]\n",
      "19400 [D loss: 0.720178, acc.: 41.41%] [G loss: 0.710965] [epoch time: 0.05]\n",
      "19600 [D loss: 0.707866, acc.: 42.97%] [G loss: 0.691851] [epoch time: 0.05]\n",
      "19800 [D loss: 0.710686, acc.: 48.44%] [G loss: 0.720696] [epoch time: 0.07]\n",
      "20000 [D loss: 0.715850, acc.: 44.53%] [G loss: 0.708534] [epoch time: 0.05]\n",
      "elapsed training time: 21 min, 6 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_91 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_37 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_38 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.586107, acc.: 60.94%] [G loss: 0.497715] [epoch time: 16.34]\n",
      "200 [D loss: 0.882765, acc.: 36.72%] [G loss: 0.688416] [epoch time: 0.07]\n",
      "400 [D loss: 0.858208, acc.: 38.28%] [G loss: 0.723203] [epoch time: 0.07]\n",
      "600 [D loss: 0.758186, acc.: 48.44%] [G loss: 0.878724] [epoch time: 0.07]\n",
      "800 [D loss: 0.815617, acc.: 42.97%] [G loss: 0.825223] [epoch time: 0.07]\n",
      "1000 [D loss: 0.786103, acc.: 43.75%] [G loss: 0.756068] [epoch time: 0.07]\n",
      "1200 [D loss: 0.702757, acc.: 57.81%] [G loss: 0.715285] [epoch time: 0.07]\n",
      "1400 [D loss: 0.728714, acc.: 50.78%] [G loss: 0.762087] [epoch time: 0.07]\n",
      "1600 [D loss: 0.718765, acc.: 46.88%] [G loss: 0.756775] [epoch time: 0.07]\n",
      "1800 [D loss: 0.712832, acc.: 56.25%] [G loss: 0.733419] [epoch time: 0.07]\n",
      "2000 [D loss: 0.742960, acc.: 43.75%] [G loss: 0.733062] [epoch time: 0.07]\n",
      "2200 [D loss: 0.704813, acc.: 51.56%] [G loss: 0.763633] [epoch time: 0.07]\n",
      "2400 [D loss: 0.775112, acc.: 38.28%] [G loss: 0.746234] [epoch time: 0.07]\n",
      "2600 [D loss: 0.767957, acc.: 42.97%] [G loss: 0.785371] [epoch time: 0.07]\n",
      "2800 [D loss: 0.727607, acc.: 50.78%] [G loss: 0.690289] [epoch time: 0.07]\n",
      "3000 [D loss: 0.791291, acc.: 32.81%] [G loss: 0.783606] [epoch time: 0.07]\n",
      "3200 [D loss: 0.703805, acc.: 51.56%] [G loss: 0.731859] [epoch time: 0.07]\n",
      "3400 [D loss: 0.749301, acc.: 46.09%] [G loss: 0.748362] [epoch time: 0.07]\n",
      "3600 [D loss: 0.779589, acc.: 36.72%] [G loss: 0.699515] [epoch time: 0.07]\n",
      "3800 [D loss: 0.792582, acc.: 32.81%] [G loss: 0.734689] [epoch time: 0.07]\n",
      "4000 [D loss: 0.754824, acc.: 42.97%] [G loss: 0.716884] [epoch time: 0.07]\n",
      "4200 [D loss: 0.739046, acc.: 49.22%] [G loss: 0.718775] [epoch time: 0.07]\n",
      "4400 [D loss: 0.739999, acc.: 42.97%] [G loss: 0.664389] [epoch time: 0.07]\n",
      "4600 [D loss: 0.704181, acc.: 46.88%] [G loss: 0.718049] [epoch time: 0.07]\n",
      "4800 [D loss: 0.726397, acc.: 45.31%] [G loss: 0.729722] [epoch time: 0.07]\n",
      "5000 [D loss: 0.736786, acc.: 40.62%] [G loss: 0.776803] [epoch time: 0.07]\n",
      "5200 [D loss: 0.727509, acc.: 45.31%] [G loss: 0.747243] [epoch time: 0.07]\n",
      "5400 [D loss: 0.729909, acc.: 41.41%] [G loss: 0.736649] [epoch time: 0.07]\n",
      "5600 [D loss: 0.736121, acc.: 39.06%] [G loss: 0.716831] [epoch time: 0.07]\n",
      "5800 [D loss: 0.741964, acc.: 42.97%] [G loss: 0.733882] [epoch time: 0.07]\n",
      "6000 [D loss: 0.723363, acc.: 39.84%] [G loss: 0.723804] [epoch time: 0.07]\n",
      "6200 [D loss: 0.746748, acc.: 32.81%] [G loss: 0.729148] [epoch time: 0.07]\n",
      "6400 [D loss: 0.709310, acc.: 51.56%] [G loss: 0.741431] [epoch time: 0.07]\n",
      "6600 [D loss: 0.716343, acc.: 44.53%] [G loss: 0.733905] [epoch time: 0.07]\n",
      "6800 [D loss: 0.718796, acc.: 41.41%] [G loss: 0.735159] [epoch time: 0.07]\n",
      "7000 [D loss: 0.714981, acc.: 47.66%] [G loss: 0.736636] [epoch time: 0.07]\n",
      "7200 [D loss: 0.720797, acc.: 45.31%] [G loss: 0.713250] [epoch time: 0.07]\n",
      "7400 [D loss: 0.726637, acc.: 42.97%] [G loss: 0.707134] [epoch time: 0.07]\n",
      "7600 [D loss: 0.729019, acc.: 40.62%] [G loss: 0.751132] [epoch time: 0.07]\n",
      "7800 [D loss: 0.721066, acc.: 47.66%] [G loss: 0.734642] [epoch time: 0.07]\n",
      "8000 [D loss: 0.703052, acc.: 52.34%] [G loss: 0.712979] [epoch time: 0.07]\n",
      "8200 [D loss: 0.697547, acc.: 50.78%] [G loss: 0.748841] [epoch time: 0.07]\n",
      "8400 [D loss: 0.719455, acc.: 42.19%] [G loss: 0.710859] [epoch time: 0.07]\n",
      "8600 [D loss: 0.732237, acc.: 32.03%] [G loss: 0.694981] [epoch time: 0.07]\n",
      "8800 [D loss: 0.722449, acc.: 42.97%] [G loss: 0.725137] [epoch time: 0.07]\n",
      "9000 [D loss: 0.720573, acc.: 45.31%] [G loss: 0.722475] [epoch time: 0.07]\n",
      "9200 [D loss: 0.716742, acc.: 43.75%] [G loss: 0.700605] [epoch time: 0.07]\n",
      "9400 [D loss: 0.712332, acc.: 43.75%] [G loss: 0.727911] [epoch time: 0.07]\n",
      "9600 [D loss: 0.718920, acc.: 42.19%] [G loss: 0.701972] [epoch time: 0.07]\n",
      "9800 [D loss: 0.718872, acc.: 39.84%] [G loss: 0.721684] [epoch time: 0.07]\n",
      "10000 [D loss: 0.715735, acc.: 44.53%] [G loss: 0.729701] [epoch time: 0.07]\n",
      "10200 [D loss: 0.698479, acc.: 52.34%] [G loss: 0.727916] [epoch time: 0.07]\n",
      "10400 [D loss: 0.709263, acc.: 44.53%] [G loss: 0.719906] [epoch time: 0.07]\n",
      "10600 [D loss: 0.703165, acc.: 46.88%] [G loss: 0.730906] [epoch time: 0.07]\n",
      "10800 [D loss: 0.725816, acc.: 38.28%] [G loss: 0.716860] [epoch time: 0.07]\n",
      "11000 [D loss: 0.717180, acc.: 43.75%] [G loss: 0.721184] [epoch time: 0.07]\n",
      "11200 [D loss: 0.718655, acc.: 35.94%] [G loss: 0.687796] [epoch time: 0.07]\n",
      "11400 [D loss: 0.702675, acc.: 47.66%] [G loss: 0.690946] [epoch time: 0.07]\n",
      "11600 [D loss: 0.701740, acc.: 48.44%] [G loss: 0.712300] [epoch time: 0.07]\n",
      "11800 [D loss: 0.721111, acc.: 39.84%] [G loss: 0.735538] [epoch time: 0.07]\n",
      "12000 [D loss: 0.704573, acc.: 42.97%] [G loss: 0.744014] [epoch time: 0.07]\n",
      "12200 [D loss: 0.716871, acc.: 42.97%] [G loss: 0.715923] [epoch time: 0.07]\n",
      "12400 [D loss: 0.713310, acc.: 46.09%] [G loss: 0.707725] [epoch time: 0.07]\n",
      "12600 [D loss: 0.713325, acc.: 45.31%] [G loss: 0.703537] [epoch time: 0.07]\n",
      "12800 [D loss: 0.710362, acc.: 46.09%] [G loss: 0.729407] [epoch time: 0.07]\n",
      "13000 [D loss: 0.695108, acc.: 49.22%] [G loss: 0.708212] [epoch time: 0.07]\n",
      "13200 [D loss: 0.704312, acc.: 42.97%] [G loss: 0.716025] [epoch time: 0.07]\n",
      "13400 [D loss: 0.698782, acc.: 46.88%] [G loss: 0.723790] [epoch time: 0.07]\n",
      "13600 [D loss: 0.710481, acc.: 42.19%] [G loss: 0.704083] [epoch time: 0.07]\n",
      "13800 [D loss: 0.706655, acc.: 43.75%] [G loss: 0.701780] [epoch time: 0.07]\n",
      "14000 [D loss: 0.705277, acc.: 42.97%] [G loss: 0.714638] [epoch time: 0.07]\n",
      "14200 [D loss: 0.711150, acc.: 46.09%] [G loss: 0.704900] [epoch time: 0.07]\n",
      "14400 [D loss: 0.707857, acc.: 43.75%] [G loss: 0.716073] [epoch time: 0.07]\n",
      "14600 [D loss: 0.706143, acc.: 42.97%] [G loss: 0.698642] [epoch time: 0.07]\n",
      "14800 [D loss: 0.695184, acc.: 52.34%] [G loss: 0.710143] [epoch time: 0.07]\n",
      "15000 [D loss: 0.706837, acc.: 40.62%] [G loss: 0.701611] [epoch time: 0.07]\n",
      "15200 [D loss: 0.698476, acc.: 46.88%] [G loss: 0.718494] [epoch time: 0.07]\n",
      "15400 [D loss: 0.709405, acc.: 43.75%] [G loss: 0.701881] [epoch time: 0.07]\n",
      "15600 [D loss: 0.704959, acc.: 42.19%] [G loss: 0.713939] [epoch time: 0.07]\n",
      "15800 [D loss: 0.715447, acc.: 37.50%] [G loss: 0.699957] [epoch time: 0.07]\n",
      "16000 [D loss: 0.718439, acc.: 36.72%] [G loss: 0.690154] [epoch time: 0.07]\n",
      "16200 [D loss: 0.716578, acc.: 42.97%] [G loss: 0.698228] [epoch time: 0.07]\n",
      "16400 [D loss: 0.713343, acc.: 40.62%] [G loss: 0.714032] [epoch time: 0.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.711054, acc.: 49.22%] [G loss: 0.702983] [epoch time: 0.07]\n",
      "16800 [D loss: 0.705616, acc.: 46.09%] [G loss: 0.698385] [epoch time: 0.07]\n",
      "17000 [D loss: 0.712001, acc.: 37.50%] [G loss: 0.706609] [epoch time: 0.07]\n",
      "17200 [D loss: 0.703369, acc.: 41.41%] [G loss: 0.721802] [epoch time: 0.07]\n",
      "17400 [D loss: 0.710255, acc.: 42.19%] [G loss: 0.707672] [epoch time: 0.07]\n",
      "17600 [D loss: 0.711434, acc.: 42.97%] [G loss: 0.700142] [epoch time: 0.07]\n",
      "17800 [D loss: 0.699728, acc.: 47.66%] [G loss: 0.713437] [epoch time: 0.07]\n",
      "18000 [D loss: 0.707814, acc.: 42.97%] [G loss: 0.698426] [epoch time: 0.07]\n",
      "18200 [D loss: 0.704161, acc.: 48.44%] [G loss: 0.704443] [epoch time: 0.07]\n",
      "18400 [D loss: 0.707146, acc.: 43.75%] [G loss: 0.698574] [epoch time: 0.07]\n",
      "18600 [D loss: 0.698173, acc.: 53.12%] [G loss: 0.694163] [epoch time: 0.07]\n",
      "18800 [D loss: 0.704794, acc.: 42.19%] [G loss: 0.708001] [epoch time: 0.07]\n",
      "19000 [D loss: 0.705444, acc.: 46.09%] [G loss: 0.711778] [epoch time: 0.07]\n",
      "19200 [D loss: 0.704569, acc.: 39.06%] [G loss: 0.708316] [epoch time: 0.07]\n",
      "19400 [D loss: 0.702932, acc.: 43.75%] [G loss: 0.706887] [epoch time: 0.07]\n",
      "19600 [D loss: 0.699740, acc.: 45.31%] [G loss: 0.722283] [epoch time: 0.07]\n",
      "19800 [D loss: 0.697558, acc.: 45.31%] [G loss: 0.704459] [epoch time: 0.07]\n",
      "20000 [D loss: 0.687884, acc.: 59.38%] [G loss: 0.708930] [epoch time: 0.07]\n",
      "elapsed training time: 20 min, 54 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_39 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_40 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.426692, acc.: 42.19%] [G loss: 1.422779] [epoch time: 13.86]\n",
      "200 [D loss: 1.329251, acc.: 14.06%] [G loss: 0.502123] [epoch time: 0.07]\n",
      "400 [D loss: 0.950002, acc.: 34.38%] [G loss: 0.872781] [epoch time: 0.07]\n",
      "600 [D loss: 0.893326, acc.: 32.03%] [G loss: 0.843699] [epoch time: 0.07]\n",
      "800 [D loss: 0.948764, acc.: 30.47%] [G loss: 0.974937] [epoch time: 0.07]\n",
      "1000 [D loss: 1.017261, acc.: 22.66%] [G loss: 0.738762] [epoch time: 0.07]\n",
      "1200 [D loss: 0.966934, acc.: 30.47%] [G loss: 0.807105] [epoch time: 0.07]\n",
      "1400 [D loss: 0.931519, acc.: 31.25%] [G loss: 0.847928] [epoch time: 0.07]\n",
      "1600 [D loss: 0.863697, acc.: 34.38%] [G loss: 0.887956] [epoch time: 0.07]\n",
      "1800 [D loss: 0.931561, acc.: 25.78%] [G loss: 0.783139] [epoch time: 0.07]\n",
      "2000 [D loss: 0.938283, acc.: 29.69%] [G loss: 0.680976] [epoch time: 0.07]\n",
      "2200 [D loss: 0.938977, acc.: 25.78%] [G loss: 0.742936] [epoch time: 0.07]\n",
      "2400 [D loss: 1.007581, acc.: 28.91%] [G loss: 0.681888] [epoch time: 0.07]\n",
      "2600 [D loss: 0.892956, acc.: 29.69%] [G loss: 0.813125] [epoch time: 0.07]\n",
      "2800 [D loss: 0.987733, acc.: 24.22%] [G loss: 0.721549] [epoch time: 0.07]\n",
      "3000 [D loss: 0.861651, acc.: 34.38%] [G loss: 0.891948] [epoch time: 0.07]\n",
      "3200 [D loss: 0.888056, acc.: 25.78%] [G loss: 0.849104] [epoch time: 0.07]\n",
      "3400 [D loss: 0.818209, acc.: 42.19%] [G loss: 0.824699] [epoch time: 0.07]\n",
      "3600 [D loss: 0.928342, acc.: 27.34%] [G loss: 0.660008] [epoch time: 0.07]\n",
      "3800 [D loss: 0.963483, acc.: 21.09%] [G loss: 0.845446] [epoch time: 0.07]\n",
      "4000 [D loss: 0.768605, acc.: 42.97%] [G loss: 0.907104] [epoch time: 0.07]\n",
      "4200 [D loss: 0.885586, acc.: 25.00%] [G loss: 0.697458] [epoch time: 0.07]\n",
      "4400 [D loss: 0.847786, acc.: 35.16%] [G loss: 0.779693] [epoch time: 0.07]\n",
      "4600 [D loss: 0.775581, acc.: 46.88%] [G loss: 0.797265] [epoch time: 0.07]\n",
      "4800 [D loss: 0.887666, acc.: 32.03%] [G loss: 0.836823] [epoch time: 0.07]\n",
      "5000 [D loss: 0.876276, acc.: 34.38%] [G loss: 0.838749] [epoch time: 0.07]\n",
      "5200 [D loss: 0.881804, acc.: 32.81%] [G loss: 0.760694] [epoch time: 0.07]\n",
      "5400 [D loss: 0.885112, acc.: 30.47%] [G loss: 0.772704] [epoch time: 0.07]\n",
      "5600 [D loss: 0.809149, acc.: 38.28%] [G loss: 0.901389] [epoch time: 0.07]\n",
      "5800 [D loss: 0.814474, acc.: 34.38%] [G loss: 0.778275] [epoch time: 0.07]\n",
      "6000 [D loss: 0.815971, acc.: 46.09%] [G loss: 0.790908] [epoch time: 0.07]\n",
      "6200 [D loss: 0.859730, acc.: 25.78%] [G loss: 0.755906] [epoch time: 0.07]\n",
      "6400 [D loss: 0.812013, acc.: 38.28%] [G loss: 0.743612] [epoch time: 0.07]\n",
      "6600 [D loss: 0.828313, acc.: 33.59%] [G loss: 0.737519] [epoch time: 0.07]\n",
      "6800 [D loss: 0.805487, acc.: 40.62%] [G loss: 0.842835] [epoch time: 0.07]\n",
      "7000 [D loss: 0.879737, acc.: 29.69%] [G loss: 0.727865] [epoch time: 0.07]\n",
      "7200 [D loss: 0.826465, acc.: 35.94%] [G loss: 0.785775] [epoch time: 0.07]\n",
      "7400 [D loss: 0.831519, acc.: 32.81%] [G loss: 0.804771] [epoch time: 0.07]\n",
      "7600 [D loss: 0.809753, acc.: 33.59%] [G loss: 0.744229] [epoch time: 0.07]\n",
      "7800 [D loss: 0.824108, acc.: 35.16%] [G loss: 0.745374] [epoch time: 0.07]\n",
      "8000 [D loss: 0.781089, acc.: 43.75%] [G loss: 0.768647] [epoch time: 0.07]\n",
      "8200 [D loss: 0.769477, acc.: 42.19%] [G loss: 0.904890] [epoch time: 0.07]\n",
      "8400 [D loss: 0.781430, acc.: 39.06%] [G loss: 0.771946] [epoch time: 0.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600 [D loss: 0.937099, acc.: 20.31%] [G loss: 0.511969] [epoch time: 0.07]\n",
      "8800 [D loss: 0.792923, acc.: 35.16%] [G loss: 0.804210] [epoch time: 0.07]\n",
      "9000 [D loss: 0.796486, acc.: 41.41%] [G loss: 0.699378] [epoch time: 0.07]\n",
      "9200 [D loss: 0.829357, acc.: 35.16%] [G loss: 0.676181] [epoch time: 0.07]\n",
      "9400 [D loss: 0.811872, acc.: 35.16%] [G loss: 0.754203] [epoch time: 0.07]\n",
      "9600 [D loss: 0.775089, acc.: 42.19%] [G loss: 0.799418] [epoch time: 0.07]\n",
      "9800 [D loss: 0.815956, acc.: 35.16%] [G loss: 0.732774] [epoch time: 0.07]\n",
      "10000 [D loss: 0.829536, acc.: 28.91%] [G loss: 0.789083] [epoch time: 0.07]\n",
      "10200 [D loss: 0.768362, acc.: 37.50%] [G loss: 0.800095] [epoch time: 0.07]\n",
      "10400 [D loss: 0.788686, acc.: 35.94%] [G loss: 0.673511] [epoch time: 0.07]\n",
      "10600 [D loss: 0.811701, acc.: 32.03%] [G loss: 0.761945] [epoch time: 0.07]\n",
      "10800 [D loss: 0.868025, acc.: 28.91%] [G loss: 0.608535] [epoch time: 0.07]\n",
      "11000 [D loss: 0.782299, acc.: 38.28%] [G loss: 0.730694] [epoch time: 0.07]\n",
      "11200 [D loss: 0.803771, acc.: 35.16%] [G loss: 0.790068] [epoch time: 0.07]\n",
      "11400 [D loss: 0.785563, acc.: 36.72%] [G loss: 0.775923] [epoch time: 0.07]\n",
      "11600 [D loss: 0.842778, acc.: 24.22%] [G loss: 0.772990] [epoch time: 0.07]\n",
      "11800 [D loss: 0.782503, acc.: 39.84%] [G loss: 0.761704] [epoch time: 0.07]\n",
      "12000 [D loss: 0.774316, acc.: 36.72%] [G loss: 0.712637] [epoch time: 0.07]\n",
      "12200 [D loss: 0.764212, acc.: 42.97%] [G loss: 0.687711] [epoch time: 0.07]\n",
      "12400 [D loss: 0.800626, acc.: 35.94%] [G loss: 0.759472] [epoch time: 0.07]\n",
      "12600 [D loss: 0.727960, acc.: 48.44%] [G loss: 0.868939] [epoch time: 0.07]\n",
      "12800 [D loss: 0.819876, acc.: 33.59%] [G loss: 0.707925] [epoch time: 0.07]\n",
      "13000 [D loss: 0.732947, acc.: 49.22%] [G loss: 0.773043] [epoch time: 0.07]\n",
      "13200 [D loss: 0.759241, acc.: 44.53%] [G loss: 0.812761] [epoch time: 0.07]\n",
      "13400 [D loss: 0.816985, acc.: 36.72%] [G loss: 0.680192] [epoch time: 0.07]\n",
      "13600 [D loss: 0.820131, acc.: 36.72%] [G loss: 0.801247] [epoch time: 0.07]\n",
      "13800 [D loss: 0.694559, acc.: 53.12%] [G loss: 0.783075] [epoch time: 0.07]\n",
      "14000 [D loss: 0.812278, acc.: 36.72%] [G loss: 0.705404] [epoch time: 0.07]\n",
      "14200 [D loss: 0.728429, acc.: 46.09%] [G loss: 0.774213] [epoch time: 0.07]\n",
      "14400 [D loss: 0.819665, acc.: 35.16%] [G loss: 0.689828] [epoch time: 0.07]\n",
      "14600 [D loss: 0.803953, acc.: 32.03%] [G loss: 0.665997] [epoch time: 0.07]\n",
      "14800 [D loss: 0.726615, acc.: 49.22%] [G loss: 0.856608] [epoch time: 0.07]\n",
      "15000 [D loss: 0.840574, acc.: 31.25%] [G loss: 0.729722] [epoch time: 0.07]\n",
      "15200 [D loss: 0.790913, acc.: 35.94%] [G loss: 0.663963] [epoch time: 0.07]\n",
      "15400 [D loss: 0.706120, acc.: 49.22%] [G loss: 0.846359] [epoch time: 0.07]\n",
      "15600 [D loss: 0.791171, acc.: 30.47%] [G loss: 0.737356] [epoch time: 0.07]\n",
      "15800 [D loss: 0.785507, acc.: 42.97%] [G loss: 0.773742] [epoch time: 0.07]\n",
      "16000 [D loss: 0.783331, acc.: 35.16%] [G loss: 0.783137] [epoch time: 0.07]\n",
      "16200 [D loss: 0.784636, acc.: 32.03%] [G loss: 0.629983] [epoch time: 0.07]\n",
      "16400 [D loss: 0.811160, acc.: 34.38%] [G loss: 0.740639] [epoch time: 0.07]\n",
      "16600 [D loss: 0.729336, acc.: 47.66%] [G loss: 0.746536] [epoch time: 0.07]\n",
      "16800 [D loss: 0.702423, acc.: 53.12%] [G loss: 0.759659] [epoch time: 0.07]\n",
      "17000 [D loss: 0.729434, acc.: 42.19%] [G loss: 0.794485] [epoch time: 0.07]\n",
      "17200 [D loss: 0.786130, acc.: 39.84%] [G loss: 0.673804] [epoch time: 0.07]\n",
      "17400 [D loss: 0.761049, acc.: 38.28%] [G loss: 0.744706] [epoch time: 0.07]\n",
      "17600 [D loss: 0.816592, acc.: 28.91%] [G loss: 0.705906] [epoch time: 0.07]\n",
      "17800 [D loss: 0.735391, acc.: 42.19%] [G loss: 0.758839] [epoch time: 0.07]\n",
      "18000 [D loss: 0.894502, acc.: 32.03%] [G loss: 0.640623] [epoch time: 0.07]\n",
      "18200 [D loss: 0.810494, acc.: 30.47%] [G loss: 0.705976] [epoch time: 0.07]\n",
      "18400 [D loss: 0.707824, acc.: 46.88%] [G loss: 0.715614] [epoch time: 0.07]\n",
      "18600 [D loss: 0.765877, acc.: 43.75%] [G loss: 0.793288] [epoch time: 0.07]\n",
      "18800 [D loss: 0.805680, acc.: 28.91%] [G loss: 0.789083] [epoch time: 0.07]\n",
      "19000 [D loss: 0.771368, acc.: 40.62%] [G loss: 0.746445] [epoch time: 0.07]\n",
      "19200 [D loss: 0.798567, acc.: 32.03%] [G loss: 0.746087] [epoch time: 0.07]\n",
      "19400 [D loss: 0.758505, acc.: 36.72%] [G loss: 0.745322] [epoch time: 0.07]\n",
      "19600 [D loss: 0.753710, acc.: 42.97%] [G loss: 0.783050] [epoch time: 0.07]\n",
      "19800 [D loss: 0.786587, acc.: 39.84%] [G loss: 0.667366] [epoch time: 0.07]\n",
      "20000 [D loss: 0.724391, acc.: 47.66%] [G loss: 0.792450] [epoch time: 0.07]\n",
      "elapsed training time: 19 min, 3 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_101 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_56 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,169\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_41 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_42 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.709815, acc.: 46.09%] [G loss: 0.616343] [epoch time: 14.24]\n",
      "200 [D loss: 0.301720, acc.: 89.06%] [G loss: 0.386478] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 [D loss: 0.590707, acc.: 71.09%] [G loss: 0.877847] [epoch time: 0.06]\n",
      "600 [D loss: 0.728707, acc.: 63.28%] [G loss: 0.925817] [epoch time: 0.06]\n",
      "800 [D loss: 0.644297, acc.: 67.97%] [G loss: 0.970176] [epoch time: 0.06]\n",
      "1000 [D loss: 0.637282, acc.: 64.06%] [G loss: 0.977583] [epoch time: 0.06]\n",
      "1200 [D loss: 0.634305, acc.: 64.06%] [G loss: 1.021015] [epoch time: 0.06]\n",
      "1400 [D loss: 0.597831, acc.: 66.41%] [G loss: 0.964212] [epoch time: 0.06]\n",
      "1600 [D loss: 0.426896, acc.: 86.72%] [G loss: 0.935836] [epoch time: 0.06]\n",
      "1800 [D loss: 0.559338, acc.: 75.00%] [G loss: 1.131786] [epoch time: 0.06]\n",
      "2000 [D loss: 0.657013, acc.: 64.06%] [G loss: 1.033108] [epoch time: 0.06]\n",
      "2200 [D loss: 0.520107, acc.: 77.34%] [G loss: 0.930482] [epoch time: 0.06]\n",
      "2400 [D loss: 0.618232, acc.: 64.84%] [G loss: 1.026450] [epoch time: 0.06]\n",
      "2600 [D loss: 0.321517, acc.: 92.97%] [G loss: 1.048802] [epoch time: 0.06]\n",
      "2800 [D loss: 0.810551, acc.: 41.41%] [G loss: 0.984000] [epoch time: 0.06]\n",
      "3000 [D loss: 0.426508, acc.: 83.59%] [G loss: 0.817020] [epoch time: 0.06]\n",
      "3200 [D loss: 0.576588, acc.: 71.09%] [G loss: 0.948620] [epoch time: 0.06]\n",
      "3400 [D loss: 0.256667, acc.: 96.88%] [G loss: 1.060428] [epoch time: 0.06]\n",
      "3600 [D loss: 0.585654, acc.: 66.41%] [G loss: 1.017452] [epoch time: 0.06]\n",
      "3800 [D loss: 0.303099, acc.: 94.53%] [G loss: 0.930650] [epoch time: 0.06]\n",
      "4000 [D loss: 0.491846, acc.: 78.91%] [G loss: 1.115955] [epoch time: 0.07]\n",
      "4200 [D loss: 0.549774, acc.: 71.88%] [G loss: 1.021787] [epoch time: 0.06]\n",
      "4400 [D loss: 0.320986, acc.: 96.09%] [G loss: 1.378991] [epoch time: 0.06]\n",
      "4600 [D loss: 0.266848, acc.: 91.41%] [G loss: 1.232862] [epoch time: 0.06]\n",
      "4800 [D loss: 0.509626, acc.: 76.56%] [G loss: 1.421244] [epoch time: 0.06]\n",
      "5000 [D loss: 0.666577, acc.: 60.94%] [G loss: 1.251863] [epoch time: 0.06]\n",
      "5200 [D loss: 0.472088, acc.: 83.59%] [G loss: 0.964834] [epoch time: 0.06]\n",
      "5400 [D loss: 0.616058, acc.: 63.28%] [G loss: 1.317376] [epoch time: 0.06]\n",
      "5600 [D loss: 0.544341, acc.: 72.66%] [G loss: 1.371307] [epoch time: 0.06]\n",
      "5800 [D loss: 0.225450, acc.: 96.09%] [G loss: 1.308767] [epoch time: 0.06]\n",
      "6000 [D loss: 0.577057, acc.: 71.88%] [G loss: 1.187962] [epoch time: 0.06]\n",
      "6200 [D loss: 0.458367, acc.: 81.25%] [G loss: 1.500081] [epoch time: 0.06]\n",
      "6400 [D loss: 0.506495, acc.: 75.00%] [G loss: 1.185038] [epoch time: 0.06]\n",
      "6600 [D loss: 0.582777, acc.: 71.09%] [G loss: 0.918180] [epoch time: 0.06]\n",
      "6800 [D loss: 0.233351, acc.: 96.09%] [G loss: 1.254049] [epoch time: 0.06]\n",
      "7000 [D loss: 0.431263, acc.: 85.94%] [G loss: 1.280542] [epoch time: 0.06]\n",
      "7200 [D loss: 0.389862, acc.: 85.16%] [G loss: 1.654378] [epoch time: 0.06]\n",
      "7400 [D loss: 0.565195, acc.: 67.19%] [G loss: 0.905715] [epoch time: 0.06]\n",
      "7600 [D loss: 0.381960, acc.: 90.62%] [G loss: 0.810936] [epoch time: 0.06]\n",
      "7800 [D loss: 0.202780, acc.: 96.09%] [G loss: 1.749634] [epoch time: 0.06]\n",
      "8000 [D loss: 0.410902, acc.: 85.16%] [G loss: 0.894055] [epoch time: 0.06]\n",
      "8200 [D loss: 0.577665, acc.: 68.75%] [G loss: 1.125073] [epoch time: 0.06]\n",
      "8400 [D loss: 0.672526, acc.: 57.81%] [G loss: 0.791741] [epoch time: 0.06]\n",
      "8600 [D loss: 0.681646, acc.: 58.59%] [G loss: 0.952107] [epoch time: 0.06]\n",
      "8800 [D loss: 0.616048, acc.: 66.41%] [G loss: 1.272763] [epoch time: 0.06]\n",
      "9000 [D loss: 0.263913, acc.: 96.88%] [G loss: 1.388401] [epoch time: 0.06]\n",
      "9200 [D loss: 0.715877, acc.: 58.59%] [G loss: 0.964194] [epoch time: 0.06]\n",
      "9400 [D loss: 0.472942, acc.: 74.22%] [G loss: 0.900223] [epoch time: 0.06]\n",
      "9600 [D loss: 0.850581, acc.: 46.09%] [G loss: 0.946478] [epoch time: 0.06]\n",
      "9800 [D loss: 0.346915, acc.: 88.28%] [G loss: 0.720760] [epoch time: 0.06]\n",
      "10000 [D loss: 0.990767, acc.: 35.16%] [G loss: 0.938621] [epoch time: 0.06]\n",
      "10200 [D loss: 0.568711, acc.: 71.09%] [G loss: 0.960931] [epoch time: 0.06]\n",
      "10400 [D loss: 0.537534, acc.: 72.66%] [G loss: 1.141336] [epoch time: 0.07]\n",
      "10600 [D loss: 0.670791, acc.: 56.25%] [G loss: 1.105262] [epoch time: 0.06]\n",
      "10800 [D loss: 0.589620, acc.: 66.41%] [G loss: 1.149336] [epoch time: 0.07]\n",
      "11000 [D loss: 0.574671, acc.: 70.31%] [G loss: 1.156644] [epoch time: 0.06]\n",
      "11200 [D loss: 0.662375, acc.: 59.38%] [G loss: 1.132266] [epoch time: 0.06]\n",
      "11400 [D loss: 0.726546, acc.: 56.25%] [G loss: 1.071860] [epoch time: 0.06]\n",
      "11600 [D loss: 0.633364, acc.: 68.75%] [G loss: 0.959451] [epoch time: 0.06]\n",
      "11800 [D loss: 0.507074, acc.: 75.00%] [G loss: 1.266964] [epoch time: 0.06]\n",
      "12000 [D loss: 0.625554, acc.: 61.72%] [G loss: 1.133736] [epoch time: 0.06]\n",
      "12200 [D loss: 0.618810, acc.: 67.97%] [G loss: 1.106055] [epoch time: 0.07]\n",
      "12400 [D loss: 0.682155, acc.: 57.81%] [G loss: 0.948769] [epoch time: 0.06]\n",
      "12600 [D loss: 0.628625, acc.: 64.84%] [G loss: 0.938085] [epoch time: 0.06]\n",
      "12800 [D loss: 0.562804, acc.: 74.22%] [G loss: 1.044786] [epoch time: 0.06]\n",
      "13000 [D loss: 0.566330, acc.: 70.31%] [G loss: 0.988179] [epoch time: 0.06]\n",
      "13200 [D loss: 0.739968, acc.: 52.34%] [G loss: 1.097592] [epoch time: 0.06]\n",
      "13400 [D loss: 0.621368, acc.: 70.31%] [G loss: 1.186448] [epoch time: 0.06]\n",
      "13600 [D loss: 0.785246, acc.: 51.56%] [G loss: 1.026521] [epoch time: 0.06]\n",
      "13800 [D loss: 0.562032, acc.: 69.53%] [G loss: 0.756948] [epoch time: 0.06]\n",
      "14000 [D loss: 0.609294, acc.: 63.28%] [G loss: 1.261758] [epoch time: 0.06]\n",
      "14200 [D loss: 0.525525, acc.: 74.22%] [G loss: 1.051107] [epoch time: 0.06]\n",
      "14400 [D loss: 0.572387, acc.: 72.66%] [G loss: 0.754157] [epoch time: 0.06]\n",
      "14600 [D loss: 0.434883, acc.: 83.59%] [G loss: 1.067362] [epoch time: 0.06]\n",
      "14800 [D loss: 0.575772, acc.: 66.41%] [G loss: 1.229690] [epoch time: 0.06]\n",
      "15000 [D loss: 0.632387, acc.: 66.41%] [G loss: 0.885886] [epoch time: 0.06]\n",
      "15200 [D loss: 0.656151, acc.: 61.72%] [G loss: 1.225626] [epoch time: 0.06]\n",
      "15400 [D loss: 0.661041, acc.: 62.50%] [G loss: 1.103579] [epoch time: 0.06]\n",
      "15600 [D loss: 0.559343, acc.: 69.53%] [G loss: 1.153448] [epoch time: 0.06]\n",
      "15800 [D loss: 0.395065, acc.: 84.38%] [G loss: 1.292696] [epoch time: 0.06]\n",
      "16000 [D loss: 0.391434, acc.: 85.94%] [G loss: 1.270951] [epoch time: 0.06]\n",
      "16200 [D loss: 0.699322, acc.: 60.16%] [G loss: 0.801616] [epoch time: 0.06]\n",
      "16400 [D loss: 0.593025, acc.: 64.84%] [G loss: 1.314170] [epoch time: 0.06]\n",
      "16600 [D loss: 0.528230, acc.: 71.88%] [G loss: 1.083501] [epoch time: 0.06]\n",
      "16800 [D loss: 0.564958, acc.: 68.75%] [G loss: 0.971491] [epoch time: 0.06]\n",
      "17000 [D loss: 0.507055, acc.: 75.78%] [G loss: 0.960458] [epoch time: 0.06]\n",
      "17200 [D loss: 0.509156, acc.: 75.00%] [G loss: 1.176558] [epoch time: 0.06]\n",
      "17400 [D loss: 0.506103, acc.: 78.91%] [G loss: 0.986092] [epoch time: 0.06]\n",
      "17600 [D loss: 0.467007, acc.: 82.81%] [G loss: 1.028393] [epoch time: 0.07]\n",
      "17800 [D loss: 0.345854, acc.: 90.62%] [G loss: 1.080354] [epoch time: 0.06]\n",
      "18000 [D loss: 0.733260, acc.: 55.47%] [G loss: 1.143764] [epoch time: 0.06]\n",
      "18200 [D loss: 0.560830, acc.: 65.62%] [G loss: 0.921714] [epoch time: 0.06]\n",
      "18400 [D loss: 0.710775, acc.: 57.03%] [G loss: 1.067442] [epoch time: 0.06]\n",
      "18600 [D loss: 0.591451, acc.: 69.53%] [G loss: 1.276209] [epoch time: 0.07]\n",
      "18800 [D loss: 0.725792, acc.: 53.91%] [G loss: 0.898512] [epoch time: 0.06]\n",
      "19000 [D loss: 0.384893, acc.: 88.28%] [G loss: 1.032518] [epoch time: 0.06]\n",
      "19200 [D loss: 0.731413, acc.: 54.69%] [G loss: 1.201511] [epoch time: 0.06]\n",
      "19400 [D loss: 0.868012, acc.: 42.19%] [G loss: 0.966518] [epoch time: 0.06]\n",
      "19600 [D loss: 0.482156, acc.: 78.12%] [G loss: 0.844643] [epoch time: 0.06]\n",
      "19800 [D loss: 0.690088, acc.: 55.47%] [G loss: 0.860141] [epoch time: 0.06]\n",
      "20000 [D loss: 0.607899, acc.: 69.53%] [G loss: 1.192740] [epoch time: 0.06]\n",
      "elapsed training time: 11 min, 54 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_106 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_57 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_43 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_44 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.141756, acc.: 29.69%] [G loss: 0.828908] [epoch time: 16.54]\n",
      "200 [D loss: 0.025056, acc.: 100.00%] [G loss: 6.294976] [epoch time: 0.06]\n",
      "400 [D loss: 0.002223, acc.: 100.00%] [G loss: 8.674274] [epoch time: 0.06]\n",
      "600 [D loss: 0.000581, acc.: 100.00%] [G loss: 9.854197] [epoch time: 0.06]\n",
      "800 [D loss: 0.000133, acc.: 100.00%] [G loss: 10.047286] [epoch time: 0.06]\n",
      "1000 [D loss: 0.000194, acc.: 100.00%] [G loss: 11.558525] [epoch time: 0.06]\n",
      "1200 [D loss: 0.000149, acc.: 100.00%] [G loss: 11.358857] [epoch time: 0.06]\n",
      "1400 [D loss: 0.000115, acc.: 100.00%] [G loss: 12.023359] [epoch time: 0.06]\n",
      "1600 [D loss: 0.000026, acc.: 100.00%] [G loss: 12.396758] [epoch time: 0.06]\n",
      "1800 [D loss: 0.000053, acc.: 100.00%] [G loss: 13.030087] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000022, acc.: 100.00%] [G loss: 13.217167] [epoch time: 0.06]\n",
      "2200 [D loss: 0.000014, acc.: 100.00%] [G loss: 13.494767] [epoch time: 0.06]\n",
      "2400 [D loss: 0.000014, acc.: 100.00%] [G loss: 13.035631] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000030, acc.: 100.00%] [G loss: 13.662609] [epoch time: 0.06]\n",
      "2800 [D loss: 0.000006, acc.: 100.00%] [G loss: 13.879962] [epoch time: 0.06]\n",
      "3000 [D loss: 0.000006, acc.: 100.00%] [G loss: 13.864410] [epoch time: 0.06]\n",
      "3200 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.423074] [epoch time: 0.06]\n",
      "3400 [D loss: 0.000009, acc.: 100.00%] [G loss: 14.321011] [epoch time: 0.06]\n",
      "3600 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.675837] [epoch time: 0.06]\n",
      "3800 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.864971] [epoch time: 0.06]\n",
      "4000 [D loss: 0.000037, acc.: 100.00%] [G loss: 14.970892] [epoch time: 0.06]\n",
      "4200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.234439] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.873017] [epoch time: 0.06]\n",
      "4600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.706783] [epoch time: 0.06]\n",
      "4800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.890837] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.109015] [epoch time: 0.06]\n",
      "5200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.027542] [epoch time: 0.06]\n",
      "5400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.671424] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.809402] [epoch time: 0.06]\n",
      "5800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.305336] [epoch time: 0.06]\n",
      "6000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.909257] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.094883] [epoch time: 0.06]\n",
      "6400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.047972] [epoch time: 0.06]\n",
      "6600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.028557] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.093689] [epoch time: 0.06]\n",
      "7000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "7200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.999512] [epoch time: 0.06]\n",
      "7600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.06]\n",
      "7800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.037930] [epoch time: 0.06]\n",
      "8200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.102680] [epoch time: 0.06]\n",
      "8400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.103859] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.051113] [epoch time: 0.06]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "10200 [D loss: 0.000066, acc.: 100.00%] [G loss: 15.371947] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000032, acc.: 100.00%] [G loss: 15.878340] [epoch time: 0.06]\n",
      "10600 [D loss: 0.000019, acc.: 100.00%] [G loss: 15.890976] [epoch time: 0.06]\n",
      "10800 [D loss: 0.000018, acc.: 100.00%] [G loss: 15.739851] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.741646] [epoch time: 0.06]\n",
      "11200 [D loss: 0.000010, acc.: 100.00%] [G loss: 15.526396] [epoch time: 0.06]\n",
      "11400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.394470] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.949100] [epoch time: 0.06]\n",
      "11800 [D loss: 0.000007, acc.: 100.00%] [G loss: 16.099545] [epoch time: 0.06]\n",
      "12000 [D loss: 0.000017, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.084621] [epoch time: 0.06]\n",
      "12400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.721538] [epoch time: 0.06]\n",
      "12600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.896209] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.935193] [epoch time: 0.06]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.957055] [epoch time: 0.06]\n",
      "13200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.962693] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.878456] [epoch time: 0.06]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.021873] [epoch time: 0.06]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.026848] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.104519] [epoch time: 0.06]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.070292] [epoch time: 0.06]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.048048] [epoch time: 0.06]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.955488] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.001503] [epoch time: 0.06]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.076853] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.091848] [epoch time: 0.06]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109015] [epoch time: 0.06]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.083355] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.067780] [epoch time: 0.06]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.091848] [epoch time: 0.06]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.086103] [epoch time: 0.06]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "elapsed training time: 20 min, 29 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_111 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_45 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_46 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.146336, acc.: 33.59%] [G loss: 0.723921] [epoch time: 16.39]\n",
      "200 [D loss: 0.052358, acc.: 98.44%] [G loss: 5.001584] [epoch time: 0.06]\n",
      "400 [D loss: 0.006506, acc.: 100.00%] [G loss: 7.538944] [epoch time: 0.06]\n",
      "600 [D loss: 0.002466, acc.: 100.00%] [G loss: 9.904135] [epoch time: 0.06]\n",
      "800 [D loss: 0.000259, acc.: 100.00%] [G loss: 10.275946] [epoch time: 0.06]\n",
      "1000 [D loss: 0.000234, acc.: 100.00%] [G loss: 11.397707] [epoch time: 0.06]\n",
      "1200 [D loss: 0.000330, acc.: 100.00%] [G loss: 11.275390] [epoch time: 0.06]\n",
      "1400 [D loss: 0.000061, acc.: 100.00%] [G loss: 12.692319] [epoch time: 0.06]\n",
      "1600 [D loss: 0.000036, acc.: 100.00%] [G loss: 13.079885] [epoch time: 0.06]\n",
      "1800 [D loss: 0.000122, acc.: 100.00%] [G loss: 13.010237] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000031, acc.: 100.00%] [G loss: 13.214079] [epoch time: 0.06]\n",
      "2200 [D loss: 0.000069, acc.: 100.00%] [G loss: 13.790925] [epoch time: 0.06]\n",
      "2400 [D loss: 0.000015, acc.: 100.00%] [G loss: 14.425884] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000008, acc.: 100.00%] [G loss: 14.276106] [epoch time: 0.06]\n",
      "2800 [D loss: 7.971192, acc.: 50.00%] [G loss: 0.000000] [epoch time: 0.06]\n",
      "3000 [D loss: 7.971192, acc.: 50.00%] [G loss: 0.000000] [epoch time: 0.06]\n",
      "3200 [D loss: 7.971192, acc.: 50.00%] [G loss: 0.000000] [epoch time: 0.06]\n",
      "3400 [D loss: 7.971192, acc.: 50.00%] [G loss: 0.000000] [epoch time: 0.06]\n",
      "3600 [D loss: 0.006460, acc.: 100.00%] [G loss: 6.786102] [epoch time: 0.06]\n",
      "3800 [D loss: 0.001351, acc.: 100.00%] [G loss: 12.912249] [epoch time: 0.06]\n",
      "4000 [D loss: 0.000301, acc.: 100.00%] [G loss: 13.612034] [epoch time: 0.06]\n",
      "4200 [D loss: 0.000082, acc.: 100.00%] [G loss: 14.377855] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000029, acc.: 100.00%] [G loss: 15.067656] [epoch time: 0.06]\n",
      "4600 [D loss: 0.000762, acc.: 100.00%] [G loss: 14.385612] [epoch time: 0.06]\n",
      "4800 [D loss: 0.000034, acc.: 100.00%] [G loss: 15.267414] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000032, acc.: 100.00%] [G loss: 15.488385] [epoch time: 0.06]\n",
      "5200 [D loss: 0.000014, acc.: 100.00%] [G loss: 15.325733] [epoch time: 0.06]\n",
      "5400 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.177224] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000008, acc.: 100.00%] [G loss: 15.261588] [epoch time: 0.06]\n",
      "5800 [D loss: 0.000016, acc.: 100.00%] [G loss: 15.757671] [epoch time: 0.06]\n",
      "6000 [D loss: 0.000007, acc.: 100.00%] [G loss: 15.867711] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.578737] [epoch time: 0.06]\n",
      "6400 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.747149] [epoch time: 0.06]\n",
      "6600 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.752360] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.806714] [epoch time: 0.06]\n",
      "7000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.697577] [epoch time: 0.06]\n",
      "7200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.825902] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.915981] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600 [D loss: 0.000071, acc.: 100.00%] [G loss: 15.564380] [epoch time: 0.06]\n",
      "7800 [D loss: 0.000015, acc.: 100.00%] [G loss: 15.025445] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000007, acc.: 100.00%] [G loss: 15.654184] [epoch time: 0.06]\n",
      "8200 [D loss: 0.000017, acc.: 100.00%] [G loss: 15.497103] [epoch time: 0.06]\n",
      "8400 [D loss: 0.000017, acc.: 100.00%] [G loss: 15.176877] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000005, acc.: 100.00%] [G loss: 15.550953] [epoch time: 0.06]\n",
      "8800 [D loss: 0.000008, acc.: 100.00%] [G loss: 15.625420] [epoch time: 0.06]\n",
      "9000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.777315] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.709129] [epoch time: 0.06]\n",
      "9400 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.744143] [epoch time: 0.06]\n",
      "9600 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.757639] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000018, acc.: 100.00%] [G loss: 15.953073] [epoch time: 0.06]\n",
      "10000 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.934599] [epoch time: 0.06]\n",
      "10200 [D loss: 0.000160, acc.: 100.00%] [G loss: 16.055397] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.076363] [epoch time: 0.06]\n",
      "10600 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.019129] [epoch time: 0.06]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.594705] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.967353] [epoch time: 0.06]\n",
      "11200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.866860] [epoch time: 0.06]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.897178] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.065788] [epoch time: 0.06]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.047209] [epoch time: 0.06]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.857596] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.039124] [epoch time: 0.06]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.040836] [epoch time: 0.06]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.074684] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.071785] [epoch time: 0.06]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.099545] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.06]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.093029] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.526857] [epoch time: 0.06]\n",
      "15400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.893435] [epoch time: 0.06]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000012, acc.: 100.00%] [G loss: 15.960276] [epoch time: 0.06]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.046638] [epoch time: 0.06]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109015] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.957097] [epoch time: 0.06]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.112604] [epoch time: 0.06]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.089439] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.983002] [epoch time: 0.06]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.042166] [epoch time: 0.06]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.102783] [epoch time: 0.06]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19000 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.104519] [epoch time: 0.06]\n",
      "19200 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.064289] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.060366] [epoch time: 0.06]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.096933] [epoch time: 0.06]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.994855] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.058151] [epoch time: 0.06]\n",
      "elapsed training time: 21 min, 1 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_116 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_24 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_47 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_48 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.259993, acc.: 18.75%] [G loss: 0.759630] [epoch time: 21.63]\n",
      "200 [D loss: 0.022342, acc.: 100.00%] [G loss: 5.409366] [epoch time: 0.04]\n",
      "400 [D loss: 0.001907, acc.: 100.00%] [G loss: 8.637941] [epoch time: 0.04]\n",
      "600 [D loss: 0.001321, acc.: 100.00%] [G loss: 10.028289] [epoch time: 0.06]\n",
      "800 [D loss: 0.000685, acc.: 100.00%] [G loss: 10.974213] [epoch time: 0.04]\n",
      "1000 [D loss: 0.000436, acc.: 100.00%] [G loss: 11.327615] [epoch time: 0.04]\n",
      "1200 [D loss: 0.000386, acc.: 100.00%] [G loss: 12.707474] [epoch time: 0.06]\n",
      "1400 [D loss: 0.000229, acc.: 100.00%] [G loss: 12.550341] [epoch time: 0.04]\n",
      "1600 [D loss: 0.000033, acc.: 100.00%] [G loss: 12.804257] [epoch time: 0.04]\n",
      "1800 [D loss: 0.000023, acc.: 100.00%] [G loss: 13.316281] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000023, acc.: 100.00%] [G loss: 13.623976] [epoch time: 0.04]\n",
      "2200 [D loss: 0.000084, acc.: 100.00%] [G loss: 13.131742] [epoch time: 0.04]\n",
      "2400 [D loss: 0.000009, acc.: 100.00%] [G loss: 13.652982] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000023, acc.: 100.00%] [G loss: 14.611370] [epoch time: 0.04]\n",
      "2800 [D loss: 0.000004, acc.: 100.00%] [G loss: 13.654264] [epoch time: 0.04]\n",
      "3000 [D loss: 0.000009, acc.: 100.00%] [G loss: 14.619668] [epoch time: 0.06]\n",
      "3200 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.075338] [epoch time: 0.04]\n",
      "3400 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.360783] [epoch time: 0.04]\n",
      "3600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.773329] [epoch time: 0.06]\n",
      "3800 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.596043] [epoch time: 0.04]\n",
      "4000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.749878] [epoch time: 0.04]\n",
      "4200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.680172] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.698730] [epoch time: 0.04]\n",
      "4600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.802653] [epoch time: 0.04]\n",
      "4800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.854306] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.279524] [epoch time: 0.04]\n",
      "5200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.983839] [epoch time: 0.04]\n",
      "5400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.901693] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.940424] [epoch time: 0.04]\n",
      "5800 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.811987] [epoch time: 0.04]\n",
      "6000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.890593] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "6400 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.009762] [epoch time: 0.04]\n",
      "6600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.823267] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.046738] [epoch time: 0.04]\n",
      "7000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.044643] [epoch time: 0.04]\n",
      "7200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.048571] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.099934] [epoch time: 0.04]\n",
      "7600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.030209] [epoch time: 0.04]\n",
      "7800 [D loss: 0.000002, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.060448] [epoch time: 0.04]\n",
      "8200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.092056] [epoch time: 0.04]\n",
      "8400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.102680] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.039089] [epoch time: 0.04]\n",
      "8800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "9000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.089439] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.026241] [epoch time: 0.04]\n",
      "9400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.010969] [epoch time: 0.04]\n",
      "9600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "10000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "10200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "10600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.087353] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "12600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.04]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.04]\n",
      "elapsed training time: 15 min, 31 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_121 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_25 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_49 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_50 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.132684, acc.: 33.59%] [G loss: 0.728361] [epoch time: 18.97]\n",
      "200 [D loss: 0.740730, acc.: 61.72%] [G loss: 1.504876] [epoch time: 0.03]\n",
      "400 [D loss: 0.144599, acc.: 96.09%] [G loss: 3.765699] [epoch time: 0.03]\n",
      "600 [D loss: 0.018090, acc.: 100.00%] [G loss: 6.146317] [epoch time: 0.06]\n",
      "800 [D loss: 0.010103, acc.: 100.00%] [G loss: 7.189903] [epoch time: 0.03]\n",
      "1000 [D loss: 0.004365, acc.: 100.00%] [G loss: 8.115630] [epoch time: 0.03]\n",
      "1200 [D loss: 0.001860, acc.: 100.00%] [G loss: 8.599583] [epoch time: 0.06]\n",
      "1400 [D loss: 0.001307, acc.: 100.00%] [G loss: 8.853790] [epoch time: 0.03]\n",
      "1600 [D loss: 0.001240, acc.: 100.00%] [G loss: 9.537289] [epoch time: 0.03]\n",
      "1800 [D loss: 0.000707, acc.: 100.00%] [G loss: 9.105886] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000616, acc.: 100.00%] [G loss: 8.926025] [epoch time: 0.03]\n",
      "2200 [D loss: 0.000878, acc.: 100.00%] [G loss: 9.927720] [epoch time: 0.03]\n",
      "2400 [D loss: 0.000254, acc.: 100.00%] [G loss: 10.864714] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000898, acc.: 100.00%] [G loss: 10.508257] [epoch time: 0.03]\n",
      "2800 [D loss: 0.000240, acc.: 100.00%] [G loss: 10.455351] [epoch time: 0.03]\n",
      "3000 [D loss: 0.000250, acc.: 100.00%] [G loss: 10.995355] [epoch time: 0.06]\n",
      "3200 [D loss: 0.000252, acc.: 100.00%] [G loss: 11.125511] [epoch time: 0.03]\n",
      "3400 [D loss: 0.000165, acc.: 100.00%] [G loss: 10.988409] [epoch time: 0.03]\n",
      "3600 [D loss: 0.000208, acc.: 100.00%] [G loss: 11.285908] [epoch time: 0.06]\n",
      "3800 [D loss: 0.000108, acc.: 100.00%] [G loss: 11.213301] [epoch time: 0.03]\n",
      "4000 [D loss: 0.000173, acc.: 100.00%] [G loss: 11.300966] [epoch time: 0.03]\n",
      "4200 [D loss: 0.000143, acc.: 100.00%] [G loss: 11.948295] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000085, acc.: 100.00%] [G loss: 12.112177] [epoch time: 0.03]\n",
      "4600 [D loss: 0.000058, acc.: 100.00%] [G loss: 12.300769] [epoch time: 0.03]\n",
      "4800 [D loss: 0.000030, acc.: 100.00%] [G loss: 12.186304] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000108, acc.: 100.00%] [G loss: 12.709992] [epoch time: 0.03]\n",
      "5200 [D loss: 0.000072, acc.: 100.00%] [G loss: 12.589635] [epoch time: 0.03]\n",
      "5400 [D loss: 0.000023, acc.: 100.00%] [G loss: 12.569808] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000448, acc.: 100.00%] [G loss: 12.680664] [epoch time: 0.03]\n",
      "5800 [D loss: 0.000082, acc.: 100.00%] [G loss: 13.382030] [epoch time: 0.03]\n",
      "6000 [D loss: 0.000044, acc.: 100.00%] [G loss: 13.318878] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000015, acc.: 100.00%] [G loss: 13.677946] [epoch time: 0.03]\n",
      "6400 [D loss: 0.000050, acc.: 100.00%] [G loss: 13.629500] [epoch time: 0.03]\n",
      "6600 [D loss: 0.000040, acc.: 100.00%] [G loss: 13.180582] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000023, acc.: 100.00%] [G loss: 13.269490] [epoch time: 0.03]\n",
      "7000 [D loss: 0.000026, acc.: 100.00%] [G loss: 13.029912] [epoch time: 0.03]\n",
      "7200 [D loss: 0.000014, acc.: 100.00%] [G loss: 13.918283] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000030, acc.: 100.00%] [G loss: 13.504513] [epoch time: 0.03]\n",
      "7600 [D loss: 0.000068, acc.: 100.00%] [G loss: 14.151920] [epoch time: 0.03]\n",
      "7800 [D loss: 0.000023, acc.: 100.00%] [G loss: 13.284526] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000017, acc.: 100.00%] [G loss: 13.963716] [epoch time: 0.03]\n",
      "8200 [D loss: 0.000011, acc.: 100.00%] [G loss: 13.673343] [epoch time: 0.03]\n",
      "8400 [D loss: 0.000020, acc.: 100.00%] [G loss: 13.467695] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000007, acc.: 100.00%] [G loss: 14.502394] [epoch time: 0.03]\n",
      "8800 [D loss: 0.000012, acc.: 100.00%] [G loss: 13.767185] [epoch time: 0.03]\n",
      "9000 [D loss: 0.000006, acc.: 100.00%] [G loss: 14.780018] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.409531] [epoch time: 0.03]\n",
      "9400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.286871] [epoch time: 0.03]\n",
      "9600 [D loss: 0.000032, acc.: 100.00%] [G loss: 14.365473] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.610397] [epoch time: 0.03]\n",
      "10000 [D loss: 0.000017, acc.: 100.00%] [G loss: 14.356484] [epoch time: 0.03]\n",
      "10200 [D loss: 0.000036, acc.: 100.00%] [G loss: 14.438732] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000011, acc.: 100.00%] [G loss: 14.481916] [epoch time: 0.03]\n",
      "10600 [D loss: 0.000044, acc.: 100.00%] [G loss: 14.752172] [epoch time: 0.03]\n",
      "10800 [D loss: 0.000025, acc.: 100.00%] [G loss: 14.753653] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000005, acc.: 100.00%] [G loss: 15.356876] [epoch time: 0.03]\n",
      "11200 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.647699] [epoch time: 0.03]\n",
      "11400 [D loss: 0.000003, acc.: 100.00%] [G loss: 14.882919] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000006, acc.: 100.00%] [G loss: 14.894011] [epoch time: 0.03]\n",
      "11800 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.194439] [epoch time: 0.03]\n",
      "12000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.387240] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.221874] [epoch time: 0.03]\n",
      "12400 [D loss: 0.000015, acc.: 100.00%] [G loss: 15.093003] [epoch time: 0.03]\n",
      "12600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.012267] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.142962] [epoch time: 0.03]\n",
      "13000 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.352091] [epoch time: 0.03]\n",
      "13200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.275196] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.286203] [epoch time: 0.03]\n",
      "13600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.395752] [epoch time: 0.03]\n",
      "13800 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.603849] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000014, acc.: 100.00%] [G loss: 15.255506] [epoch time: 0.03]\n",
      "14200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.664846] [epoch time: 0.03]\n",
      "14400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.684612] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.572656] [epoch time: 0.03]\n",
      "14800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.485849] [epoch time: 0.03]\n",
      "15000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.704430] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.600740] [epoch time: 0.03]\n",
      "15400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.856775] [epoch time: 0.03]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.863962] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.619658] [epoch time: 0.03]\n",
      "16000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.494341] [epoch time: 0.03]\n",
      "16200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.798855] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.661451] [epoch time: 0.03]\n",
      "16600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.784691] [epoch time: 0.03]\n",
      "16800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.353237] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.925786] [epoch time: 0.03]\n",
      "17200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.783739] [epoch time: 0.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.772021] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.823763] [epoch time: 0.03]\n",
      "17800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.858974] [epoch time: 0.03]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.986110] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.018991] [epoch time: 0.03]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.804789] [epoch time: 0.03]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.933472] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.782086] [epoch time: 0.03]\n",
      "19000 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.021976] [epoch time: 0.03]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.852834] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.985603] [epoch time: 0.03]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.065451] [epoch time: 0.03]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.907350] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.014442] [epoch time: 0.03]\n",
      "elapsed training time: 14 min, 47 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_126 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_26 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_51 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_52 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.151658, acc.: 39.84%] [G loss: 0.458023] [epoch time: 18.55]\n",
      "200 [D loss: 0.346317, acc.: 89.06%] [G loss: 2.654723] [epoch time: 0.06]\n",
      "400 [D loss: 0.011736, acc.: 100.00%] [G loss: 6.349699] [epoch time: 0.06]\n",
      "600 [D loss: 0.004768, acc.: 100.00%] [G loss: 8.059701] [epoch time: 0.06]\n",
      "800 [D loss: 0.012188, acc.: 99.22%] [G loss: 7.355773] [epoch time: 0.06]\n",
      "1000 [D loss: 0.024584, acc.: 99.22%] [G loss: 8.935112] [epoch time: 0.06]\n",
      "1200 [D loss: 0.000776, acc.: 100.00%] [G loss: 9.439745] [epoch time: 0.06]\n",
      "1400 [D loss: 0.000368, acc.: 100.00%] [G loss: 9.994253] [epoch time: 0.06]\n",
      "1600 [D loss: 0.000587, acc.: 100.00%] [G loss: 10.252743] [epoch time: 0.06]\n",
      "1800 [D loss: 0.000180, acc.: 100.00%] [G loss: 10.634961] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000458, acc.: 100.00%] [G loss: 10.831259] [epoch time: 0.06]\n",
      "2200 [D loss: 0.000169, acc.: 100.00%] [G loss: 11.111675] [epoch time: 0.06]\n",
      "2400 [D loss: 0.000227, acc.: 100.00%] [G loss: 10.993348] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000185, acc.: 100.00%] [G loss: 11.576099] [epoch time: 0.06]\n",
      "2800 [D loss: 0.000061, acc.: 100.00%] [G loss: 11.986228] [epoch time: 0.06]\n",
      "3000 [D loss: 0.000063, acc.: 100.00%] [G loss: 12.779869] [epoch time: 0.06]\n",
      "3200 [D loss: 0.000168, acc.: 100.00%] [G loss: 11.462714] [epoch time: 0.06]\n",
      "3400 [D loss: 0.000085, acc.: 100.00%] [G loss: 12.265825] [epoch time: 0.06]\n",
      "3600 [D loss: 0.000056, acc.: 100.00%] [G loss: 12.739435] [epoch time: 0.06]\n",
      "3800 [D loss: 0.000021, acc.: 100.00%] [G loss: 12.619440] [epoch time: 0.06]\n",
      "4000 [D loss: 0.000271, acc.: 100.00%] [G loss: 12.840555] [epoch time: 0.06]\n",
      "4200 [D loss: 0.000062, acc.: 100.00%] [G loss: 12.763466] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000032, acc.: 100.00%] [G loss: 12.829351] [epoch time: 0.06]\n",
      "4600 [D loss: 0.000026, acc.: 100.00%] [G loss: 13.874793] [epoch time: 0.06]\n",
      "4800 [D loss: 0.000014, acc.: 100.00%] [G loss: 13.252384] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000020, acc.: 100.00%] [G loss: 13.685288] [epoch time: 0.06]\n",
      "5200 [D loss: 0.000021, acc.: 100.00%] [G loss: 13.681725] [epoch time: 0.06]\n",
      "5400 [D loss: 0.000015, acc.: 100.00%] [G loss: 13.737268] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000006, acc.: 100.00%] [G loss: 14.212970] [epoch time: 0.06]\n",
      "5800 [D loss: 0.000009, acc.: 100.00%] [G loss: 14.359592] [epoch time: 0.06]\n",
      "6000 [D loss: 0.000022, acc.: 100.00%] [G loss: 14.008327] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000005, acc.: 100.00%] [G loss: 14.399278] [epoch time: 0.06]\n",
      "6400 [D loss: 0.000012, acc.: 100.00%] [G loss: 14.462410] [epoch time: 0.06]\n",
      "6600 [D loss: 0.000010, acc.: 100.00%] [G loss: 14.537794] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000013, acc.: 100.00%] [G loss: 14.893964] [epoch time: 0.06]\n",
      "7000 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.698009] [epoch time: 0.06]\n",
      "7200 [D loss: 0.000018, acc.: 100.00%] [G loss: 14.072418] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000002, acc.: 100.00%] [G loss: 14.930773] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.773712] [epoch time: 0.06]\n",
      "7800 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.229453] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.430396] [epoch time: 0.06]\n",
      "8200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.427793] [epoch time: 0.06]\n",
      "8400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.338893] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.315569] [epoch time: 0.06]\n",
      "8800 [D loss: 0.000005, acc.: 100.00%] [G loss: 15.495934] [epoch time: 0.06]\n",
      "9000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.404234] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.175163] [epoch time: 0.06]\n",
      "9400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.366219] [epoch time: 0.06]\n",
      "9600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.212543] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.687287] [epoch time: 0.06]\n",
      "10000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.881649] [epoch time: 0.06]\n",
      "10200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.730939] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.794290] [epoch time: 0.06]\n",
      "10600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.781509] [epoch time: 0.06]\n",
      "10800 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.799250] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.855945] [epoch time: 0.06]\n",
      "11200 [D loss: 0.000017, acc.: 100.00%] [G loss: 15.705455] [epoch time: 0.06]\n",
      "11400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.894654] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.773220] [epoch time: 0.06]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.893897] [epoch time: 0.06]\n",
      "12000 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.967636] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.900856] [epoch time: 0.06]\n",
      "12400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.798441] [epoch time: 0.06]\n",
      "12600 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.021324] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.851330] [epoch time: 0.06]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.906401] [epoch time: 0.06]\n",
      "13200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.955770] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.993341] [epoch time: 0.06]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.068390] [epoch time: 0.06]\n",
      "13800 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.014153] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.939712] [epoch time: 0.06]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.048300] [epoch time: 0.06]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.104519] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.036144] [epoch time: 0.06]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.109015] [epoch time: 0.06]\n",
      "15000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.097628] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.022984] [epoch time: 0.06]\n",
      "15400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.072783] [epoch time: 0.06]\n",
      "15600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.078794] [epoch time: 0.06]\n",
      "16000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.050510] [epoch time: 0.06]\n",
      "16200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.073879] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.011364] [epoch time: 0.06]\n",
      "16600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.051491] [epoch time: 0.06]\n",
      "16800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.057339] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "17200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.106606] [epoch time: 0.06]\n",
      "17400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.101032] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "17800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.082199] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "18400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.071865] [epoch time: 0.06]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.083355] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "19600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.094698] [epoch time: 0.06]\n",
      "elapsed training time: 16 min, 21 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_131 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_27 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_53 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_54 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.101225, acc.: 28.91%] [G loss: 0.693757] [epoch time: 19.50]\n",
      "200 [D loss: 1.072402, acc.: 32.81%] [G loss: 1.435952] [epoch time: 0.06]\n",
      "400 [D loss: 0.421081, acc.: 81.25%] [G loss: 2.483145] [epoch time: 0.06]\n",
      "600 [D loss: 0.161892, acc.: 92.97%] [G loss: 3.862711] [epoch time: 0.06]\n",
      "800 [D loss: 0.030424, acc.: 100.00%] [G loss: 4.925918] [epoch time: 0.06]\n",
      "1000 [D loss: 0.017954, acc.: 100.00%] [G loss: 6.024903] [epoch time: 0.06]\n",
      "1200 [D loss: 0.012253, acc.: 100.00%] [G loss: 6.469545] [epoch time: 0.06]\n",
      "1400 [D loss: 0.006189, acc.: 100.00%] [G loss: 7.363674] [epoch time: 0.06]\n",
      "1600 [D loss: 0.004999, acc.: 100.00%] [G loss: 6.928174] [epoch time: 0.06]\n",
      "1800 [D loss: 0.002927, acc.: 100.00%] [G loss: 7.448262] [epoch time: 0.06]\n",
      "2000 [D loss: 0.002898, acc.: 100.00%] [G loss: 7.456986] [epoch time: 0.06]\n",
      "2200 [D loss: 0.002222, acc.: 100.00%] [G loss: 7.384526] [epoch time: 0.06]\n",
      "2400 [D loss: 0.002412, acc.: 100.00%] [G loss: 8.140359] [epoch time: 0.06]\n",
      "2600 [D loss: 0.001365, acc.: 100.00%] [G loss: 8.359638] [epoch time: 0.06]\n",
      "2800 [D loss: 0.002450, acc.: 100.00%] [G loss: 7.294227] [epoch time: 0.06]\n",
      "3000 [D loss: 0.001690, acc.: 100.00%] [G loss: 10.012776] [epoch time: 0.06]\n",
      "3200 [D loss: 0.001386, acc.: 100.00%] [G loss: 9.107229] [epoch time: 0.06]\n",
      "3400 [D loss: 0.004631, acc.: 100.00%] [G loss: 10.560556] [epoch time: 0.06]\n",
      "3600 [D loss: 0.014394, acc.: 100.00%] [G loss: 6.106405] [epoch time: 0.06]\n",
      "3800 [D loss: 0.008764, acc.: 100.00%] [G loss: 7.004717] [epoch time: 0.06]\n",
      "4000 [D loss: 0.014120, acc.: 100.00%] [G loss: 7.552175] [epoch time: 0.06]\n",
      "4200 [D loss: 0.003573, acc.: 100.00%] [G loss: 8.187002] [epoch time: 0.06]\n",
      "4400 [D loss: 0.004529, acc.: 100.00%] [G loss: 8.235641] [epoch time: 0.06]\n",
      "4600 [D loss: 0.001766, acc.: 100.00%] [G loss: 8.771792] [epoch time: 0.06]\n",
      "4800 [D loss: 0.002747, acc.: 100.00%] [G loss: 9.077223] [epoch time: 0.06]\n",
      "5000 [D loss: 0.001895, acc.: 100.00%] [G loss: 8.768496] [epoch time: 0.06]\n",
      "5200 [D loss: 0.000881, acc.: 100.00%] [G loss: 8.686275] [epoch time: 0.06]\n",
      "5400 [D loss: 0.002664, acc.: 100.00%] [G loss: 8.690712] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000951, acc.: 100.00%] [G loss: 9.032019] [epoch time: 0.06]\n",
      "5800 [D loss: 0.000909, acc.: 100.00%] [G loss: 9.276376] [epoch time: 0.06]\n",
      "6000 [D loss: 0.000788, acc.: 100.00%] [G loss: 9.269094] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000595, acc.: 100.00%] [G loss: 10.067044] [epoch time: 0.06]\n",
      "6400 [D loss: 0.000613, acc.: 100.00%] [G loss: 9.893726] [epoch time: 0.06]\n",
      "6600 [D loss: 0.000479, acc.: 100.00%] [G loss: 9.585221] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000316, acc.: 100.00%] [G loss: 9.699892] [epoch time: 0.06]\n",
      "7000 [D loss: 0.000724, acc.: 100.00%] [G loss: 10.172691] [epoch time: 0.06]\n",
      "7200 [D loss: 0.000264, acc.: 100.00%] [G loss: 9.409574] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000485, acc.: 100.00%] [G loss: 9.856383] [epoch time: 0.06]\n",
      "7600 [D loss: 0.000148, acc.: 100.00%] [G loss: 10.075518] [epoch time: 0.06]\n",
      "7800 [D loss: 0.001939, acc.: 100.00%] [G loss: 11.039574] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000179, acc.: 100.00%] [G loss: 10.414579] [epoch time: 0.06]\n",
      "8200 [D loss: 0.000342, acc.: 100.00%] [G loss: 10.500020] [epoch time: 0.06]\n",
      "8400 [D loss: 0.000350, acc.: 100.00%] [G loss: 10.222417] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000304, acc.: 100.00%] [G loss: 10.730921] [epoch time: 0.06]\n",
      "8800 [D loss: 0.000509, acc.: 100.00%] [G loss: 10.760625] [epoch time: 0.06]\n",
      "9000 [D loss: 0.000228, acc.: 100.00%] [G loss: 10.357736] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000504, acc.: 100.00%] [G loss: 10.255331] [epoch time: 0.06]\n",
      "9400 [D loss: 0.000541, acc.: 100.00%] [G loss: 10.562504] [epoch time: 0.06]\n",
      "9600 [D loss: 0.000395, acc.: 100.00%] [G loss: 10.409143] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000332, acc.: 100.00%] [G loss: 10.575221] [epoch time: 0.06]\n",
      "10000 [D loss: 0.000328, acc.: 100.00%] [G loss: 11.248306] [epoch time: 0.06]\n",
      "10200 [D loss: 0.000375, acc.: 100.00%] [G loss: 10.516966] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000250, acc.: 100.00%] [G loss: 10.438776] [epoch time: 0.06]\n",
      "10600 [D loss: 0.000182, acc.: 100.00%] [G loss: 10.815411] [epoch time: 0.06]\n",
      "10800 [D loss: 0.000360, acc.: 100.00%] [G loss: 10.158110] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000254, acc.: 100.00%] [G loss: 10.656228] [epoch time: 0.06]\n",
      "11200 [D loss: 0.000148, acc.: 100.00%] [G loss: 10.990060] [epoch time: 0.06]\n",
      "11400 [D loss: 0.000259, acc.: 100.00%] [G loss: 10.754498] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000269, acc.: 100.00%] [G loss: 11.297300] [epoch time: 0.06]\n",
      "11800 [D loss: 0.000188, acc.: 100.00%] [G loss: 11.443041] [epoch time: 0.06]\n",
      "12000 [D loss: 0.000079, acc.: 100.00%] [G loss: 11.047560] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000102, acc.: 100.00%] [G loss: 11.412848] [epoch time: 0.06]\n",
      "12400 [D loss: 0.000110, acc.: 100.00%] [G loss: 11.517568] [epoch time: 0.06]\n",
      "12600 [D loss: 0.000232, acc.: 100.00%] [G loss: 11.357494] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000105, acc.: 100.00%] [G loss: 11.938309] [epoch time: 0.06]\n",
      "13000 [D loss: 0.000136, acc.: 100.00%] [G loss: 12.701756] [epoch time: 0.06]\n",
      "13200 [D loss: 0.001203, acc.: 100.00%] [G loss: 11.628077] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000065, acc.: 100.00%] [G loss: 11.429821] [epoch time: 0.07]\n",
      "13600 [D loss: 0.000057, acc.: 100.00%] [G loss: 12.233503] [epoch time: 0.06]\n",
      "13800 [D loss: 0.000050, acc.: 100.00%] [G loss: 11.983053] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000045, acc.: 100.00%] [G loss: 12.167530] [epoch time: 0.06]\n",
      "14200 [D loss: 0.000037, acc.: 100.00%] [G loss: 12.127260] [epoch time: 0.06]\n",
      "14400 [D loss: 0.000103, acc.: 100.00%] [G loss: 12.287079] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000208, acc.: 100.00%] [G loss: 12.449942] [epoch time: 0.06]\n",
      "14800 [D loss: 0.000056, acc.: 100.00%] [G loss: 11.714735] [epoch time: 0.06]\n",
      "15000 [D loss: 0.000070, acc.: 100.00%] [G loss: 12.566275] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000034, acc.: 100.00%] [G loss: 11.913206] [epoch time: 0.06]\n",
      "15400 [D loss: 0.000042, acc.: 100.00%] [G loss: 12.400556] [epoch time: 0.06]\n",
      "15600 [D loss: 0.000037, acc.: 100.00%] [G loss: 12.857380] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000147, acc.: 100.00%] [G loss: 13.112398] [epoch time: 0.06]\n",
      "16000 [D loss: 0.000052, acc.: 100.00%] [G loss: 12.597092] [epoch time: 0.06]\n",
      "16200 [D loss: 0.000024, acc.: 100.00%] [G loss: 12.443465] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000050, acc.: 100.00%] [G loss: 12.584220] [epoch time: 0.06]\n",
      "16600 [D loss: 0.000056, acc.: 100.00%] [G loss: 13.027639] [epoch time: 0.06]\n",
      "16800 [D loss: 0.000029, acc.: 100.00%] [G loss: 12.921550] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000027, acc.: 100.00%] [G loss: 13.118931] [epoch time: 0.06]\n",
      "17200 [D loss: 0.000046, acc.: 100.00%] [G loss: 12.556656] [epoch time: 0.06]\n",
      "17400 [D loss: 0.000046, acc.: 100.00%] [G loss: 12.995080] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000122, acc.: 100.00%] [G loss: 12.643047] [epoch time: 0.06]\n",
      "17800 [D loss: 0.000049, acc.: 100.00%] [G loss: 13.142356] [epoch time: 0.06]\n",
      "18000 [D loss: 0.000068, acc.: 100.00%] [G loss: 12.893897] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000028, acc.: 100.00%] [G loss: 13.180285] [epoch time: 0.06]\n",
      "18400 [D loss: 0.000077, acc.: 100.00%] [G loss: 13.010262] [epoch time: 0.06]\n",
      "18600 [D loss: 0.000027, acc.: 100.00%] [G loss: 12.892684] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000044, acc.: 100.00%] [G loss: 12.895517] [epoch time: 0.06]\n",
      "19000 [D loss: 0.000018, acc.: 100.00%] [G loss: 12.561197] [epoch time: 0.06]\n",
      "19200 [D loss: 0.000030, acc.: 100.00%] [G loss: 12.790289] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000051, acc.: 100.00%] [G loss: 12.743615] [epoch time: 0.06]\n",
      "19600 [D loss: 0.000149, acc.: 100.00%] [G loss: 13.391031] [epoch time: 0.06]\n",
      "19800 [D loss: 0.000018, acc.: 100.00%] [G loss: 12.986337] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000087, acc.: 100.00%] [G loss: 13.022902] [epoch time: 0.06]\n",
      "elapsed training time: 12 min, 45 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_136 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_139 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_28 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_55 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_56 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 28, 28, 1)         1153      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 635,137\n",
      "Trainable params: 634,881\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.117215, acc.: 32.81%] [G loss: 0.926907] [epoch time: 20.95]\n",
      "200 [D loss: 0.004457, acc.: 100.00%] [G loss: 7.221930] [epoch time: 0.06]\n",
      "400 [D loss: 0.000760, acc.: 100.00%] [G loss: 11.619468] [epoch time: 0.06]\n",
      "600 [D loss: 0.000817, acc.: 100.00%] [G loss: 9.572063] [epoch time: 0.06]\n",
      "800 [D loss: 0.000079, acc.: 100.00%] [G loss: 12.539629] [epoch time: 0.06]\n",
      "1000 [D loss: 0.000107, acc.: 100.00%] [G loss: 11.490277] [epoch time: 0.06]\n",
      "1200 [D loss: 0.000079, acc.: 100.00%] [G loss: 12.282101] [epoch time: 0.06]\n",
      "1400 [D loss: 0.000030, acc.: 100.00%] [G loss: 13.282374] [epoch time: 0.06]\n",
      "1600 [D loss: 0.000042, acc.: 100.00%] [G loss: 13.737755] [epoch time: 0.06]\n",
      "1800 [D loss: 0.000003, acc.: 100.00%] [G loss: 13.583644] [epoch time: 0.06]\n",
      "2000 [D loss: 0.000021, acc.: 100.00%] [G loss: 14.378000] [epoch time: 0.06]\n",
      "2200 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.226231] [epoch time: 0.06]\n",
      "2400 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.417709] [epoch time: 0.06]\n",
      "2600 [D loss: 0.000038, acc.: 100.00%] [G loss: 14.870065] [epoch time: 0.06]\n",
      "2800 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.694059] [epoch time: 0.06]\n",
      "3000 [D loss: 0.000004, acc.: 100.00%] [G loss: 14.993029] [epoch time: 0.06]\n",
      "3200 [D loss: 0.000005, acc.: 100.00%] [G loss: 15.499779] [epoch time: 0.06]\n",
      "3400 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.597178] [epoch time: 0.06]\n",
      "3600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.178240] [epoch time: 0.06]\n",
      "3800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.049973] [epoch time: 0.06]\n",
      "4000 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.478613] [epoch time: 0.06]\n",
      "4200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.960077] [epoch time: 0.06]\n",
      "4400 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.610508] [epoch time: 0.06]\n",
      "4600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.746075] [epoch time: 0.06]\n",
      "4800 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.898365] [epoch time: 0.06]\n",
      "5000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.662607] [epoch time: 0.06]\n",
      "5200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.981812] [epoch time: 0.06]\n",
      "5400 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.519953] [epoch time: 0.06]\n",
      "5600 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.979815] [epoch time: 0.06]\n",
      "5800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.942425] [epoch time: 0.06]\n",
      "6000 [D loss: 0.000004, acc.: 100.00%] [G loss: 15.913275] [epoch time: 0.06]\n",
      "6200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.988633] [epoch time: 0.06]\n",
      "6400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.020699] [epoch time: 0.06]\n",
      "6600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.051573] [epoch time: 0.06]\n",
      "6800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.098185] [epoch time: 0.06]\n",
      "7000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.070553] [epoch time: 0.06]\n",
      "7200 [D loss: 0.005239, acc.: 100.00%] [G loss: 11.418240] [epoch time: 0.06]\n",
      "7400 [D loss: 0.000402, acc.: 100.00%] [G loss: 12.810675] [epoch time: 0.06]\n",
      "7600 [D loss: 0.000474, acc.: 100.00%] [G loss: 13.413706] [epoch time: 0.06]\n",
      "7800 [D loss: 0.000540, acc.: 100.00%] [G loss: 13.690088] [epoch time: 0.06]\n",
      "8000 [D loss: 0.000051, acc.: 100.00%] [G loss: 14.617246] [epoch time: 0.06]\n",
      "8200 [D loss: 0.000045, acc.: 100.00%] [G loss: 15.420488] [epoch time: 0.06]\n",
      "8400 [D loss: 0.000008, acc.: 100.00%] [G loss: 14.692100] [epoch time: 0.06]\n",
      "8600 [D loss: 0.000027, acc.: 100.00%] [G loss: 15.064243] [epoch time: 0.06]\n",
      "8800 [D loss: 0.000009, acc.: 100.00%] [G loss: 15.197362] [epoch time: 0.06]\n",
      "9000 [D loss: 0.000005, acc.: 100.00%] [G loss: 15.697329] [epoch time: 0.06]\n",
      "9200 [D loss: 0.000008, acc.: 100.00%] [G loss: 15.511067] [epoch time: 0.06]\n",
      "9400 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.657329] [epoch time: 0.06]\n",
      "9600 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.709158] [epoch time: 0.06]\n",
      "9800 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.779486] [epoch time: 0.06]\n",
      "10000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.397661] [epoch time: 0.06]\n",
      "10200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.949923] [epoch time: 0.06]\n",
      "10400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.671569] [epoch time: 0.06]\n",
      "10600 [D loss: 0.000006, acc.: 100.00%] [G loss: 15.980678] [epoch time: 0.06]\n",
      "10800 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.931248] [epoch time: 0.06]\n",
      "11000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.959454] [epoch time: 0.06]\n",
      "11200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.058144] [epoch time: 0.06]\n",
      "11400 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.868937] [epoch time: 0.06]\n",
      "11600 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.026812] [epoch time: 0.06]\n",
      "11800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.082226] [epoch time: 0.06]\n",
      "12000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.001026] [epoch time: 0.06]\n",
      "12200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.077614] [epoch time: 0.06]\n",
      "12400 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.06]\n",
      "12600 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.949480] [epoch time: 0.06]\n",
      "12800 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.048046] [epoch time: 0.06]\n",
      "13000 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.926011] [epoch time: 0.06]\n",
      "13200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.055576] [epoch time: 0.06]\n",
      "13400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.098288] [epoch time: 0.06]\n",
      "13600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.061707] [epoch time: 0.06]\n",
      "13800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.051073] [epoch time: 0.06]\n",
      "14000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.077126] [epoch time: 0.06]\n",
      "14200 [D loss: 0.000000, acc.: 100.00%] [G loss: 15.983089] [epoch time: 0.06]\n",
      "14400 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "14600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.043617] [epoch time: 0.06]\n",
      "14800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "15000 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.859558] [epoch time: 0.06]\n",
      "15200 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.910530] [epoch time: 0.06]\n",
      "15400 [D loss: 0.000002, acc.: 100.00%] [G loss: 15.830137] [epoch time: 0.06]\n",
      "15600 [D loss: 0.000001, acc.: 100.00%] [G loss: 15.702665] [epoch time: 0.06]\n",
      "15800 [D loss: 0.000034, acc.: 100.00%] [G loss: 15.773035] [epoch time: 0.06]\n",
      "16000 [D loss: 0.000011, acc.: 100.00%] [G loss: 16.041470] [epoch time: 0.06]\n",
      "16200 [D loss: 0.000051, acc.: 100.00%] [G loss: 15.945890] [epoch time: 0.06]\n",
      "16400 [D loss: 0.000004, acc.: 100.00%] [G loss: 16.070686] [epoch time: 0.06]\n",
      "16600 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.067545] [epoch time: 0.06]\n",
      "16800 [D loss: 0.000003, acc.: 100.00%] [G loss: 16.049744] [epoch time: 0.06]\n",
      "17000 [D loss: 0.000003, acc.: 100.00%] [G loss: 15.990658] [epoch time: 0.06]\n",
      "17200 [D loss: 0.000014, acc.: 100.00%] [G loss: 16.015972] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17400 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.069040] [epoch time: 0.06]\n",
      "17600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.089207] [epoch time: 0.06]\n",
      "17800 [D loss: 0.000009, acc.: 100.00%] [G loss: 16.004593] [epoch time: 0.06]\n",
      "18000 [D loss: 0.000002, acc.: 100.00%] [G loss: 16.096933] [epoch time: 0.06]\n",
      "18200 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.115349] [epoch time: 0.06]\n",
      "18400 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.111862] [epoch time: 0.06]\n",
      "18600 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.083355] [epoch time: 0.06]\n",
      "18800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.067066] [epoch time: 0.06]\n",
      "19000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19200 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19400 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19600 [D loss: 0.000001, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "19800 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "20000 [D loss: 0.000000, acc.: 100.00%] [G loss: 16.118095] [epoch time: 0.06]\n",
      "elapsed training time: 14 min, 9 sec \n"
     ]
    }
   ],
   "source": [
    "ratio_array = [ (1,1) , (1,2), (1,3), (3,1), (2,1), (10,1), (1,10)]\n",
    "# ratio_array = [ (1,30), (1,60), (1,90), (30,1), (60,1), (90,1) ] # rip \n",
    "\n",
    "model_array =  ['Deep_BN', 'Super_Shallow_BN', 'Super_Deeper_G_BN', 'Super_Deeper_D_BN' ]# ['Deep_BN', 'Drop', 'Shallow_BN', 'Shallow_Drop', 'Deeper_G_BN', 'Deeper_D_BN']\n",
    "\n",
    "optimizer_array = [0.0002] #[0.000025, 0.0000125] #[0.0001, 0.00005, 0.000025, 0.0000125] # 2, 4, 8, 16 time smaller\n",
    "for pick_model in model_array:\n",
    "    \n",
    "    \n",
    "    for learning_rate in optimizer_array:\n",
    "    \n",
    "        \n",
    "        #----------------------------------------LOOP OVER RATIOS--------------------------------#\n",
    "        for ratio in ratio_array:\n",
    "            #---------------------------COMPILE SELECTED MODELS--------------------------------------#\n",
    "            # build discriminator\n",
    "            optimizer = Adam(learning_rate, 0.5)\n",
    "\n",
    "            discriminator = build_discriminator(pick_model=pick_model)\n",
    "            discriminator.compile(loss='binary_crossentropy',\n",
    "                                  optimizer=optimizer,\n",
    "                                  metrics=['accuracy'])\n",
    "\n",
    "            # build generator\n",
    "            generator = build_generator(pick_model=pick_model)\n",
    "            z = Input(shape=(100,))\n",
    "            img = generator(z)\n",
    "\n",
    "            # For the combined model we will only train the generator\n",
    "            discriminator.trainable = False\n",
    "\n",
    "            # The discriminator takes generated images as input and determines validity\n",
    "            valid = discriminator(img)\n",
    "\n",
    "            # The combined model  (stacked generator and discriminator)\n",
    "            # Trains the generator to fool the discriminator\n",
    "            combined = Model(z, valid)\n",
    "            combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "            epochs = int(20000*(learning_rate/0.0002))\n",
    "            #----------------------------------------EXECUTION-----------------------------------#\n",
    "            start = time.time()\n",
    "\n",
    "            train(epochs=epochs+1, batch_size=64, save_interval=epochs//100, ratio=ratio, pick_model=pick_model, learning_rate=learning_rate) ## ratio G:D\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            #--------------------------------------GET--INFO-------------------------------------#\n",
    "            elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) / 60),\n",
    "                                                                                 int((end - start) % 60))\n",
    "            train_hist['total_ptime'].append(elapsed_train_time)\n",
    "\n",
    "            print(elapsed_train_time)\n",
    "            os.makedirs(root + 'hist/', exist_ok=True)  \n",
    "            show_train_hist(train_hist, save=True, path=root + 'hist/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model+ '_' + str(learning_rate) + '.png')\n",
    "            # save hist data to csv\n",
    "            os.makedirs(root + 'hist_csv/', exist_ok=True) \n",
    "            with open(root+ 'hist_csv/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model + '_' +str(learning_rate) + '.csv', 'w') as f:\n",
    "                for key in train_hist.keys():\n",
    "                    f.write(\"%s,%s\\n\"%(key,train_hist[key]))\n",
    "\n",
    "            # save weights\n",
    "\n",
    "\n",
    "            # remove old data structure\n",
    "            del train_hist\n",
    "            # redefine\n",
    "            train_hist = {}\n",
    "            train_hist['D_losses'] = []\n",
    "            train_hist['G_losses'] = []\n",
    "            train_hist['per_epoch_ptimes'] = []\n",
    "            train_hist['total_ptime'] = []\n",
    "            train_hist['accuracy'] = []\n",
    "            train_hist['Model'] = []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_141 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_29 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_57 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_58 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_147 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.972408, acc.: 39.84%] [G loss: 1.095028] [epoch time: 26.51]\n",
      "200 [D loss: 0.001122, acc.: 100.00%] [G loss: 0.362781] [epoch time: 0.05]\n",
      "400 [D loss: 0.002322, acc.: 100.00%] [G loss: 0.253584] [epoch time: 0.05]\n",
      "600 [D loss: 0.014672, acc.: 100.00%] [G loss: 4.918403] [epoch time: 0.09]\n",
      "800 [D loss: 0.001158, acc.: 100.00%] [G loss: 0.192187] [epoch time: 0.05]\n",
      "1000 [D loss: 0.339397, acc.: 85.16%] [G loss: 0.117560] [epoch time: 0.05]\n",
      "1200 [D loss: 0.001069, acc.: 100.00%] [G loss: 0.045243] [epoch time: 0.08]\n",
      "1400 [D loss: 0.002461, acc.: 100.00%] [G loss: 0.235193] [epoch time: 0.05]\n",
      "1600 [D loss: 0.002324, acc.: 100.00%] [G loss: 0.222828] [epoch time: 0.05]\n",
      "1800 [D loss: 0.007974, acc.: 100.00%] [G loss: 0.946931] [epoch time: 0.08]\n",
      "2000 [D loss: 0.085615, acc.: 98.44%] [G loss: 2.278091] [epoch time: 0.05]\n",
      "2200 [D loss: 0.049041, acc.: 100.00%] [G loss: 4.258592] [epoch time: 0.05]\n",
      "2400 [D loss: 0.011930, acc.: 100.00%] [G loss: 4.854603] [epoch time: 0.09]\n",
      "2600 [D loss: 0.326884, acc.: 85.16%] [G loss: 3.290105] [epoch time: 0.05]\n",
      "2800 [D loss: 0.078745, acc.: 100.00%] [G loss: 2.471306] [epoch time: 0.05]\n",
      "3000 [D loss: 0.046595, acc.: 100.00%] [G loss: 3.820210] [epoch time: 0.09]\n",
      "3200 [D loss: 0.149186, acc.: 93.75%] [G loss: 2.318785] [epoch time: 0.05]\n",
      "3400 [D loss: 0.067145, acc.: 99.22%] [G loss: 3.781804] [epoch time: 0.05]\n",
      "3600 [D loss: 0.276455, acc.: 88.28%] [G loss: 3.935779] [epoch time: 0.08]\n",
      "3800 [D loss: 0.090651, acc.: 99.22%] [G loss: 2.980679] [epoch time: 0.05]\n",
      "4000 [D loss: 0.108555, acc.: 98.44%] [G loss: 4.372334] [epoch time: 0.05]\n",
      "4200 [D loss: 0.021491, acc.: 100.00%] [G loss: 4.384091] [epoch time: 0.09]\n",
      "4400 [D loss: 0.027031, acc.: 99.22%] [G loss: 5.346201] [epoch time: 0.05]\n",
      "4600 [D loss: 0.012564, acc.: 100.00%] [G loss: 5.287126] [epoch time: 0.05]\n",
      "4800 [D loss: 0.011563, acc.: 100.00%] [G loss: 6.182003] [epoch time: 0.09]\n",
      "5000 [D loss: 0.021304, acc.: 100.00%] [G loss: 5.015374] [epoch time: 0.05]\n",
      "5200 [D loss: 0.049778, acc.: 100.00%] [G loss: 3.312972] [epoch time: 0.05]\n",
      "5400 [D loss: 0.060633, acc.: 100.00%] [G loss: 5.881816] [epoch time: 0.09]\n",
      "5600 [D loss: 0.054796, acc.: 99.22%] [G loss: 5.876542] [epoch time: 0.05]\n",
      "5800 [D loss: 0.161359, acc.: 94.53%] [G loss: 4.772978] [epoch time: 0.05]\n",
      "6000 [D loss: 0.045607, acc.: 99.22%] [G loss: 5.427075] [epoch time: 0.09]\n",
      "6200 [D loss: 0.047749, acc.: 99.22%] [G loss: 3.138236] [epoch time: 0.05]\n",
      "6400 [D loss: 0.141043, acc.: 93.75%] [G loss: 4.338983] [epoch time: 0.05]\n",
      "6600 [D loss: 0.006554, acc.: 100.00%] [G loss: 4.947379] [epoch time: 0.09]\n",
      "6800 [D loss: 0.029751, acc.: 100.00%] [G loss: 4.494855] [epoch time: 0.05]\n",
      "7000 [D loss: 0.081479, acc.: 97.66%] [G loss: 4.772556] [epoch time: 0.05]\n",
      "7200 [D loss: 0.049224, acc.: 100.00%] [G loss: 4.280951] [epoch time: 0.09]\n",
      "7400 [D loss: 0.054189, acc.: 99.22%] [G loss: 5.023796] [epoch time: 0.05]\n",
      "7600 [D loss: 0.055473, acc.: 99.22%] [G loss: 5.999565] [epoch time: 0.05]\n",
      "7800 [D loss: 0.019179, acc.: 99.22%] [G loss: 5.719047] [epoch time: 0.09]\n",
      "8000 [D loss: 0.013409, acc.: 100.00%] [G loss: 4.192751] [epoch time: 0.05]\n",
      "8200 [D loss: 0.021581, acc.: 100.00%] [G loss: 5.927316] [epoch time: 0.05]\n",
      "8400 [D loss: 0.024043, acc.: 100.00%] [G loss: 8.092891] [epoch time: 0.08]\n",
      "8600 [D loss: 0.007217, acc.: 100.00%] [G loss: 5.098043] [epoch time: 0.05]\n",
      "8800 [D loss: 0.019255, acc.: 100.00%] [G loss: 4.514923] [epoch time: 0.05]\n",
      "9000 [D loss: 0.021663, acc.: 100.00%] [G loss: 5.751373] [epoch time: 0.09]\n",
      "9200 [D loss: 0.003519, acc.: 100.00%] [G loss: 5.720074] [epoch time: 0.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9400 [D loss: 0.020397, acc.: 100.00%] [G loss: 3.681775] [epoch time: 0.05]\n",
      "9600 [D loss: 0.010948, acc.: 100.00%] [G loss: 5.321174] [epoch time: 0.09]\n",
      "9800 [D loss: 0.009540, acc.: 100.00%] [G loss: 7.284524] [epoch time: 0.05]\n",
      "10000 [D loss: 0.003292, acc.: 100.00%] [G loss: 6.708129] [epoch time: 0.05]\n",
      "10200 [D loss: 0.015250, acc.: 100.00%] [G loss: 6.014953] [epoch time: 0.08]\n",
      "10400 [D loss: 0.055338, acc.: 98.44%] [G loss: 7.568379] [epoch time: 0.05]\n",
      "10600 [D loss: 0.034366, acc.: 99.22%] [G loss: 10.883080] [epoch time: 0.05]\n",
      "10800 [D loss: 0.012835, acc.: 100.00%] [G loss: 7.588521] [epoch time: 0.08]\n",
      "11000 [D loss: 0.010750, acc.: 100.00%] [G loss: 6.469763] [epoch time: 0.05]\n",
      "11200 [D loss: 0.014628, acc.: 100.00%] [G loss: 5.876101] [epoch time: 0.05]\n",
      "11400 [D loss: 0.016321, acc.: 100.00%] [G loss: 5.782694] [epoch time: 0.08]\n",
      "11600 [D loss: 0.096904, acc.: 97.66%] [G loss: 4.899748] [epoch time: 0.05]\n",
      "11800 [D loss: 0.014140, acc.: 100.00%] [G loss: 3.813360] [epoch time: 0.05]\n",
      "12000 [D loss: 0.031473, acc.: 99.22%] [G loss: 5.771869] [epoch time: 0.09]\n",
      "12200 [D loss: 0.016544, acc.: 99.22%] [G loss: 5.237404] [epoch time: 0.05]\n",
      "12400 [D loss: 0.003410, acc.: 100.00%] [G loss: 5.918956] [epoch time: 0.05]\n",
      "12600 [D loss: 0.004342, acc.: 100.00%] [G loss: 9.784039] [epoch time: 0.08]\n",
      "12800 [D loss: 0.016421, acc.: 100.00%] [G loss: 6.469790] [epoch time: 0.05]\n",
      "13000 [D loss: 0.008802, acc.: 100.00%] [G loss: 8.043478] [epoch time: 0.05]\n",
      "13200 [D loss: 0.002411, acc.: 100.00%] [G loss: 8.901432] [epoch time: 0.09]\n",
      "13400 [D loss: 0.004510, acc.: 100.00%] [G loss: 10.731098] [epoch time: 0.05]\n",
      "13600 [D loss: 0.006200, acc.: 100.00%] [G loss: 4.510098] [epoch time: 0.05]\n",
      "13800 [D loss: 0.015419, acc.: 100.00%] [G loss: 8.319925] [epoch time: 0.08]\n",
      "14000 [D loss: 0.130805, acc.: 96.09%] [G loss: 6.257208] [epoch time: 0.05]\n",
      "14200 [D loss: 0.035875, acc.: 99.22%] [G loss: 6.243561] [epoch time: 0.05]\n",
      "14400 [D loss: 0.005725, acc.: 100.00%] [G loss: 8.372541] [epoch time: 0.09]\n",
      "14600 [D loss: 0.202918, acc.: 89.84%] [G loss: 7.886228] [epoch time: 0.05]\n",
      "14800 [D loss: 0.050572, acc.: 99.22%] [G loss: 6.425920] [epoch time: 0.05]\n",
      "15000 [D loss: 0.024141, acc.: 100.00%] [G loss: 6.044370] [epoch time: 0.08]\n",
      "15200 [D loss: 0.012445, acc.: 100.00%] [G loss: 9.392384] [epoch time: 0.05]\n",
      "15400 [D loss: 0.004801, acc.: 100.00%] [G loss: 6.044448] [epoch time: 0.05]\n",
      "15600 [D loss: 0.004761, acc.: 100.00%] [G loss: 6.706762] [epoch time: 0.08]\n",
      "15800 [D loss: 0.004114, acc.: 100.00%] [G loss: 9.713800] [epoch time: 0.05]\n",
      "16000 [D loss: 0.005078, acc.: 100.00%] [G loss: 8.495738] [epoch time: 0.05]\n",
      "16200 [D loss: 0.006205, acc.: 100.00%] [G loss: 6.654925] [epoch time: 0.08]\n",
      "16400 [D loss: 0.008208, acc.: 100.00%] [G loss: 7.417011] [epoch time: 0.05]\n",
      "16600 [D loss: 0.026615, acc.: 99.22%] [G loss: 6.985457] [epoch time: 0.05]\n",
      "16800 [D loss: 0.004878, acc.: 100.00%] [G loss: 9.487508] [epoch time: 0.08]\n",
      "17000 [D loss: 0.016087, acc.: 100.00%] [G loss: 8.548919] [epoch time: 0.05]\n",
      "17200 [D loss: 0.000865, acc.: 100.00%] [G loss: 5.961884] [epoch time: 0.05]\n",
      "17400 [D loss: 0.001339, acc.: 100.00%] [G loss: 8.748807] [epoch time: 0.09]\n",
      "17600 [D loss: 0.000473, acc.: 100.00%] [G loss: 9.478683] [epoch time: 0.05]\n",
      "17800 [D loss: 0.002984, acc.: 100.00%] [G loss: 9.329235] [epoch time: 0.05]\n",
      "18000 [D loss: 0.060837, acc.: 98.44%] [G loss: 6.693810] [epoch time: 0.09]\n",
      "18200 [D loss: 0.004512, acc.: 100.00%] [G loss: 5.418716] [epoch time: 0.05]\n",
      "18400 [D loss: 0.002622, acc.: 100.00%] [G loss: 9.704893] [epoch time: 0.05]\n",
      "18600 [D loss: 0.020585, acc.: 100.00%] [G loss: 7.647614] [epoch time: 0.09]\n",
      "18800 [D loss: 0.008599, acc.: 100.00%] [G loss: 7.170920] [epoch time: 0.05]\n",
      "19000 [D loss: 0.002683, acc.: 100.00%] [G loss: 9.113074] [epoch time: 0.05]\n",
      "19200 [D loss: 0.028705, acc.: 100.00%] [G loss: 7.943702] [epoch time: 0.09]\n",
      "19400 [D loss: 0.006470, acc.: 100.00%] [G loss: 6.677464] [epoch time: 0.05]\n",
      "19600 [D loss: 0.003727, acc.: 100.00%] [G loss: 6.412505] [epoch time: 0.05]\n",
      "19800 [D loss: 0.007616, acc.: 100.00%] [G loss: 8.528749] [epoch time: 0.08]\n",
      "20000 [D loss: 0.001010, acc.: 100.00%] [G loss: 5.292102] [epoch time: 0.05]\n",
      "elapsed training time: 17 min, 15 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_148 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_30 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_59 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_60 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.939692, acc.: 41.41%] [G loss: 0.697980] [epoch time: 25.56]\n",
      "200 [D loss: 0.001298, acc.: 100.00%] [G loss: 12.621004] [epoch time: 0.05]\n",
      "400 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.192312] [epoch time: 0.05]\n",
      "600 [D loss: 0.000226, acc.: 100.00%] [G loss: 0.845407] [epoch time: 0.09]\n",
      "800 [D loss: 0.220818, acc.: 94.53%] [G loss: 0.542989] [epoch time: 0.05]\n",
      "1000 [D loss: 0.128902, acc.: 95.31%] [G loss: 4.182220] [epoch time: 0.05]\n",
      "1200 [D loss: 0.006895, acc.: 100.00%] [G loss: 0.085682] [epoch time: 0.09]\n",
      "1400 [D loss: 0.003847, acc.: 100.00%] [G loss: 0.009816] [epoch time: 0.05]\n",
      "1600 [D loss: 0.000947, acc.: 100.00%] [G loss: 2.586396] [epoch time: 0.05]\n",
      "1800 [D loss: 0.002316, acc.: 100.00%] [G loss: 2.190244] [epoch time: 0.09]\n",
      "2000 [D loss: 0.041863, acc.: 99.22%] [G loss: 0.195136] [epoch time: 0.05]\n",
      "2200 [D loss: 0.009103, acc.: 100.00%] [G loss: 4.863677] [epoch time: 0.05]\n",
      "2400 [D loss: 0.056977, acc.: 98.44%] [G loss: 4.725718] [epoch time: 0.09]\n",
      "2600 [D loss: 0.006541, acc.: 100.00%] [G loss: 4.127819] [epoch time: 0.05]\n",
      "2800 [D loss: 0.050642, acc.: 99.22%] [G loss: 4.893886] [epoch time: 0.05]\n",
      "3000 [D loss: 0.011071, acc.: 100.00%] [G loss: 1.977565] [epoch time: 0.09]\n",
      "3200 [D loss: 0.041525, acc.: 100.00%] [G loss: 3.166020] [epoch time: 0.05]\n",
      "3400 [D loss: 0.007017, acc.: 100.00%] [G loss: 7.284256] [epoch time: 0.05]\n",
      "3600 [D loss: 0.006922, acc.: 100.00%] [G loss: 2.169620] [epoch time: 0.09]\n",
      "3800 [D loss: 0.046347, acc.: 99.22%] [G loss: 3.604228] [epoch time: 0.05]\n",
      "4000 [D loss: 0.015659, acc.: 100.00%] [G loss: 4.242840] [epoch time: 0.05]\n",
      "4200 [D loss: 0.569897, acc.: 67.97%] [G loss: 2.261687] [epoch time: 0.09]\n",
      "4400 [D loss: 0.142354, acc.: 93.75%] [G loss: 4.699875] [epoch time: 0.05]\n",
      "4600 [D loss: 0.034780, acc.: 100.00%] [G loss: 5.946455] [epoch time: 0.05]\n",
      "4800 [D loss: 0.004619, acc.: 100.00%] [G loss: 3.634380] [epoch time: 0.09]\n",
      "5000 [D loss: 0.063712, acc.: 98.44%] [G loss: 7.101558] [epoch time: 0.05]\n",
      "5200 [D loss: 0.007750, acc.: 100.00%] [G loss: 6.262176] [epoch time: 0.05]\n",
      "5400 [D loss: 0.010086, acc.: 100.00%] [G loss: 5.996396] [epoch time: 0.09]\n",
      "5600 [D loss: 0.009505, acc.: 100.00%] [G loss: 4.251352] [epoch time: 0.05]\n",
      "5800 [D loss: 0.027371, acc.: 100.00%] [G loss: 5.172068] [epoch time: 0.05]\n",
      "6000 [D loss: 0.037124, acc.: 99.22%] [G loss: 6.121702] [epoch time: 0.09]\n",
      "6200 [D loss: 0.071553, acc.: 98.44%] [G loss: 4.638186] [epoch time: 0.05]\n",
      "6400 [D loss: 0.011251, acc.: 100.00%] [G loss: 6.927994] [epoch time: 0.05]\n",
      "6600 [D loss: 0.006914, acc.: 100.00%] [G loss: 4.531794] [epoch time: 0.09]\n",
      "6800 [D loss: 0.048185, acc.: 100.00%] [G loss: 6.618027] [epoch time: 0.05]\n",
      "7000 [D loss: 0.047713, acc.: 98.44%] [G loss: 7.588825] [epoch time: 0.05]\n",
      "7200 [D loss: 0.003538, acc.: 100.00%] [G loss: 7.664452] [epoch time: 0.09]\n",
      "7400 [D loss: 1.323292, acc.: 39.84%] [G loss: 6.951414] [epoch time: 0.05]\n",
      "7600 [D loss: 0.008616, acc.: 100.00%] [G loss: 8.837649] [epoch time: 0.05]\n",
      "7800 [D loss: 0.027642, acc.: 100.00%] [G loss: 5.770756] [epoch time: 0.09]\n",
      "8000 [D loss: 0.024120, acc.: 100.00%] [G loss: 6.215792] [epoch time: 0.05]\n",
      "8200 [D loss: 0.021380, acc.: 100.00%] [G loss: 7.253451] [epoch time: 0.05]\n",
      "8400 [D loss: 0.004646, acc.: 100.00%] [G loss: 4.537557] [epoch time: 0.09]\n",
      "8600 [D loss: 0.003651, acc.: 100.00%] [G loss: 6.978201] [epoch time: 0.05]\n",
      "8800 [D loss: 0.003654, acc.: 100.00%] [G loss: 7.010642] [epoch time: 0.05]\n",
      "9000 [D loss: 0.023084, acc.: 100.00%] [G loss: 9.979374] [epoch time: 0.09]\n",
      "9200 [D loss: 0.002095, acc.: 100.00%] [G loss: 5.557179] [epoch time: 0.05]\n",
      "9400 [D loss: 0.014386, acc.: 100.00%] [G loss: 5.281941] [epoch time: 0.05]\n",
      "9600 [D loss: 0.009670, acc.: 100.00%] [G loss: 6.510033] [epoch time: 0.09]\n",
      "9800 [D loss: 0.476806, acc.: 75.78%] [G loss: 6.731821] [epoch time: 0.05]\n",
      "10000 [D loss: 0.024485, acc.: 99.22%] [G loss: 8.781511] [epoch time: 0.05]\n",
      "10200 [D loss: 0.015551, acc.: 100.00%] [G loss: 6.450241] [epoch time: 0.09]\n",
      "10400 [D loss: 0.008591, acc.: 100.00%] [G loss: 9.034710] [epoch time: 0.05]\n",
      "10600 [D loss: 0.002802, acc.: 100.00%] [G loss: 6.460602] [epoch time: 0.05]\n",
      "10800 [D loss: 0.005666, acc.: 100.00%] [G loss: 6.914970] [epoch time: 0.09]\n",
      "11000 [D loss: 1.259510, acc.: 56.25%] [G loss: 7.671109] [epoch time: 0.05]\n",
      "11200 [D loss: 0.000833, acc.: 100.00%] [G loss: 5.665355] [epoch time: 0.05]\n",
      "11400 [D loss: 0.012096, acc.: 100.00%] [G loss: 6.115801] [epoch time: 0.09]\n",
      "11600 [D loss: 0.003951, acc.: 100.00%] [G loss: 8.965155] [epoch time: 0.05]\n",
      "11800 [D loss: 0.012688, acc.: 99.22%] [G loss: 6.435143] [epoch time: 0.05]\n",
      "12000 [D loss: 0.005237, acc.: 100.00%] [G loss: 6.660243] [epoch time: 0.09]\n",
      "12200 [D loss: 0.008735, acc.: 100.00%] [G loss: 6.861510] [epoch time: 0.05]\n",
      "12400 [D loss: 0.007226, acc.: 100.00%] [G loss: 4.739426] [epoch time: 0.05]\n",
      "12600 [D loss: 0.003159, acc.: 100.00%] [G loss: 7.286611] [epoch time: 0.09]\n",
      "12800 [D loss: 0.006808, acc.: 100.00%] [G loss: 4.357501] [epoch time: 0.05]\n",
      "13000 [D loss: 0.006675, acc.: 100.00%] [G loss: 7.379688] [epoch time: 0.05]\n",
      "13200 [D loss: 0.001958, acc.: 100.00%] [G loss: 6.573462] [epoch time: 0.09]\n",
      "13400 [D loss: 0.061742, acc.: 100.00%] [G loss: 9.762358] [epoch time: 0.05]\n",
      "13600 [D loss: 0.042680, acc.: 99.22%] [G loss: 6.402397] [epoch time: 0.05]\n",
      "13800 [D loss: 0.014692, acc.: 100.00%] [G loss: 6.512616] [epoch time: 0.09]\n",
      "14000 [D loss: 0.010851, acc.: 100.00%] [G loss: 9.014462] [epoch time: 0.05]\n",
      "14200 [D loss: 0.000285, acc.: 100.00%] [G loss: 5.748520] [epoch time: 0.05]\n",
      "14400 [D loss: 0.004272, acc.: 100.00%] [G loss: 7.804986] [epoch time: 0.09]\n",
      "14600 [D loss: 0.002117, acc.: 100.00%] [G loss: 7.368800] [epoch time: 0.05]\n",
      "14800 [D loss: 0.001688, acc.: 100.00%] [G loss: 3.972346] [epoch time: 0.05]\n",
      "15000 [D loss: 0.038090, acc.: 98.44%] [G loss: 5.816480] [epoch time: 0.09]\n",
      "15200 [D loss: 0.016057, acc.: 100.00%] [G loss: 8.913809] [epoch time: 0.05]\n",
      "15400 [D loss: 0.063318, acc.: 97.66%] [G loss: 9.159801] [epoch time: 0.05]\n",
      "15600 [D loss: 0.000870, acc.: 100.00%] [G loss: 6.359465] [epoch time: 0.09]\n",
      "15800 [D loss: 0.000920, acc.: 100.00%] [G loss: 6.816710] [epoch time: 0.05]\n",
      "16000 [D loss: 0.000275, acc.: 100.00%] [G loss: 6.552058] [epoch time: 0.05]\n",
      "16200 [D loss: 0.005088, acc.: 100.00%] [G loss: 9.067144] [epoch time: 0.09]\n",
      "16400 [D loss: 2.122281, acc.: 21.88%] [G loss: 8.347791] [epoch time: 0.05]\n",
      "16600 [D loss: 0.011816, acc.: 100.00%] [G loss: 7.149439] [epoch time: 0.05]\n",
      "16800 [D loss: 0.012257, acc.: 100.00%] [G loss: 11.472895] [epoch time: 0.09]\n",
      "17000 [D loss: 0.006199, acc.: 100.00%] [G loss: 7.578585] [epoch time: 0.05]\n",
      "17200 [D loss: 0.002602, acc.: 100.00%] [G loss: 7.983278] [epoch time: 0.05]\n",
      "17400 [D loss: 0.053648, acc.: 97.66%] [G loss: 7.100614] [epoch time: 0.09]\n",
      "17600 [D loss: 0.391893, acc.: 82.81%] [G loss: 10.152278] [epoch time: 0.05]\n",
      "17800 [D loss: 0.003980, acc.: 100.00%] [G loss: 8.620918] [epoch time: 0.05]\n",
      "18000 [D loss: 0.018072, acc.: 99.22%] [G loss: 6.190589] [epoch time: 0.09]\n",
      "18200 [D loss: 0.010856, acc.: 100.00%] [G loss: 9.506098] [epoch time: 0.05]\n",
      "18400 [D loss: 0.000863, acc.: 100.00%] [G loss: 10.345737] [epoch time: 0.05]\n",
      "18600 [D loss: 0.010312, acc.: 100.00%] [G loss: 6.827431] [epoch time: 0.09]\n",
      "18800 [D loss: 0.004632, acc.: 100.00%] [G loss: 7.660951] [epoch time: 0.05]\n",
      "19000 [D loss: 0.001214, acc.: 100.00%] [G loss: 7.253681] [epoch time: 0.05]\n",
      "19200 [D loss: 0.001505, acc.: 100.00%] [G loss: 9.941982] [epoch time: 0.09]\n",
      "19400 [D loss: 0.003572, acc.: 100.00%] [G loss: 5.910978] [epoch time: 0.05]\n",
      "19600 [D loss: 0.004153, acc.: 100.00%] [G loss: 6.540484] [epoch time: 0.05]\n",
      "19800 [D loss: 0.000202, acc.: 100.00%] [G loss: 11.535734] [epoch time: 0.09]\n",
      "20000 [D loss: 0.005784, acc.: 100.00%] [G loss: 8.334811] [epoch time: 0.05]\n",
      "elapsed training time: 17 min, 22 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_155 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_156 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_157 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_158 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_96 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_62 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_31 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_61 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_159 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_62 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_160 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 0.990406, acc.: 32.81%] [G loss: 0.579102] [epoch time: 27.33]\n",
      "200 [D loss: 0.000209, acc.: 100.00%] [G loss: 0.020728] [epoch time: 0.05]\n",
      "400 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.028565] [epoch time: 0.05]\n",
      "600 [D loss: 0.005673, acc.: 100.00%] [G loss: 1.742704] [epoch time: 0.05]\n",
      "800 [D loss: 0.000146, acc.: 100.00%] [G loss: 6.854001] [epoch time: 0.05]\n",
      "1000 [D loss: 0.000677, acc.: 100.00%] [G loss: 0.815566] [epoch time: 0.05]\n",
      "1200 [D loss: 0.107646, acc.: 98.44%] [G loss: 7.866009] [epoch time: 0.05]\n",
      "1400 [D loss: 0.000161, acc.: 100.00%] [G loss: 5.159935] [epoch time: 0.05]\n",
      "1600 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.210261] [epoch time: 0.05]\n",
      "1800 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.047165] [epoch time: 0.09]\n",
      "2000 [D loss: 0.021119, acc.: 100.00%] [G loss: 0.184266] [epoch time: 0.05]\n",
      "2200 [D loss: 0.000388, acc.: 100.00%] [G loss: 0.471676] [epoch time: 0.05]\n",
      "2400 [D loss: 0.003521, acc.: 100.00%] [G loss: 1.605383] [epoch time: 0.05]\n",
      "2600 [D loss: 0.025059, acc.: 99.22%] [G loss: 4.372545] [epoch time: 0.05]\n",
      "2800 [D loss: 0.076136, acc.: 98.44%] [G loss: 1.183740] [epoch time: 0.05]\n",
      "3000 [D loss: 0.000422, acc.: 100.00%] [G loss: 0.294099] [epoch time: 0.05]\n",
      "3200 [D loss: 0.001450, acc.: 100.00%] [G loss: 0.959924] [epoch time: 0.05]\n",
      "3400 [D loss: 0.001636, acc.: 100.00%] [G loss: 0.769855] [epoch time: 0.05]\n",
      "3600 [D loss: 0.000416, acc.: 100.00%] [G loss: 1.128471] [epoch time: 0.09]\n",
      "3800 [D loss: 0.000353, acc.: 100.00%] [G loss: 0.453226] [epoch time: 0.05]\n",
      "4000 [D loss: 0.006791, acc.: 100.00%] [G loss: 0.716435] [epoch time: 0.05]\n",
      "4200 [D loss: 0.017042, acc.: 100.00%] [G loss: 1.856286] [epoch time: 0.05]\n",
      "4400 [D loss: 0.070495, acc.: 97.66%] [G loss: 2.412981] [epoch time: 0.05]\n",
      "4600 [D loss: 0.494275, acc.: 80.47%] [G loss: 3.635919] [epoch time: 0.05]\n",
      "4800 [D loss: 0.016520, acc.: 99.22%] [G loss: 4.439496] [epoch time: 0.05]\n",
      "5000 [D loss: 0.010130, acc.: 100.00%] [G loss: 2.015393] [epoch time: 0.05]\n",
      "5200 [D loss: 0.012529, acc.: 100.00%] [G loss: 8.910471] [epoch time: 0.05]\n",
      "5400 [D loss: 0.061153, acc.: 97.66%] [G loss: 6.519727] [epoch time: 0.09]\n",
      "5600 [D loss: 0.082550, acc.: 99.22%] [G loss: 5.326890] [epoch time: 0.05]\n",
      "5800 [D loss: 0.011124, acc.: 100.00%] [G loss: 4.718649] [epoch time: 0.05]\n",
      "6000 [D loss: 0.019877, acc.: 99.22%] [G loss: 6.648772] [epoch time: 0.05]\n",
      "6200 [D loss: 0.005944, acc.: 100.00%] [G loss: 5.309699] [epoch time: 0.05]\n",
      "6400 [D loss: 0.007601, acc.: 100.00%] [G loss: 7.485544] [epoch time: 0.05]\n",
      "6600 [D loss: 0.024794, acc.: 99.22%] [G loss: 8.861761] [epoch time: 0.05]\n",
      "6800 [D loss: 0.006900, acc.: 100.00%] [G loss: 5.728390] [epoch time: 0.05]\n",
      "7000 [D loss: 0.014004, acc.: 100.00%] [G loss: 3.163401] [epoch time: 0.05]\n",
      "7200 [D loss: 0.007081, acc.: 100.00%] [G loss: 6.944105] [epoch time: 0.09]\n",
      "7400 [D loss: 0.006633, acc.: 100.00%] [G loss: 7.016007] [epoch time: 0.05]\n",
      "7600 [D loss: 0.010517, acc.: 100.00%] [G loss: 8.566388] [epoch time: 0.05]\n",
      "7800 [D loss: 0.019116, acc.: 100.00%] [G loss: 5.695950] [epoch time: 0.05]\n",
      "8000 [D loss: 0.008840, acc.: 100.00%] [G loss: 7.303344] [epoch time: 0.05]\n",
      "8200 [D loss: 0.035286, acc.: 100.00%] [G loss: 7.114244] [epoch time: 0.05]\n",
      "8400 [D loss: 0.016694, acc.: 100.00%] [G loss: 5.336305] [epoch time: 0.05]\n",
      "8600 [D loss: 0.003476, acc.: 100.00%] [G loss: 7.073181] [epoch time: 0.05]\n",
      "8800 [D loss: 0.002883, acc.: 100.00%] [G loss: 8.564713] [epoch time: 0.05]\n",
      "9000 [D loss: 0.000819, acc.: 100.00%] [G loss: 7.868448] [epoch time: 0.09]\n",
      "9200 [D loss: 0.039652, acc.: 99.22%] [G loss: 6.884616] [epoch time: 0.05]\n",
      "9400 [D loss: 0.005241, acc.: 100.00%] [G loss: 9.306628] [epoch time: 0.05]\n",
      "9600 [D loss: 0.001662, acc.: 100.00%] [G loss: 8.195416] [epoch time: 0.05]\n",
      "9800 [D loss: 0.019885, acc.: 99.22%] [G loss: 9.223305] [epoch time: 0.05]\n",
      "10000 [D loss: 0.182951, acc.: 95.31%] [G loss: 5.322577] [epoch time: 0.05]\n",
      "10200 [D loss: 0.005348, acc.: 100.00%] [G loss: 6.790786] [epoch time: 0.05]\n",
      "10400 [D loss: 0.023363, acc.: 100.00%] [G loss: 3.435519] [epoch time: 0.05]\n",
      "10600 [D loss: 0.002588, acc.: 100.00%] [G loss: 7.573983] [epoch time: 0.05]\n",
      "10800 [D loss: 0.001166, acc.: 100.00%] [G loss: 7.588552] [epoch time: 0.09]\n",
      "11000 [D loss: 0.005060, acc.: 100.00%] [G loss: 5.241316] [epoch time: 0.05]\n",
      "11200 [D loss: 0.016267, acc.: 100.00%] [G loss: 9.421405] [epoch time: 0.05]\n",
      "11400 [D loss: 0.001068, acc.: 100.00%] [G loss: 7.206788] [epoch time: 0.05]\n",
      "11600 [D loss: 0.001639, acc.: 100.00%] [G loss: 7.180921] [epoch time: 0.05]\n",
      "11800 [D loss: 0.000437, acc.: 100.00%] [G loss: 9.131810] [epoch time: 0.05]\n",
      "12000 [D loss: 0.012598, acc.: 100.00%] [G loss: 8.917964] [epoch time: 0.05]\n",
      "12200 [D loss: 0.003474, acc.: 100.00%] [G loss: 9.242163] [epoch time: 0.05]\n",
      "12400 [D loss: 0.016611, acc.: 99.22%] [G loss: 5.578765] [epoch time: 0.05]\n",
      "12600 [D loss: 0.000385, acc.: 100.00%] [G loss: 8.129600] [epoch time: 0.09]\n",
      "12800 [D loss: 0.014410, acc.: 100.00%] [G loss: 8.390394] [epoch time: 0.05]\n",
      "13000 [D loss: 0.006307, acc.: 100.00%] [G loss: 10.246098] [epoch time: 0.05]\n",
      "13200 [D loss: 0.001179, acc.: 100.00%] [G loss: 4.473831] [epoch time: 0.05]\n",
      "13400 [D loss: 0.004209, acc.: 100.00%] [G loss: 9.916580] [epoch time: 0.05]\n",
      "13600 [D loss: 0.003000, acc.: 100.00%] [G loss: 6.699547] [epoch time: 0.05]\n",
      "13800 [D loss: 0.005816, acc.: 100.00%] [G loss: 10.687370] [epoch time: 0.05]\n",
      "14000 [D loss: 0.017020, acc.: 100.00%] [G loss: 9.203117] [epoch time: 0.05]\n",
      "14200 [D loss: 0.004025, acc.: 100.00%] [G loss: 8.031605] [epoch time: 0.05]\n",
      "14400 [D loss: 0.001933, acc.: 100.00%] [G loss: 7.031146] [epoch time: 0.09]\n",
      "14600 [D loss: 0.028018, acc.: 100.00%] [G loss: 11.555339] [epoch time: 0.05]\n",
      "14800 [D loss: 0.005067, acc.: 100.00%] [G loss: 6.905332] [epoch time: 0.05]\n",
      "15000 [D loss: 0.000332, acc.: 100.00%] [G loss: 8.981966] [epoch time: 0.05]\n",
      "15200 [D loss: 0.007135, acc.: 100.00%] [G loss: 6.953675] [epoch time: 0.05]\n",
      "15400 [D loss: 0.001664, acc.: 100.00%] [G loss: 6.335015] [epoch time: 0.05]\n",
      "15600 [D loss: 0.000600, acc.: 100.00%] [G loss: 5.202460] [epoch time: 0.05]\n",
      "15800 [D loss: 0.009879, acc.: 100.00%] [G loss: 6.805230] [epoch time: 0.05]\n",
      "16000 [D loss: 0.002293, acc.: 100.00%] [G loss: 7.558563] [epoch time: 0.05]\n",
      "16200 [D loss: 0.013730, acc.: 100.00%] [G loss: 4.066437] [epoch time: 0.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16400 [D loss: 0.001746, acc.: 100.00%] [G loss: 8.209297] [epoch time: 0.05]\n",
      "16600 [D loss: 0.000588, acc.: 100.00%] [G loss: 7.885602] [epoch time: 0.05]\n",
      "16800 [D loss: 0.004622, acc.: 100.00%] [G loss: 0.251873] [epoch time: 0.05]\n",
      "17000 [D loss: 0.002333, acc.: 100.00%] [G loss: 8.844582] [epoch time: 0.05]\n",
      "17200 [D loss: 0.000886, acc.: 100.00%] [G loss: 8.393699] [epoch time: 0.05]\n",
      "17400 [D loss: 0.000639, acc.: 100.00%] [G loss: 8.836848] [epoch time: 0.05]\n",
      "17600 [D loss: 0.000846, acc.: 100.00%] [G loss: 9.284134] [epoch time: 0.05]\n",
      "17800 [D loss: 0.003277, acc.: 100.00%] [G loss: 5.246515] [epoch time: 0.05]\n",
      "18000 [D loss: 0.001233, acc.: 100.00%] [G loss: 7.146752] [epoch time: 0.09]\n",
      "18200 [D loss: 0.034862, acc.: 98.44%] [G loss: 3.711475] [epoch time: 0.05]\n",
      "18400 [D loss: 0.003569, acc.: 100.00%] [G loss: 7.367589] [epoch time: 0.05]\n",
      "18600 [D loss: 0.001599, acc.: 100.00%] [G loss: 7.083160] [epoch time: 0.05]\n",
      "18800 [D loss: 0.003965, acc.: 100.00%] [G loss: 8.609360] [epoch time: 0.05]\n",
      "19000 [D loss: 0.005504, acc.: 100.00%] [G loss: 7.407260] [epoch time: 0.05]\n",
      "19200 [D loss: 0.000075, acc.: 100.00%] [G loss: 10.654881] [epoch time: 0.05]\n",
      "19400 [D loss: 0.022429, acc.: 99.22%] [G loss: 16.024469] [epoch time: 0.05]\n",
      "19600 [D loss: 0.020322, acc.: 99.22%] [G loss: 5.358078] [epoch time: 0.05]\n",
      "19800 [D loss: 0.000901, acc.: 100.00%] [G loss: 10.107220] [epoch time: 0.09]\n",
      "20000 [D loss: 0.000244, acc.: 100.00%] [G loss: 7.189154] [epoch time: 0.05]\n",
      "elapsed training time: 17 min, 38 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_162 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_97 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_98 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_99 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_100 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_32 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_63 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_64 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.288644, acc.: 32.03%] [G loss: 0.648689] [epoch time: 29.30]\n",
      "200 [D loss: 1.677974, acc.: 10.16%] [G loss: 1.055775] [epoch time: 0.06]\n",
      "400 [D loss: 1.829706, acc.: 8.59%] [G loss: 1.560930] [epoch time: 0.06]\n",
      "600 [D loss: 1.618096, acc.: 11.72%] [G loss: 1.907763] [epoch time: 0.10]\n",
      "800 [D loss: 1.500892, acc.: 14.84%] [G loss: 0.932772] [epoch time: 0.06]\n",
      "1000 [D loss: 1.258418, acc.: 21.09%] [G loss: 0.950365] [epoch time: 0.06]\n",
      "1200 [D loss: 1.331270, acc.: 17.19%] [G loss: 1.586685] [epoch time: 0.10]\n",
      "1400 [D loss: 1.214283, acc.: 17.19%] [G loss: 0.690189] [epoch time: 0.06]\n",
      "1600 [D loss: 1.130575, acc.: 25.00%] [G loss: 0.905089] [epoch time: 0.06]\n",
      "1800 [D loss: 1.112439, acc.: 14.06%] [G loss: 1.364270] [epoch time: 0.09]\n",
      "2000 [D loss: 1.283927, acc.: 15.62%] [G loss: 0.765614] [epoch time: 0.06]\n",
      "2200 [D loss: 1.061561, acc.: 22.66%] [G loss: 0.798149] [epoch time: 0.06]\n",
      "2400 [D loss: 1.138911, acc.: 12.50%] [G loss: 1.193153] [epoch time: 0.10]\n",
      "2600 [D loss: 1.194095, acc.: 14.84%] [G loss: 0.745537] [epoch time: 0.06]\n",
      "2800 [D loss: 1.222356, acc.: 10.16%] [G loss: 0.871766] [epoch time: 0.06]\n",
      "3000 [D loss: 1.024071, acc.: 21.88%] [G loss: 1.158126] [epoch time: 0.10]\n",
      "3200 [D loss: 1.232738, acc.: 12.50%] [G loss: 0.669356] [epoch time: 0.06]\n",
      "3400 [D loss: 1.083417, acc.: 13.28%] [G loss: 0.839855] [epoch time: 0.06]\n",
      "3600 [D loss: 1.036266, acc.: 14.84%] [G loss: 1.056414] [epoch time: 0.10]\n",
      "3800 [D loss: 1.036838, acc.: 17.97%] [G loss: 0.722457] [epoch time: 0.06]\n",
      "4000 [D loss: 1.077829, acc.: 18.75%] [G loss: 0.835800] [epoch time: 0.06]\n",
      "4200 [D loss: 0.998559, acc.: 21.88%] [G loss: 1.034652] [epoch time: 0.10]\n",
      "4400 [D loss: 0.973135, acc.: 20.31%] [G loss: 0.700872] [epoch time: 0.06]\n",
      "4600 [D loss: 0.948714, acc.: 26.56%] [G loss: 0.826837] [epoch time: 0.06]\n",
      "4800 [D loss: 0.898893, acc.: 29.69%] [G loss: 0.945687] [epoch time: 0.10]\n",
      "5000 [D loss: 1.094900, acc.: 9.38%] [G loss: 0.767624] [epoch time: 0.06]\n",
      "5200 [D loss: 0.907199, acc.: 23.44%] [G loss: 0.851274] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 [D loss: 0.963460, acc.: 21.09%] [G loss: 0.948679] [epoch time: 0.10]\n",
      "5600 [D loss: 0.901194, acc.: 24.22%] [G loss: 0.798109] [epoch time: 0.06]\n",
      "5800 [D loss: 0.867516, acc.: 24.22%] [G loss: 0.921384] [epoch time: 0.06]\n",
      "6000 [D loss: 0.852182, acc.: 33.59%] [G loss: 1.048419] [epoch time: 0.10]\n",
      "6200 [D loss: 0.881878, acc.: 33.59%] [G loss: 0.814583] [epoch time: 0.06]\n",
      "6400 [D loss: 0.957296, acc.: 17.19%] [G loss: 0.770979] [epoch time: 0.06]\n",
      "6600 [D loss: 0.902366, acc.: 20.31%] [G loss: 0.937082] [epoch time: 0.10]\n",
      "6800 [D loss: 0.867394, acc.: 27.34%] [G loss: 0.846662] [epoch time: 0.06]\n",
      "7000 [D loss: 0.919398, acc.: 23.44%] [G loss: 0.745283] [epoch time: 0.06]\n",
      "7200 [D loss: 0.842730, acc.: 32.03%] [G loss: 0.941629] [epoch time: 0.10]\n",
      "7400 [D loss: 0.834944, acc.: 34.38%] [G loss: 0.714629] [epoch time: 0.06]\n",
      "7600 [D loss: 0.822537, acc.: 31.25%] [G loss: 0.813719] [epoch time: 0.06]\n",
      "7800 [D loss: 0.757298, acc.: 40.62%] [G loss: 1.019201] [epoch time: 0.10]\n",
      "8000 [D loss: 0.902016, acc.: 23.44%] [G loss: 0.757097] [epoch time: 0.06]\n",
      "8200 [D loss: 0.789032, acc.: 39.84%] [G loss: 0.875312] [epoch time: 0.06]\n",
      "8400 [D loss: 0.907498, acc.: 20.31%] [G loss: 0.872278] [epoch time: 0.10]\n",
      "8600 [D loss: 0.881849, acc.: 26.56%] [G loss: 0.671432] [epoch time: 0.06]\n",
      "8800 [D loss: 0.947766, acc.: 21.09%] [G loss: 0.666573] [epoch time: 0.06]\n",
      "9000 [D loss: 0.900404, acc.: 24.22%] [G loss: 0.845384] [epoch time: 0.09]\n",
      "9200 [D loss: 0.858074, acc.: 31.25%] [G loss: 0.817058] [epoch time: 0.06]\n",
      "9400 [D loss: 0.784593, acc.: 37.50%] [G loss: 0.805776] [epoch time: 0.06]\n",
      "9600 [D loss: 0.860082, acc.: 29.69%] [G loss: 0.886236] [epoch time: 0.10]\n",
      "9800 [D loss: 0.849688, acc.: 30.47%] [G loss: 0.663258] [epoch time: 0.06]\n",
      "10000 [D loss: 0.777100, acc.: 39.06%] [G loss: 0.808658] [epoch time: 0.06]\n",
      "10200 [D loss: 0.862452, acc.: 26.56%] [G loss: 0.866023] [epoch time: 0.10]\n",
      "10400 [D loss: 0.747220, acc.: 46.09%] [G loss: 0.841289] [epoch time: 0.06]\n",
      "10600 [D loss: 0.817451, acc.: 31.25%] [G loss: 0.932892] [epoch time: 0.06]\n",
      "10800 [D loss: 0.875254, acc.: 25.78%] [G loss: 0.943708] [epoch time: 0.10]\n",
      "11000 [D loss: 0.866899, acc.: 25.78%] [G loss: 0.915092] [epoch time: 0.06]\n",
      "11200 [D loss: 0.913788, acc.: 24.22%] [G loss: 0.758066] [epoch time: 0.06]\n",
      "11400 [D loss: 0.839985, acc.: 32.81%] [G loss: 0.870730] [epoch time: 0.10]\n",
      "11600 [D loss: 0.750969, acc.: 44.53%] [G loss: 0.729458] [epoch time: 0.06]\n",
      "11800 [D loss: 0.809225, acc.: 33.59%] [G loss: 1.009336] [epoch time: 0.06]\n",
      "12000 [D loss: 0.825345, acc.: 32.03%] [G loss: 0.919905] [epoch time: 0.10]\n",
      "12200 [D loss: 0.767909, acc.: 41.41%] [G loss: 0.651962] [epoch time: 0.06]\n",
      "12400 [D loss: 0.842279, acc.: 31.25%] [G loss: 0.790277] [epoch time: 0.06]\n",
      "12600 [D loss: 0.834282, acc.: 35.16%] [G loss: 0.925179] [epoch time: 0.10]\n",
      "12800 [D loss: 0.893392, acc.: 20.31%] [G loss: 0.693272] [epoch time: 0.06]\n",
      "13000 [D loss: 0.848586, acc.: 28.12%] [G loss: 0.757350] [epoch time: 0.06]\n",
      "13200 [D loss: 0.890500, acc.: 24.22%] [G loss: 0.704426] [epoch time: 0.10]\n",
      "13400 [D loss: 0.840628, acc.: 26.56%] [G loss: 0.661040] [epoch time: 0.06]\n",
      "13600 [D loss: 0.803182, acc.: 34.38%] [G loss: 0.745961] [epoch time: 0.06]\n",
      "13800 [D loss: 0.844168, acc.: 32.03%] [G loss: 0.771204] [epoch time: 0.10]\n",
      "14000 [D loss: 0.838134, acc.: 35.94%] [G loss: 0.708738] [epoch time: 0.06]\n",
      "14200 [D loss: 0.798558, acc.: 33.59%] [G loss: 0.790746] [epoch time: 0.06]\n",
      "14400 [D loss: 0.815117, acc.: 39.84%] [G loss: 0.789708] [epoch time: 0.09]\n",
      "14600 [D loss: 0.798135, acc.: 30.47%] [G loss: 0.781666] [epoch time: 0.06]\n",
      "14800 [D loss: 0.791668, acc.: 33.59%] [G loss: 0.737800] [epoch time: 0.06]\n",
      "15000 [D loss: 0.781660, acc.: 35.94%] [G loss: 0.751620] [epoch time: 0.09]\n",
      "15200 [D loss: 0.813222, acc.: 30.47%] [G loss: 0.724198] [epoch time: 0.06]\n",
      "15400 [D loss: 0.800270, acc.: 32.81%] [G loss: 0.786915] [epoch time: 0.06]\n",
      "15600 [D loss: 0.810830, acc.: 31.25%] [G loss: 0.814922] [epoch time: 0.10]\n",
      "15800 [D loss: 0.783260, acc.: 34.38%] [G loss: 0.728065] [epoch time: 0.06]\n",
      "16000 [D loss: 0.783048, acc.: 39.06%] [G loss: 0.801451] [epoch time: 0.06]\n",
      "16200 [D loss: 0.773780, acc.: 39.84%] [G loss: 0.767709] [epoch time: 0.10]\n",
      "16400 [D loss: 0.770785, acc.: 39.84%] [G loss: 0.752167] [epoch time: 0.06]\n",
      "16600 [D loss: 0.813550, acc.: 27.34%] [G loss: 0.719720] [epoch time: 0.06]\n",
      "16800 [D loss: 0.792035, acc.: 32.03%] [G loss: 0.797278] [epoch time: 0.10]\n",
      "17000 [D loss: 0.762110, acc.: 38.28%] [G loss: 0.799675] [epoch time: 0.06]\n",
      "17200 [D loss: 0.758763, acc.: 37.50%] [G loss: 0.785618] [epoch time: 0.06]\n",
      "17400 [D loss: 0.762875, acc.: 41.41%] [G loss: 0.842421] [epoch time: 0.10]\n",
      "17600 [D loss: 0.778587, acc.: 31.25%] [G loss: 0.764222] [epoch time: 0.06]\n",
      "17800 [D loss: 0.800365, acc.: 34.38%] [G loss: 0.718995] [epoch time: 0.06]\n",
      "18000 [D loss: 0.745431, acc.: 43.75%] [G loss: 0.813403] [epoch time: 0.10]\n",
      "18200 [D loss: 0.779866, acc.: 39.06%] [G loss: 0.785236] [epoch time: 0.06]\n",
      "18400 [D loss: 0.758092, acc.: 40.62%] [G loss: 0.844507] [epoch time: 0.06]\n",
      "18600 [D loss: 0.808302, acc.: 31.25%] [G loss: 0.778050] [epoch time: 0.10]\n",
      "18800 [D loss: 0.800838, acc.: 31.25%] [G loss: 0.711904] [epoch time: 0.06]\n",
      "19000 [D loss: 0.834206, acc.: 25.78%] [G loss: 0.691848] [epoch time: 0.06]\n",
      "19200 [D loss: 0.812249, acc.: 32.03%] [G loss: 0.766305] [epoch time: 0.10]\n",
      "19400 [D loss: 0.817032, acc.: 32.81%] [G loss: 0.791491] [epoch time: 0.06]\n",
      "19600 [D loss: 0.770022, acc.: 36.72%] [G loss: 0.794148] [epoch time: 0.06]\n",
      "19800 [D loss: 0.765446, acc.: 37.50%] [G loss: 0.767106] [epoch time: 0.10]\n",
      "20000 [D loss: 0.759381, acc.: 43.75%] [G loss: 0.695239] [epoch time: 0.06]\n",
      "elapsed training time: 22 min, 19 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_169 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_101 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_102 (LeakyReLU)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_103 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_104 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_33 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_65 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_66 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.037464, acc.: 35.16%] [G loss: 0.565909] [epoch time: 30.81]\n",
      "200 [D loss: 2.589215, acc.: 1.56%] [G loss: 1.207930] [epoch time: 0.06]\n",
      "400 [D loss: 2.533916, acc.: 3.91%] [G loss: 0.459523] [epoch time: 0.06]\n",
      "600 [D loss: 2.848813, acc.: 3.12%] [G loss: 2.624863] [epoch time: 0.10]\n",
      "800 [D loss: 2.117689, acc.: 3.12%] [G loss: 1.367317] [epoch time: 0.06]\n",
      "1000 [D loss: 1.864868, acc.: 6.25%] [G loss: 0.587944] [epoch time: 0.06]\n",
      "1200 [D loss: 1.738318, acc.: 2.34%] [G loss: 2.151595] [epoch time: 0.10]\n",
      "1400 [D loss: 1.915804, acc.: 3.12%] [G loss: 0.733887] [epoch time: 0.06]\n",
      "1600 [D loss: 1.662641, acc.: 3.91%] [G loss: 0.571480] [epoch time: 0.06]\n",
      "1800 [D loss: 1.583571, acc.: 2.34%] [G loss: 1.761340] [epoch time: 0.10]\n",
      "2000 [D loss: 1.369397, acc.: 7.03%] [G loss: 1.038134] [epoch time: 0.07]\n",
      "2200 [D loss: 1.431277, acc.: 6.25%] [G loss: 0.847328] [epoch time: 0.06]\n",
      "2400 [D loss: 1.389349, acc.: 4.69%] [G loss: 1.523222] [epoch time: 0.10]\n",
      "2600 [D loss: 1.077634, acc.: 19.53%] [G loss: 0.915578] [epoch time: 0.06]\n",
      "2800 [D loss: 1.275979, acc.: 8.59%] [G loss: 0.807385] [epoch time: 0.06]\n",
      "3000 [D loss: 1.131396, acc.: 12.50%] [G loss: 1.263947] [epoch time: 0.10]\n",
      "3200 [D loss: 1.237059, acc.: 7.03%] [G loss: 0.793211] [epoch time: 0.06]\n",
      "3400 [D loss: 1.262548, acc.: 7.03%] [G loss: 0.769935] [epoch time: 0.06]\n",
      "3600 [D loss: 1.153079, acc.: 7.81%] [G loss: 1.214572] [epoch time: 0.10]\n",
      "3800 [D loss: 1.117990, acc.: 10.94%] [G loss: 0.894915] [epoch time: 0.06]\n",
      "4000 [D loss: 1.051929, acc.: 12.50%] [G loss: 0.851456] [epoch time: 0.07]\n",
      "4200 [D loss: 1.041056, acc.: 14.06%] [G loss: 0.996864] [epoch time: 0.10]\n",
      "4400 [D loss: 1.146748, acc.: 6.25%] [G loss: 0.831200] [epoch time: 0.06]\n",
      "4600 [D loss: 1.009032, acc.: 17.97%] [G loss: 0.781799] [epoch time: 0.06]\n",
      "4800 [D loss: 0.968039, acc.: 20.31%] [G loss: 1.101762] [epoch time: 0.10]\n",
      "5000 [D loss: 0.969345, acc.: 20.31%] [G loss: 0.844563] [epoch time: 0.06]\n",
      "5200 [D loss: 0.946055, acc.: 17.19%] [G loss: 0.807073] [epoch time: 0.06]\n",
      "5400 [D loss: 1.014917, acc.: 17.19%] [G loss: 1.010015] [epoch time: 0.10]\n",
      "5600 [D loss: 1.097423, acc.: 13.28%] [G loss: 0.861409] [epoch time: 0.06]\n",
      "5800 [D loss: 1.064249, acc.: 10.16%] [G loss: 0.664471] [epoch time: 0.06]\n",
      "6000 [D loss: 1.042162, acc.: 11.72%] [G loss: 1.017853] [epoch time: 0.10]\n",
      "6200 [D loss: 1.042089, acc.: 15.62%] [G loss: 0.841804] [epoch time: 0.06]\n",
      "6400 [D loss: 0.956444, acc.: 17.97%] [G loss: 0.716124] [epoch time: 0.06]\n",
      "6600 [D loss: 0.888787, acc.: 28.12%] [G loss: 1.005621] [epoch time: 0.10]\n",
      "6800 [D loss: 0.988656, acc.: 17.97%] [G loss: 0.839176] [epoch time: 0.06]\n",
      "7000 [D loss: 0.983016, acc.: 22.66%] [G loss: 0.834698] [epoch time: 0.06]\n",
      "7200 [D loss: 1.047798, acc.: 11.72%] [G loss: 1.014752] [epoch time: 0.10]\n",
      "7400 [D loss: 0.839707, acc.: 35.94%] [G loss: 0.814768] [epoch time: 0.06]\n",
      "7600 [D loss: 0.955028, acc.: 21.09%] [G loss: 0.752269] [epoch time: 0.06]\n",
      "7800 [D loss: 0.916340, acc.: 19.53%] [G loss: 0.925279] [epoch time: 0.10]\n",
      "8000 [D loss: 0.911136, acc.: 24.22%] [G loss: 0.851334] [epoch time: 0.06]\n",
      "8200 [D loss: 0.936435, acc.: 20.31%] [G loss: 0.799599] [epoch time: 0.06]\n",
      "8400 [D loss: 0.933163, acc.: 24.22%] [G loss: 0.903056] [epoch time: 0.10]\n",
      "8600 [D loss: 0.913633, acc.: 24.22%] [G loss: 0.769685] [epoch time: 0.06]\n",
      "8800 [D loss: 0.890642, acc.: 19.53%] [G loss: 0.810428] [epoch time: 0.06]\n",
      "9000 [D loss: 0.948427, acc.: 19.53%] [G loss: 0.938350] [epoch time: 0.10]\n",
      "9200 [D loss: 0.874930, acc.: 28.12%] [G loss: 0.790922] [epoch time: 0.06]\n",
      "9400 [D loss: 0.955997, acc.: 16.41%] [G loss: 0.833737] [epoch time: 0.06]\n",
      "9600 [D loss: 0.875214, acc.: 22.66%] [G loss: 0.977268] [epoch time: 0.10]\n",
      "9800 [D loss: 0.832072, acc.: 30.47%] [G loss: 0.851770] [epoch time: 0.06]\n",
      "10000 [D loss: 0.868404, acc.: 28.12%] [G loss: 0.795426] [epoch time: 0.06]\n",
      "10200 [D loss: 1.001594, acc.: 13.28%] [G loss: 0.902281] [epoch time: 0.10]\n",
      "10400 [D loss: 0.844965, acc.: 30.47%] [G loss: 0.805830] [epoch time: 0.06]\n",
      "10600 [D loss: 0.948798, acc.: 18.75%] [G loss: 0.661595] [epoch time: 0.06]\n",
      "10800 [D loss: 0.887185, acc.: 24.22%] [G loss: 0.745706] [epoch time: 0.10]\n",
      "11000 [D loss: 0.861016, acc.: 22.66%] [G loss: 0.751464] [epoch time: 0.06]\n",
      "11200 [D loss: 0.879406, acc.: 25.00%] [G loss: 0.781999] [epoch time: 0.06]\n",
      "11400 [D loss: 0.922164, acc.: 19.53%] [G loss: 0.828888] [epoch time: 0.10]\n",
      "11600 [D loss: 0.870581, acc.: 25.78%] [G loss: 0.707769] [epoch time: 0.06]\n",
      "11800 [D loss: 0.917988, acc.: 17.97%] [G loss: 0.808647] [epoch time: 0.06]\n",
      "12000 [D loss: 0.897401, acc.: 24.22%] [G loss: 0.859433] [epoch time: 0.10]\n",
      "12200 [D loss: 0.808635, acc.: 32.03%] [G loss: 0.776838] [epoch time: 0.06]\n",
      "12400 [D loss: 0.838017, acc.: 31.25%] [G loss: 0.773226] [epoch time: 0.06]\n",
      "12600 [D loss: 0.844761, acc.: 32.81%] [G loss: 0.804287] [epoch time: 0.10]\n",
      "12800 [D loss: 0.810218, acc.: 35.16%] [G loss: 0.777857] [epoch time: 0.06]\n",
      "13000 [D loss: 0.844879, acc.: 28.12%] [G loss: 0.743261] [epoch time: 0.06]\n",
      "13200 [D loss: 0.807596, acc.: 37.50%] [G loss: 0.903398] [epoch time: 0.10]\n",
      "13400 [D loss: 0.832463, acc.: 26.56%] [G loss: 0.857230] [epoch time: 0.06]\n",
      "13600 [D loss: 0.857753, acc.: 22.66%] [G loss: 0.808536] [epoch time: 0.06]\n",
      "13800 [D loss: 0.859433, acc.: 27.34%] [G loss: 0.823734] [epoch time: 0.10]\n",
      "14000 [D loss: 0.809334, acc.: 32.03%] [G loss: 0.776204] [epoch time: 0.06]\n",
      "14200 [D loss: 0.804480, acc.: 33.59%] [G loss: 0.821438] [epoch time: 0.06]\n",
      "14400 [D loss: 0.827037, acc.: 25.78%] [G loss: 0.823700] [epoch time: 0.10]\n",
      "14600 [D loss: 0.803706, acc.: 35.16%] [G loss: 0.759857] [epoch time: 0.06]\n",
      "14800 [D loss: 0.865125, acc.: 23.44%] [G loss: 0.704244] [epoch time: 0.06]\n",
      "15000 [D loss: 0.856481, acc.: 26.56%] [G loss: 0.832941] [epoch time: 0.10]\n",
      "15200 [D loss: 0.812270, acc.: 34.38%] [G loss: 0.858174] [epoch time: 0.06]\n",
      "15400 [D loss: 0.816509, acc.: 31.25%] [G loss: 0.712546] [epoch time: 0.06]\n",
      "15600 [D loss: 0.808123, acc.: 35.16%] [G loss: 0.800181] [epoch time: 0.10]\n",
      "15800 [D loss: 0.837961, acc.: 32.03%] [G loss: 0.767570] [epoch time: 0.07]\n",
      "16000 [D loss: 0.808153, acc.: 36.72%] [G loss: 0.776246] [epoch time: 0.06]\n",
      "16200 [D loss: 0.830502, acc.: 25.78%] [G loss: 0.858671] [epoch time: 0.10]\n",
      "16400 [D loss: 0.863734, acc.: 23.44%] [G loss: 0.735577] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16600 [D loss: 0.780733, acc.: 40.62%] [G loss: 0.769145] [epoch time: 0.06]\n",
      "16800 [D loss: 0.851618, acc.: 26.56%] [G loss: 0.819372] [epoch time: 0.10]\n",
      "17000 [D loss: 0.789271, acc.: 36.72%] [G loss: 0.741055] [epoch time: 0.06]\n",
      "17200 [D loss: 0.818159, acc.: 32.81%] [G loss: 0.795352] [epoch time: 0.06]\n",
      "17400 [D loss: 0.823231, acc.: 30.47%] [G loss: 0.777661] [epoch time: 0.10]\n",
      "17600 [D loss: 0.807343, acc.: 31.25%] [G loss: 0.745355] [epoch time: 0.06]\n",
      "17800 [D loss: 0.864043, acc.: 25.78%] [G loss: 0.737910] [epoch time: 0.06]\n",
      "18000 [D loss: 0.832558, acc.: 36.72%] [G loss: 0.758253] [epoch time: 0.10]\n",
      "18200 [D loss: 0.762025, acc.: 37.50%] [G loss: 0.767543] [epoch time: 0.06]\n",
      "18400 [D loss: 0.789542, acc.: 38.28%] [G loss: 0.755037] [epoch time: 0.06]\n",
      "18600 [D loss: 0.810547, acc.: 31.25%] [G loss: 0.728491] [epoch time: 0.10]\n",
      "18800 [D loss: 0.787322, acc.: 36.72%] [G loss: 0.732548] [epoch time: 0.07]\n",
      "19000 [D loss: 0.784629, acc.: 38.28%] [G loss: 0.775444] [epoch time: 0.06]\n",
      "19200 [D loss: 0.856411, acc.: 25.00%] [G loss: 0.730435] [epoch time: 0.10]\n",
      "19400 [D loss: 0.843300, acc.: 27.34%] [G loss: 0.763432] [epoch time: 0.06]\n",
      "19600 [D loss: 0.805711, acc.: 26.56%] [G loss: 0.766726] [epoch time: 0.06]\n",
      "19800 [D loss: 0.764044, acc.: 38.28%] [G loss: 0.778175] [epoch time: 0.10]\n",
      "20000 [D loss: 0.827599, acc.: 32.81%] [G loss: 0.740489] [epoch time: 0.06]\n",
      "elapsed training time: 22 min, 29 sec \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_176 (Conv2D)          (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_105 (LeakyReLU)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPaddi (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_106 (LeakyReLU)  (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)  (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)  (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_34 (Reshape)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_67 (UpSampling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_68 (UpSampling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.152595, acc.: 33.59%] [G loss: 0.541809] [epoch time: 33.16]\n",
      "200 [D loss: 2.864159, acc.: 4.69%] [G loss: 0.685027] [epoch time: 0.06]\n",
      "400 [D loss: 2.825977, acc.: 1.56%] [G loss: 0.494311] [epoch time: 0.07]\n",
      "600 [D loss: 2.945184, acc.: 1.56%] [G loss: 0.408200] [epoch time: 0.07]\n",
      "800 [D loss: 2.842646, acc.: 0.00%] [G loss: 0.526582] [epoch time: 0.07]\n",
      "1000 [D loss: 2.579532, acc.: 0.00%] [G loss: 1.646847] [epoch time: 0.06]\n",
      "1200 [D loss: 2.321470, acc.: 0.00%] [G loss: 0.770363] [epoch time: 0.07]\n",
      "1400 [D loss: 1.975147, acc.: 1.56%] [G loss: 0.769597] [epoch time: 0.07]\n",
      "1600 [D loss: 1.977933, acc.: 0.78%] [G loss: 0.713677] [epoch time: 0.06]\n",
      "1800 [D loss: 1.697482, acc.: 1.56%] [G loss: 2.308378] [epoch time: 0.10]\n",
      "2000 [D loss: 1.704112, acc.: 2.34%] [G loss: 0.835430] [epoch time: 0.06]\n",
      "2200 [D loss: 1.657710, acc.: 3.12%] [G loss: 0.923910] [epoch time: 0.06]\n",
      "2400 [D loss: 1.556667, acc.: 6.25%] [G loss: 0.861310] [epoch time: 0.06]\n",
      "2600 [D loss: 1.600547, acc.: 1.56%] [G loss: 0.642972] [epoch time: 0.06]\n",
      "2800 [D loss: 1.517829, acc.: 0.78%] [G loss: 1.065232] [epoch time: 0.06]\n",
      "3000 [D loss: 1.482369, acc.: 3.12%] [G loss: 0.930899] [epoch time: 0.06]\n",
      "3200 [D loss: 1.433369, acc.: 5.47%] [G loss: 0.850619] [epoch time: 0.06]\n",
      "3400 [D loss: 1.314337, acc.: 8.59%] [G loss: 0.796685] [epoch time: 0.06]\n",
      "3600 [D loss: 1.189571, acc.: 6.25%] [G loss: 1.339113] [epoch time: 0.10]\n",
      "3800 [D loss: 1.289574, acc.: 6.25%] [G loss: 0.963395] [epoch time: 0.07]\n",
      "4000 [D loss: 1.110343, acc.: 10.16%] [G loss: 0.979619] [epoch time: 0.06]\n",
      "4200 [D loss: 1.144772, acc.: 9.38%] [G loss: 0.688055] [epoch time: 0.06]\n",
      "4400 [D loss: 1.166870, acc.: 10.16%] [G loss: 0.752759] [epoch time: 0.07]\n",
      "4600 [D loss: 1.184176, acc.: 8.59%] [G loss: 0.860555] [epoch time: 0.07]\n",
      "4800 [D loss: 1.097967, acc.: 8.59%] [G loss: 0.926711] [epoch time: 0.06]\n",
      "5000 [D loss: 1.128331, acc.: 11.72%] [G loss: 0.781605] [epoch time: 0.06]\n",
      "5200 [D loss: 1.111391, acc.: 10.16%] [G loss: 0.763284] [epoch time: 0.07]\n",
      "5400 [D loss: 1.115559, acc.: 10.94%] [G loss: 1.165790] [epoch time: 0.10]\n",
      "5600 [D loss: 1.150747, acc.: 7.81%] [G loss: 0.828277] [epoch time: 0.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 [D loss: 1.077234, acc.: 7.81%] [G loss: 0.834507] [epoch time: 0.06]\n",
      "6000 [D loss: 1.060455, acc.: 8.59%] [G loss: 0.781269] [epoch time: 0.06]\n",
      "6200 [D loss: 1.032753, acc.: 14.06%] [G loss: 0.757090] [epoch time: 0.07]\n",
      "6400 [D loss: 1.031021, acc.: 19.53%] [G loss: 0.851789] [epoch time: 0.06]\n",
      "6600 [D loss: 1.040898, acc.: 17.19%] [G loss: 0.776707] [epoch time: 0.06]\n",
      "6800 [D loss: 1.008062, acc.: 15.62%] [G loss: 0.835400] [epoch time: 0.07]\n",
      "7000 [D loss: 0.981231, acc.: 24.22%] [G loss: 0.828314] [epoch time: 0.06]\n",
      "7200 [D loss: 0.933887, acc.: 20.31%] [G loss: 0.943349] [epoch time: 0.10]\n",
      "7400 [D loss: 0.933380, acc.: 22.66%] [G loss: 0.940605] [epoch time: 0.06]\n",
      "7600 [D loss: 1.101680, acc.: 11.72%] [G loss: 0.824743] [epoch time: 0.07]\n",
      "7800 [D loss: 1.037287, acc.: 14.84%] [G loss: 0.662348] [epoch time: 0.06]\n",
      "8000 [D loss: 1.027871, acc.: 8.59%] [G loss: 0.673166] [epoch time: 0.07]\n",
      "8200 [D loss: 0.946934, acc.: 24.22%] [G loss: 0.901264] [epoch time: 0.07]\n",
      "8400 [D loss: 0.929032, acc.: 21.09%] [G loss: 0.744323] [epoch time: 0.07]\n",
      "8600 [D loss: 0.933479, acc.: 21.88%] [G loss: 0.812962] [epoch time: 0.06]\n",
      "8800 [D loss: 0.965665, acc.: 19.53%] [G loss: 0.706701] [epoch time: 0.06]\n",
      "9000 [D loss: 0.935718, acc.: 21.09%] [G loss: 0.926848] [epoch time: 0.10]\n",
      "9200 [D loss: 0.906321, acc.: 30.47%] [G loss: 0.905862] [epoch time: 0.06]\n",
      "9400 [D loss: 0.967904, acc.: 17.19%] [G loss: 0.783679] [epoch time: 0.06]\n",
      "9600 [D loss: 0.909224, acc.: 20.31%] [G loss: 0.886508] [epoch time: 0.07]\n",
      "9800 [D loss: 0.924676, acc.: 20.31%] [G loss: 0.696081] [epoch time: 0.07]\n",
      "10000 [D loss: 0.946200, acc.: 20.31%] [G loss: 0.838657] [epoch time: 0.06]\n",
      "10200 [D loss: 0.899375, acc.: 24.22%] [G loss: 0.864739] [epoch time: 0.06]\n",
      "10400 [D loss: 0.932933, acc.: 21.88%] [G loss: 0.828463] [epoch time: 0.06]\n",
      "10600 [D loss: 0.928891, acc.: 18.75%] [G loss: 0.764041] [epoch time: 0.06]\n",
      "10800 [D loss: 0.891414, acc.: 25.00%] [G loss: 0.918623] [epoch time: 0.10]\n",
      "11000 [D loss: 0.905528, acc.: 20.31%] [G loss: 0.790066] [epoch time: 0.06]\n",
      "11200 [D loss: 0.896123, acc.: 21.09%] [G loss: 0.712856] [epoch time: 0.06]\n",
      "11400 [D loss: 0.907396, acc.: 22.66%] [G loss: 0.810872] [epoch time: 0.07]\n",
      "11600 [D loss: 0.962526, acc.: 19.53%] [G loss: 0.662004] [epoch time: 0.06]\n",
      "11800 [D loss: 0.914144, acc.: 20.31%] [G loss: 0.839926] [epoch time: 0.06]\n",
      "12000 [D loss: 0.924528, acc.: 21.88%] [G loss: 0.788459] [epoch time: 0.06]\n",
      "12200 [D loss: 0.962438, acc.: 14.84%] [G loss: 0.778521] [epoch time: 0.06]\n",
      "12400 [D loss: 0.849156, acc.: 29.69%] [G loss: 0.782860] [epoch time: 0.06]\n",
      "12600 [D loss: 0.884275, acc.: 22.66%] [G loss: 0.914659] [epoch time: 0.10]\n",
      "12800 [D loss: 0.861904, acc.: 27.34%] [G loss: 0.867336] [epoch time: 0.06]\n",
      "13000 [D loss: 0.898788, acc.: 23.44%] [G loss: 0.759077] [epoch time: 0.06]\n",
      "13200 [D loss: 0.902988, acc.: 22.66%] [G loss: 0.711190] [epoch time: 0.07]\n",
      "13400 [D loss: 0.883965, acc.: 28.91%] [G loss: 0.687473] [epoch time: 0.06]\n",
      "13600 [D loss: 0.872105, acc.: 26.56%] [G loss: 0.767802] [epoch time: 0.06]\n",
      "13800 [D loss: 0.877907, acc.: 25.78%] [G loss: 0.717734] [epoch time: 0.06]\n",
      "14000 [D loss: 0.885443, acc.: 25.00%] [G loss: 0.771575] [epoch time: 0.06]\n",
      "14200 [D loss: 0.878498, acc.: 31.25%] [G loss: 0.767308] [epoch time: 0.06]\n",
      "14400 [D loss: 0.887929, acc.: 26.56%] [G loss: 0.769541] [epoch time: 0.10]\n",
      "14600 [D loss: 0.833443, acc.: 28.91%] [G loss: 0.836691] [epoch time: 0.06]\n",
      "14800 [D loss: 0.881810, acc.: 22.66%] [G loss: 0.767848] [epoch time: 0.06]\n",
      "15000 [D loss: 0.840778, acc.: 32.03%] [G loss: 0.787195] [epoch time: 0.06]\n",
      "15200 [D loss: 0.843675, acc.: 30.47%] [G loss: 0.769311] [epoch time: 0.07]\n",
      "15400 [D loss: 0.792931, acc.: 39.06%] [G loss: 0.787851] [epoch time: 0.07]\n",
      "15600 [D loss: 0.930668, acc.: 19.53%] [G loss: 0.725343] [epoch time: 0.06]\n",
      "15800 [D loss: 0.889211, acc.: 27.34%] [G loss: 0.723362] [epoch time: 0.06]\n",
      "16000 [D loss: 0.860411, acc.: 31.25%] [G loss: 0.805019] [epoch time: 0.06]\n",
      "16200 [D loss: 0.853854, acc.: 23.44%] [G loss: 0.790143] [epoch time: 0.10]\n",
      "16400 [D loss: 0.810790, acc.: 35.16%] [G loss: 0.811271] [epoch time: 0.06]\n",
      "16600 [D loss: 0.881522, acc.: 26.56%] [G loss: 0.808849] [epoch time: 0.06]\n",
      "16800 [D loss: 0.837992, acc.: 28.12%] [G loss: 0.703228] [epoch time: 0.06]\n",
      "17000 [D loss: 0.832596, acc.: 34.38%] [G loss: 0.755774] [epoch time: 0.06]\n",
      "17200 [D loss: 0.855771, acc.: 27.34%] [G loss: 0.866306] [epoch time: 0.06]\n",
      "17400 [D loss: 0.849322, acc.: 28.91%] [G loss: 0.858806] [epoch time: 0.06]\n",
      "17600 [D loss: 0.839802, acc.: 32.03%] [G loss: 0.801257] [epoch time: 0.06]\n",
      "17800 [D loss: 0.884233, acc.: 27.34%] [G loss: 0.757231] [epoch time: 0.06]\n",
      "18000 [D loss: 0.823465, acc.: 37.50%] [G loss: 0.838219] [epoch time: 0.10]\n",
      "18200 [D loss: 0.815543, acc.: 31.25%] [G loss: 0.760270] [epoch time: 0.06]\n",
      "18400 [D loss: 0.874756, acc.: 20.31%] [G loss: 0.740693] [epoch time: 0.06]\n",
      "18600 [D loss: 0.823295, acc.: 32.03%] [G loss: 0.769907] [epoch time: 0.06]\n",
      "18800 [D loss: 0.842017, acc.: 32.81%] [G loss: 0.717357] [epoch time: 0.07]\n",
      "19000 [D loss: 0.820622, acc.: 32.03%] [G loss: 0.819513] [epoch time: 0.06]\n",
      "19200 [D loss: 0.825749, acc.: 32.81%] [G loss: 0.804680] [epoch time: 0.06]\n",
      "19400 [D loss: 0.827437, acc.: 34.38%] [G loss: 0.764143] [epoch time: 0.06]\n",
      "19600 [D loss: 0.828462, acc.: 33.59%] [G loss: 0.755913] [epoch time: 0.06]\n",
      "19800 [D loss: 0.899476, acc.: 23.44%] [G loss: 0.819430] [epoch time: 0.10]\n",
      "20000 [D loss: 0.817635, acc.: 31.25%] [G loss: 0.787466] [epoch time: 0.06]\n",
      "elapsed training time: 22 min, 46 sec \n"
     ]
    }
   ],
   "source": [
    "ratio_array = [ (1,30), (1,60), (1,90), (30,1), (60,1), (90,1) ] # rip \n",
    "\n",
    "model_array =  ['Deep_BN'] #, 'Super_Shallow_BN', 'Super_Deeper_G_BN', 'Super_Deeper_D_BN' ]# ['Deep_BN', 'Drop', 'Shallow_BN', 'Shallow_Drop', 'Deeper_G_BN', 'Deeper_D_BN']\n",
    "\n",
    "optimizer_array = [0.0002] #[0.000025, 0.0000125] #[0.0001, 0.00005, 0.000025, 0.0000125] # 2, 4, 8, 16 time smaller\n",
    "for pick_model in model_array:\n",
    "    \n",
    "    \n",
    "    for learning_rate in optimizer_array:\n",
    "    \n",
    "        \n",
    "        #----------------------------------------LOOP OVER RATIOS--------------------------------#\n",
    "        for ratio in ratio_array:\n",
    "            #---------------------------COMPILE SELECTED MODELS--------------------------------------#\n",
    "            # build discriminator\n",
    "            optimizer = Adam(learning_rate, 0.5)\n",
    "\n",
    "            discriminator = build_discriminator(pick_model=pick_model)\n",
    "            discriminator.compile(loss='binary_crossentropy',\n",
    "                                  optimizer=optimizer,\n",
    "                                  metrics=['accuracy'])\n",
    "\n",
    "            # build generator\n",
    "            generator = build_generator(pick_model=pick_model)\n",
    "            z = Input(shape=(100,))\n",
    "            img = generator(z)\n",
    "\n",
    "            # For the combined model we will only train the generator\n",
    "            discriminator.trainable = False\n",
    "\n",
    "            # The discriminator takes generated images as input and determines validity\n",
    "            valid = discriminator(img)\n",
    "\n",
    "            # The combined model  (stacked generator and discriminator)\n",
    "            # Trains the generator to fool the discriminator\n",
    "            combined = Model(z, valid)\n",
    "            combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "            epochs = int(20000*(learning_rate/0.0002))\n",
    "            #----------------------------------------EXECUTION-----------------------------------#\n",
    "            start = time.time()\n",
    "\n",
    "            train(epochs=epochs+1, batch_size=64, save_interval=epochs//100, ratio=ratio, pick_model=pick_model, learning_rate=learning_rate) ## ratio G:D\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            #--------------------------------------GET--INFO-------------------------------------#\n",
    "            elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) / 60),\n",
    "                                                                                 int((end - start) % 60))\n",
    "            train_hist['total_ptime'].append(elapsed_train_time)\n",
    "\n",
    "            print(elapsed_train_time)\n",
    "            os.makedirs(root + 'hist/', exist_ok=True)  \n",
    "            show_train_hist(train_hist, save=True, path=root + 'hist/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model+ '_' + str(learning_rate) + '.png')\n",
    "            # save hist data to csv\n",
    "            os.makedirs(root + 'hist_csv/', exist_ok=True) \n",
    "            with open(root+ 'hist_csv/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model + '_' +str(learning_rate) + '.csv', 'w') as f:\n",
    "                for key in train_hist.keys():\n",
    "                    f.write(\"%s,%s\\n\"%(key,train_hist[key]))\n",
    "\n",
    "            # save weights\n",
    "\n",
    "\n",
    "            # remove old data structure\n",
    "            del train_hist\n",
    "            # redefine\n",
    "            train_hist = {}\n",
    "            train_hist['D_losses'] = []\n",
    "            train_hist['G_losses'] = []\n",
    "            train_hist['per_epoch_ptimes'] = []\n",
    "            train_hist['total_ptime'] = []\n",
    "            train_hist['accuracy'] = []\n",
    "            train_hist['Model'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "cb7c9e65347eb077e1dabd74445713ddef12ba34"
   },
   "outputs": [],
   "source": [
    "# os.makedirs('saved_model_weights', exist_ok=True)\n",
    "# generator.save_weights('saved_model_weights/generator_weights.h5')\n",
    "# discriminator.save_weights('saved_model_weights/discriminator_weights.h5')\n",
    "# combined.save_weights('saved_model_weights/combined_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "526455382f869ceadc4206cb703e676a4037b213",
    "collapsed": true
   },
   "source": [
    "## Show generated MNIST images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
