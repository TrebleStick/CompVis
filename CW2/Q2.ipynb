{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "# https://github.com/eriklindernoren/Keras-GAN\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "root = 'CGAN_results/'\n",
    "\n",
    "# plotting data structure\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "train_hist['per_epoch_ptimes'] = []\n",
    "train_hist['total_ptime'] = []\n",
    "train_hist['accuracy'] = []\n",
    "train_hist['Model'] = []\n",
    "train_hist['classif_loss'] = []\n",
    "train_hist['classif_acc'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainClassif():\n",
    "    (train_set, train_label_raw), (_, _) = mnist.load_data()\n",
    "    train_label = to_categorical(train_label_raw)\n",
    "    train_data = np.asarray(train_set).reshape(60000, 28, 28, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.33, random_state=43)\n",
    "\n",
    "#     test_data = test_set.reshape(10000, 28, 28, 1)\n",
    "\n",
    "    np.shape(train_data)\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(Conv2D(5, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 40200 samples, validate on 19800 samples\n",
      "Epoch 1/4\n",
      "40200/40200 [==============================] - 9s 223us/step - loss: 14.4466 - acc: 0.1037 - val_loss: 14.4119 - val_acc: 0.1059\n",
      "Epoch 2/4\n",
      "40200/40200 [==============================] - 7s 168us/step - loss: 14.4465 - acc: 0.1037 - val_loss: 14.4119 - val_acc: 0.1059\n",
      "Epoch 3/4\n",
      "40200/40200 [==============================] - 7s 175us/step - loss: 14.4465 - acc: 0.1037 - val_loss: 14.4119 - val_acc: 0.1059\n",
      "Epoch 4/4\n",
      "40200/40200 [==============================] - 7s 177us/step - loss: 14.4465 - acc: 0.1037 - val_loss: 14.4119 - val_acc: 0.1059\n"
     ]
    }
   ],
   "source": [
    "classif = trainClassif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN():\n",
    "    def __init__(self, pick_model='Deep_BN'):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator(pick_model=pick_model)\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator(pick_model=pick_model)\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self, pick_model='Deep_BN'):\n",
    "        if (pick_model == 'Deep_BN') | (pick_model == 'Deeper_D_BN'):\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(256, input_dim=self.latent_dim))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(1024))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "            model.add(Reshape(self.img_shape))\n",
    "\n",
    "            model.summary()\n",
    "\n",
    "        elif (pick_model == 'Shallow_BN') | (pick_model == 'Deeper_G_BN'): \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(256, input_dim=self.latent_dim))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "            model.add(Reshape(self.img_shape))\n",
    "\n",
    "            model.summary()\n",
    "        elif pick_model == 'Shallow_Drop':\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(256, input_dim=self.latent_dim))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "            model.add(Reshape(self.img_shape))\n",
    "\n",
    "            model.summary()\n",
    "        elif pick_model == 'Drop':\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(256, input_dim=self.latent_dim))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(1024))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "            model.add(Reshape(self.img_shape))\n",
    "\n",
    "            model.summary()\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self, pick_model='Deep_BN'):\n",
    "        if (pick_model == 'Deep_BN') | (pick_model == 'Deeper_D_BN'):\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.summary()\n",
    "        \n",
    "        elif (pick_model == 'Shallow_BN') | (pick_model == 'Deeper_G_BN'): \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.summary()\n",
    "        \n",
    "        elif pick_model == 'Shallow_Drop':\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.summary()\n",
    "        \n",
    "        elif pick_model == 'Drop':\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(512))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "            model.add(Dropout(0.4))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "            model.summary()\n",
    "        \n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50, ratio = (1,1), pick_model = 'Deep_BN'):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            epoch_start_time = time.time()\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "            #implement ratio of D  \n",
    "            if epoch % ratio[0] == 0:\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "            #implement ratio of G\n",
    "            if epoch % ratio[1] == 0:\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            # save data for plotting and csv\n",
    "            train_hist['D_losses'].append(d_loss[0])\n",
    "            train_hist['G_losses'].append(g_loss)\n",
    "            train_hist['per_epoch_ptimes'].append(per_epoch_ptime)    \n",
    "            train_hist['accuracy'].append(100 * d_loss[1])\n",
    "            train_hist['Model'].append(pick_model)\n",
    "            \n",
    "            \n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch, pick_model, ratio)\n",
    "                # Plot the progress\n",
    "                print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                # REMEMBER TO CHANGE TO PARAM DIRECTORY\n",
    "#                 os.makedirs('saved_model_weights', exist_ok=True)\n",
    "#                 generator.save_weights('saved_model_weights/generator_weights_%d.h5'%epoch)\n",
    "#                 discriminator.save_weights('saved_model_weights/discriminator_weights_%d.h5'%epoch)\n",
    "#                 combined.save_weights('saved_model_weights/combined_weights-%d.h5'%epoch)\n",
    "\n",
    "    def sample_images(self, epoch, pick_model, ratio):\n",
    "        r, c = 2, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
    "                axs[i,j].set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        os.makedirs(root + 'images/'+  pick_model + '/'+ str(ratio[0]) + '_' + str(ratio[1]) + '/' , exist_ok=True)\n",
    "        fig.savefig(root + 'images/'+  pick_model + '/'+ str(ratio[0]) + '_' + str(ratio[1]) + '/' + str(epoch) + '.png')\n",
    "#         fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        \n",
    "    def generate_images(self, num):\n",
    "        r, c = 2, 5\n",
    "        arr_imgs = []\n",
    "        arr_labels = []\n",
    "        for i in range(0, num):\n",
    "            noise = np.random.normal(0, 1, (2 * 5, 100))\n",
    "            sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
    "            gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "            # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            arr_imgs.append(gen_imgs)\n",
    "            arr_labels.append(sampled_labels)\n",
    "            \n",
    "        out_imgs = np.asarray(arr_imgs).reshape(num*10, 28, 28, 1)\n",
    "        out_labels = np.asarray(arr_labels).reshape(num*10, 1)\n",
    "        \n",
    "        return out_imgs, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "    x = range(len(hist['D_losses']))\n",
    "    \n",
    "    y1 = hist['D_losses']\n",
    "    y2 = hist['G_losses']\n",
    "\n",
    "    plt.plot(x, y1, label='D_loss')\n",
    "    plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        \n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jack\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 927,745\n",
      "Trainable params: 927,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\venv\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.703743, acc.: 2.34%] [G loss: 0.692811]\n",
      "200 [D loss: 0.590690, acc.: 62.50%] [G loss: 2.020267]\n",
      "elapsed training time: 0 min, 9 sec \n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "10000/10000 [==============================] - 1s 63us/step\n",
      "0 [D loss: 0.512083, acc.: 72.66%] [G loss: 1.949608]\n",
      "200 [D loss: 0.508209, acc.: 75.00%] [G loss: 2.017418]\n",
      "elapsed training time: 0 min, 5 sec \n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "10000/10000 [==============================] - 1s 61us/step\n",
      "0 [D loss: 0.469999, acc.: 76.95%] [G loss: 2.163162]\n",
      "200 [D loss: 0.435567, acc.: 80.86%] [G loss: 2.768640]\n",
      "elapsed training time: 0 min, 5 sec \n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "0 [D loss: 0.412530, acc.: 83.20%] [G loss: 2.614779]\n",
      "200 [D loss: 0.600529, acc.: 60.94%] [G loss: 1.821091]\n",
      "elapsed training time: 0 min, 4 sec \n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "10000/10000 [==============================] - 1s 63us/step\n",
      "0 [D loss: 0.580877, acc.: 72.27%] [G loss: 2.140772]\n",
      "200 [D loss: 0.664184, acc.: 52.73%] [G loss: 1.653927]\n",
      "elapsed training time: 0 min, 3 sec \n",
      "10000/10000 [==============================] - 1s 62us/step\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "0 [D loss: 0.623617, acc.: 53.12%] [G loss: 1.523172]\n",
      "200 [D loss: 0.661501, acc.: 48.05%] [G loss: 1.205379]\n",
      "elapsed training time: 0 min, 5 sec \n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "0 [D loss: 0.620216, acc.: 51.95%] [G loss: 1.268993]\n",
      "200 [D loss: 0.606239, acc.: 54.30%] [G loss: 1.149692]\n",
      "elapsed training time: 0 min, 5 sec \n",
      "10000/10000 [==============================] - 1s 66us/step\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "0 [D loss: 0.640752, acc.: 52.34%] [G loss: 1.408839]\n",
      "200 [D loss: 0.661324, acc.: 27.73%] [G loss: 1.118265]\n",
      "elapsed training time: 0 min, 4 sec \n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "0 [D loss: 0.673674, acc.: 32.81%] [G loss: 1.218667]\n",
      "200 [D loss: 0.223909, acc.: 95.70%] [G loss: 3.374158]\n",
      "elapsed training time: 0 min, 5 sec \n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "10000/10000 [==============================] - 1s 66us/step\n"
     ]
    }
   ],
   "source": [
    "ratio_array = [ (1,1), (1,2), (1,3), (2,3), (3,2), (3,1), (2,1), (10,1), (1,10)]\n",
    "model_array = ['Deep_BN' ] #'Drop' 'Shallow_BN' 'Shallow_Drop' 'Deeper_G_BN' 'Deeper_D_BN']\n",
    "\n",
    "for pick_model in model_array:\n",
    "    #---------------------------COMPILE SELECTED MODELS--------------------------------------#\n",
    "    cgan = CGAN(pick_model=pick_model)\n",
    "    #----------------------------------------LOOP OVER RATIOS--------------------------------#\n",
    "    for ratio in ratio_array:\n",
    "         #----------------------------------------EXECUTION-----------------------------------#\n",
    "        start = time.time()\n",
    "\n",
    "        cgan.train(epochs=20001, batch_size=128, sample_interval=200, ratio=ratio, pick_model=pick_model) ## ratio G:D\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) / 60),\n",
    "                                                                             int((end - start) % 60))\n",
    "        train_hist['total_ptime'].append(elapsed_train_time)\n",
    "\n",
    "        print(elapsed_train_time)\n",
    "        os.makedirs(root + 'hist/', exist_ok=True)  \n",
    "        show_train_hist(train_hist, save=True, path=root + 'hist/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model +'.png')\n",
    "        # save hist data to csv\n",
    "        gen_images, gen_labels = cgan.generate_images(1000)\n",
    "        loss, acc = classif.evaluate(gen_images, to_categorical(gen_labels))\n",
    "        train_hist['classif_loss'].append(loss)\n",
    "        train_hist['classif_acc'].append(acc)\n",
    "        \n",
    "        os.makedirs(root + 'hist_csv/', exist_ok=True) \n",
    "        with open(root+ 'hist_csv/' + str(ratio[0]) + '_' + str(ratio[1]) + pick_model +'.csv', 'w') as f:\n",
    "            for key in train_hist.keys():\n",
    "                f.write(\"%s,%s\\n\"%(key,train_hist[key]))\n",
    "        \n",
    "        \n",
    "        # remove old data structure\n",
    "        del train_hist\n",
    "        # redefine\n",
    "        train_hist = {}\n",
    "        train_hist['D_losses'] = []\n",
    "        train_hist['G_losses'] = []\n",
    "        train_hist['per_epoch_ptimes'] = []\n",
    "        train_hist['total_ptime'] = []\n",
    "        train_hist['accuracy'] = []\n",
    "        train_hist['Model'] = []\n",
    "        train_hist['classif_loss'] = []\n",
    "        train_hist['classif_acc'] = []\n",
    "        gen_images, gen_labels = cgan.generate_images(1000)\n",
    "        loss, acc = classif.evaluate(gen_images, to_categorical(gen_labels))\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_images, gen_labels = cgan.generate_images(1000)\n",
    "# loss, acc = classif.evaluate(gen_images, to_categorical(gen_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4406905708312987\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "(10000, 28, 28, 1)\n",
      "[4]\n",
      "['loss', 'acc']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(gen_labels.shape)\n",
    "print(gen_images.shape)\n",
    "\n",
    "print(gen_labels[5004])\n",
    "plt.imshow(gen_images[5004,:,:, 0], cmap='gray')\n",
    "\n",
    "print(classif.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
